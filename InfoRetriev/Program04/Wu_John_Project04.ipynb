{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Paths\n",
    "\n",
    "For this project, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, nltk, os, sklearn.preprocessing, sklearn.metrics\n",
    "import tokenHelper as tkn # import custom function for tokenization of text\n",
    "import numpy as np\n",
    "from sklearn import naive_bayes as NB, svm as SVM, linear_model as LM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = os.path.join('e:', 'VirtualMachines', 'shared', 'tmp')\n",
    "d = os.path.join('c:', 'data', 'JHU', 'InfoRetriev', 'Program04')\n",
    "trainFile = os.path.join(d, 'phase1.train.shuf.tsv')\n",
    "devFile = os.path.join(d, 'phase1.dev.shuf.tsv')\n",
    "testFile = os.path.join(d, 'phase1.test.shuf.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['assessment','docID','title','authors','journal','ISSN','year',\n",
    "\t\t'language', 'abstract', 'keywords'] # the variable names for file\n",
    "convFun = {1: lambda b: b[5:]} # to capture hash code without prefix\n",
    "\n",
    "def readFile(fName):\n",
    "\treturn np.genfromtxt(fName, delimiter='\\t', dtype=None, names=header,\n",
    "\t\tcomments=None, converters=convFun, encoding='utf-8') # load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = readFile(trainFile) # training set\n",
    "dev = readFile(devFile) # development set\n",
    "test = readFile(testFile) # test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create binarizer for labeling assessments in the data\n",
    "# mark +1 as positive, and rest as negative based on data\n",
    "labelr = sklearn.preprocessing.LabelBinarizer(pos_label=1)\n",
    "labelr.fit(train['assessment']) # fit on training labels\n",
    "y_train = labelr.transform(train['assessment']).ravel()\n",
    "y_actual = labelr.transform(dev['assessment']).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates various stats related to validation\n",
    "def validationStats(y_Prd, y_Act, msg=''): \n",
    "    # confusion matrix, T=true, F=false, N=negative, P=positive\n",
    "    TN, FP, FN, TP = sklearn.metrics.confusion_matrix(y_Act, y_Prd).ravel()\n",
    "    precision,recall = TP/(TP+FP) , TP/(TP+FN) # precision and recall\n",
    "    corr,tot = TN+TP , TN+TP+FN+FP # used for accuracy calculation\n",
    "    print(\"Using Naive Bayes, %s\"%msg)\n",
    "    print(\"\\tRecall: %u/%u = %.1f%%\" % (TP, TP+FN, recall*100) )\n",
    "    print(\"\\tPrecision: %u/%u = %.1f%%\" % (TP, TP+FP, precision*100) )\n",
    "    print(\"\\tF1 score: %.3f\" % (2*precision*recall / (precision+recall)) )\n",
    "    print(\"\\tAccuracy: %u/%u = %.1f%%\" % (corr,tot,corr/tot*100) )\n",
    "    return (TN, FP, FN, TP)\n",
    "\n",
    "################################################################################\n",
    "def concatColsForFeat(rawTxt, cols, delDashStar=True):\n",
    "    if delDashStar:\n",
    "        tranTab = str.maketrans('/*','  ')\n",
    "    else:\n",
    "        tranTab = str.maketrans('','')\n",
    "    f = np.vectorize(lambda x: ' '.join(x).translate(tranTab))\n",
    "    return f(rawTxt[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Using Title Only\n",
    "The following section builds a pipeline for a Naive Bayes classifier. The pipeline includes two parts:\n",
    "1. **TF-IDF vectorizer**, which extracts features from input text and builds a document-term matrix based on TF-IDF values. \n",
    "  * The text is tokenized via NLTK `word_tokenize` function.\n",
    "  * Tokens are removed if they are on a list of NLTK English stopwords or any consecutive punctuation.\n",
    "  * Only the top 10K terms by document frequency is retained, as well as any terms with less than DF<3 are also removed.\n",
    "  * TF-IDF weights are used for document-term matrix.\n",
    "1. **Complement Naive Bayes** model is used for classification\n",
    "  * The algorithm is described in [Rennie et al (2003)](http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf), and corrects for severe assumptions of Multinomial or Bernoulli Naive Bayes.\n",
    "  * It is useful for when the training set has unbalanced classes (in this case 3.2% of the training sample is positive)\n",
    "  * Laplace smoothing is used with $\\alpha=0.05$, due to the large number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.naive_bayes' has no attribute 'ComplementNB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ade5fc009784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n\u001b[0;32m      3\u001b[0m                              max_features=5000, min_df=3) ), \n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mComplementNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.naive_bayes' has no attribute 'ComplementNB'"
     ]
    }
   ],
   "source": [
    "NB_pipe = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=5000, min_df=3) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_pred = NB_pipe.fit(train['title'], y_train).predict(dev['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Naive Bayes model using only title when validated against the development sample is presented as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title only.\n",
      "\tRecall: 96/150 = 64.0%\n",
      "\tPrecision: 96/622 = 15.4%\n",
      "\tF1 score: 0.249\n",
      "\tAccuracy: 4270/4850 = 88.0%\n"
     ]
    }
   ],
   "source": [
    "# calculate validation stats\n",
    "\n",
    "validationStats(y_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Title, Abstract, and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text by cocatenating three fields from CSV file\n",
    "txt3_train = concatColsForFeat(train, ['title','abstract','keywords'])\n",
    "txt3_dev = concatColsForFeat(dev, ['title','abstract','keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipe_TAK = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=5000, min_df=5) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "################################################################################\n",
    "# extract, train, and predict\n",
    "y3_pred = NB_pipe.fit(txt3_train,y_train).predict(txt3_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Naive Bayes model using only title when validated against the development sample is presented as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title+abstract+keywords\n",
      "\tRecall: 135/150 = 90.0%\n",
      "\tPrecision: 135/1373 = 9.8%\n",
      "\tF1 score: 0.177\n",
      "\tAccuracy: 3597/4850 = 74.2%\n"
     ]
    }
   ],
   "source": [
    "validationStats(y3_pred, y_actual, 'features from title+abstract+keywords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Alternative Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title only.\n",
      "\tRecall: 97/150 = 64.7%\n",
      "\tPrecision: 97/705 = 13.8%\n",
      "\tF1 score: 0.227\n",
      "\tAccuracy: 4189/4850 = 86.4%\n"
     ]
    }
   ],
   "source": [
    "NB_pipe2 = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopwordNStem, \n",
    "                             max_features=5000, min_df=3) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_2_pred = NB_pipe2.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_2_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title only.\n",
      "\tRecall: 92/150 = 61.3%\n",
      "\tPrecision: 92/584 = 15.8%\n",
      "\tF1 score: 0.251\n",
      "\tAccuracy: 4300/4850 = 88.7%\n"
     ]
    }
   ],
   "source": [
    "NB_pipe3 = Pipeline([ # establish pipeline\n",
    "    ('vect', CountVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=5000, min_df=3) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_3_pred = NB_pipe3.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_3_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title only.\n",
      "\tRecall: 78/150 = 52.0%\n",
      "\tPrecision: 78/716 = 10.9%\n",
      "\tF1 score: 0.180\n",
      "\tAccuracy: 4140/4850 = 85.4%\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "NB_pipe4 = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=5000, min_df=3, ngram_range=(2,3)) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_4_pred = NB_pipe4.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_4_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title only.\n",
      "\tRecall: 110/150 = 73.3%\n",
      "\tPrecision: 110/856 = 12.9%\n",
      "\tF1 score: 0.219\n",
      "\tAccuracy: 4064/4850 = 83.8%\n"
     ]
    }
   ],
   "source": [
    "NB_pipe5 = Pipeline([ # establish pipeline\n",
    "    ('vect', CountVectorizer(max_features=5000, min_df=3, analyzer='char', \n",
    "                             ngram_range=(5,5) ) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_5_pred = NB_pipe5.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_5_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "SVM_pipe = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=5000, min_df=3, ngram_range=(2,3)) ), \n",
    "    ('clf', LM.SGDClassifier(loss='log', penalty='l2', alpha=1e-3, \n",
    "                             random_state=1, tol=1e-3) )\n",
    "])\n",
    "\n",
    "y_svm_pred = SVM_pipe.fit(train['title'], y_train).predict(dev['title'])\n",
    "#validationStats(y_svm_pred, y_actual, 'features from title only.');\n",
    "\n",
    "print(sum(y_svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Naive Bayes, features from title only.\n",
      "\tRecall: 45/150 = 30.0%\n",
      "\tPrecision: 45/162 = 27.8%\n",
      "\tF1 score: 0.288\n",
      "\tAccuracy: 4628/4850 = 95.4%\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "SVM_pipe = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=5000, min_df=3) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(max_iter=-1, random_state=1, class_weight='balanced') )\n",
    "])\n",
    "################################################################################\n",
    "y_svm_pred = SVM_pipe.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_svm_pred, y_actual, 'features from title only.');\n",
    "\n",
    "print(sum(y_svm_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
