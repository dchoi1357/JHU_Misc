{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 04\n",
    "Student: John Wu  \n",
    "\n",
    "For this project, I applied naive Bayes algorithm to the **Systematic Review** data set. The machine learning library, `scikit-learn` is used extensively for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, nltk, os, sklearn.preprocessing, sklearn.metrics\n",
    "import tokenHelper as tkn # import custom function for tokenization of text\n",
    "import numpy as np\n",
    "from sklearn import naive_bayes as NB, svm as SVM, linear_model as LM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline as skPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = os.path.join('e:', 'VirtualMachines', 'shared', 'tmp')\n",
    "#d = os.path.join('c:', 'data', 'JHU', 'InfoRetriev', 'Program04')\n",
    "trainFile = os.path.join(d, 'phase1.train.shuf.tsv')\n",
    "devFile = os.path.join(d, 'phase1.dev.shuf.tsv')\n",
    "testFile = os.path.join(d, 'phase1.test.shuf.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['assessment','docID','title','authors','journal','ISSN','year',\n",
    "\t\t'language', 'abstract', 'keywords'] # the variable names for file\n",
    "\n",
    "def readFile(fName):\n",
    "\treturn np.genfromtxt(fName, delimiter='\\t', dtype=None, names=header,\n",
    "\t\tcomments=None, encoding='utf-8') # load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in files\n",
    "train = readFile(trainFile) # training set\n",
    "dev = readFile(devFile) # development set\n",
    "test = readFile(testFile) # test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates various stats related to validation\n",
    "def validationStats(y_Prd, y_Act, msg='', algo='naive Bayes'):\n",
    "    # confusion matrix, T=true, F=false, N=negative, P=positive\n",
    "    TN, FP, FN, TP = sklearn.metrics.confusion_matrix(y_Act, y_Prd).ravel()\n",
    "    precision,recall = TP/(TP+FP) , TP/(TP+FN) # precision and recall\n",
    "    corr,tot = TN+TP , TN+TP+FN+FP # used for accuracy calculation\n",
    "    print(\"Using %s, %s\"%(algo,msg))\n",
    "    print(\"\\tRecall: %u/%u = %.1f%%\" % (TP, TP+FN, recall*100) )\n",
    "    print(\"\\tPrecision: %u/%u = %.1f%%\" % (TP, TP+FP, precision*100) )\n",
    "    print(\"\\tF1 score: %.3f\" % (2*precision*recall / (precision+recall)) )\n",
    "    print(\"\\tAccuracy: %u/%u = %.1f%%\" % (corr,tot,corr/tot*100) )\n",
    "    return (TN, FP, FN, TP)\n",
    "\n",
    "# get columns from raw data and concatenate data\n",
    "def concatColsForFeat(rawTxt, cols, delDashStar=True):\n",
    "    if delDashStar:\n",
    "        tranTab = str.maketrans('/*','  ')\n",
    "    else:\n",
    "        tranTab = str.maketrans('','')\n",
    "    f = np.vectorize(lambda x: ' '.join(x).translate(tranTab))\n",
    "    return f(rawTxt[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Using Title Only\n",
    "The following section builds a pipeline for a naive Bayes classifier. The pipeline includes two parts:\n",
    "1. **TF-IDF vectorizer**, which extracts features from input text and builds a document-term matrix based on TF-IDF values. \n",
    "  * The text is tokenized via NLTK `word_tokenize` function.\n",
    "    * It is based on [Treebank tokenization](ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html) developed at UPenn.\n",
    "    * It splits on all whitespaces as well as contractions i.e. \"can't\" -> \"ca\", \"n't\"\n",
    "    * It tokenizes any consecutive number of punctuations, such as “,”, “?”, “—“, or “…”\n",
    "    * Punctuations inmixed with letters, such as “03/20/2018” would be tokenized as one word, as well as\n",
    "things like URL or hyphenated words like “open-faced”\n",
    "  * Tokens are removed if they are on a list of NLTK English stopwords or any consecutive punctuation.\n",
    "  * Only the top 10K terms by document frequency is retained, as well as any terms with less than DF<2 are also removed.\n",
    "  * TF-IDF weights are used for document-term matrix.\n",
    "1. **Complement Naive Bayes** model is used for the \"baselie\" classification\n",
    "  * The algorithm is described in [Rennie et al (2003)](http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf), and corrects for severe assumptions of multinomial or Bernoulli naive Bayes.\n",
    "  * It is useful for when the training set has unbalanced classes (in this case 3.2% of the training sample is positive)\n",
    "  * Laplace smoothing is used with $\\alpha=0.05$, due to the large number of features and high possibility of a term not appearing in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to work correctly in `sklearn`, we must first binarize the asessment labels by marking +1 as positive, and the rest as negative. This binarizer are then used to mark the development sample also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create binarizer for labeling assessments in the data\n",
    "labelr = sklearn.preprocessing.LabelBinarizer(pos_label=1)\n",
    "y_train = labelr.fit_transform(train['assessment']).ravel() # training set\n",
    "y_actual = labelr.transform(dev['assessment']).ravel() # validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code builds a pipeline as described at the beginning of the section, combining TF-IDF vectorizer and a complement naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipe = skPipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=10000, min_df=2) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_pred = NB_pipe.fit(train['title'], y_train).predict(dev['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Naive Bayes model using only title when validated against the development sample is presented as follows, where the various performance statistics are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, features from title only.\n",
      "\tRecall: 93/150 = 62.0%\n",
      "\tPrecision: 93/569 = 16.3%\n",
      "\tF1 score: 0.259\n",
      "\tAccuracy: 4317/4850 = 89.0%\n"
     ]
    }
   ],
   "source": [
    "validationStats(y_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Title, Abstract, and Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must extract text by cocatenating three fields from CSV file. This is done for both training and development samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3_train = concatColsForFeat(train, ['title','abstract','keywords'])\n",
    "txt3_dev = concatColsForFeat(dev, ['title','abstract','keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the previous section, a pipeline is built, but this time using the expanded set of features. With the increased amouont of text, the maximum allowed number of features is increased as well as the minimum document frequency to qualify as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pipe_TAK = skPipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=15000, min_df=3) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "################################################################################\n",
    "# extract, train, and predict\n",
    "y3_pred = NB_pipe_TAK.fit(txt3_train,y_train).predict(txt3_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Naive Bayes model improves appreciably, with a large increase in recall and a small increase in precision. However, training and fitting time also increases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, features from title+abstract+keywords\n",
      "\tRecall: 118/150 = 78.7%\n",
      "\tPrecision: 118/562 = 21.0%\n",
      "\tF1 score: 0.331\n",
      "\tAccuracy: 4374/4850 = 90.2%\n"
     ]
    }
   ],
   "source": [
    "validationStats(y3_pred, y_actual, 'features from title+abstract+keywords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Alternative Hyperparameters\n",
    "This section present several alternative Naive Bayes models with different tokenization, vectorization, feature selection, and algorithm. Since fitting a model with title, abstract, and keywords take quite a bit longer, this section will only use title for features to so as to allow the running of multiple alternative setups. The result will be benchmarked with the baselinse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, title features, 5-stemmed\n",
      "\tRecall: 96/150 = 64.0%\n",
      "\tPrecision: 96/690 = 13.9%\n",
      "\tF1 score: 0.229\n",
      "\tAccuracy: 4202/4850 = 86.6%\n"
     ]
    }
   ],
   "source": [
    "# 5 Stemming title text\n",
    "NB_pipe2 = skPipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopwordNStem, \n",
    "                             max_features=5000, min_df=2) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_2_pred = NB_pipe2.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_2_pred, y_actual, 'title features, 5-stemmed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-stemming the title degrades performance, resulting in slightly worse precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, title features, count vectors\n",
      "\tRecall: 90/150 = 60.0%\n",
      "\tPrecision: 90/549 = 16.4%\n",
      "\tF1 score: 0.258\n",
      "\tAccuracy: 4331/4850 = 89.3%\n"
     ]
    }
   ],
   "source": [
    "# Using counts instead of TF-IDF weights\n",
    "NB_pipe3 = skPipeline([ # establish pipeline\n",
    "    ('vect', CountVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=10000, min_df=3) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_3_pred = NB_pipe3.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_3_pred, y_actual, 'title features, count vectors');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using count instead of TF-IDF document-term vectors result in similar performance, with slight drop in recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, features from title only.\n",
      "\tRecall: 77/150 = 51.3%\n",
      "\tPrecision: 77/659 = 11.7%\n",
      "\tF1 score: 0.190\n",
      "\tAccuracy: 4195/4850 = 86.5%\n"
     ]
    }
   ],
   "source": [
    "# Using word 2 and 3-gram \n",
    "NB_pipe4 = skPipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=10000, min_df=1, ngram_range=(2,3)) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_4_pred = NB_pipe4.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_4_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using word 2 and 3-gram result in significantly worse performance.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, features from title only.\n",
      "\tRecall: 101/150 = 67.3%\n",
      "\tPrecision: 101/676 = 14.9%\n",
      "\tF1 score: 0.245\n",
      "\tAccuracy: 4226/4850 = 87.1%\n"
     ]
    }
   ],
   "source": [
    "# Using character 4-5 grams\n",
    "NB_pipe5 = skPipeline([ # establish pipeline\n",
    "    ('vect', CountVectorizer(max_features=15000, min_df=3, analyzer='char', \n",
    "                             ngram_range=(4,5)) ), \n",
    "    ('clf', NB.ComplementNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "y_5_pred = NB_pipe5.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_5_pred, y_actual, 'features from title only.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using character 4-5 grams is a large step-up over using word n-grams, but still significantly worse than using word features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Machine Learning Algorithms\n",
    "In this section, support vector machine (SVM) algorithm is explored to test whether it can provide a better performance than naive Bayes. Like with naive Bayes classifier, we also run into the problem of unbalanced class. Since so much of the data are of the negative class, SVM classifier would get overwhelmed and predict all classes as negative. Therefore, one must weigh the classes so that the training sample would not be biased. Likewise, the input also need to be scaled as SVM works best when the features are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVM, features from title only.\n",
      "\tRecall: 54/150 = 36.0%\n",
      "\tPrecision: 54/207 = 26.1%\n",
      "\tF1 score: 0.303\n",
      "\tAccuracy: 4601/4850 = 94.9%\n"
     ]
    }
   ],
   "source": [
    "# Using features from title only\n",
    "SVM_pipe = skPipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=10000, min_df=2) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(gamma='auto', max_iter=-1, random_state=1, \n",
    "                    class_weight='balanced') )\n",
    "])\n",
    "\n",
    "y_svm_pred = SVM_pipe.fit(train['title'], y_train).predict(dev['title'])\n",
    "validationStats(y_svm_pred, y_actual, 'features from title only.', 'SVM');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVM, features from title only.\n",
      "\tRecall: 22/150 = 14.7%\n",
      "\tPrecision: 22/32 = 68.8%\n",
      "\tF1 score: 0.242\n",
      "\tAccuracy: 4712/4850 = 97.2%\n"
     ]
    }
   ],
   "source": [
    "# Using features from title+abstract+keywords only\n",
    "SVM3_pipe = skPipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=tkn.tokenizeNoPunctStopword, \n",
    "                             max_features=15000, min_df=3) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(gamma='auto', max_iter=-1, random_state=1, \n",
    "                    class_weight='balanced') )\n",
    "])\n",
    "\n",
    "y3_svm_pred = SVM_pipe.fit(txt3_train, y_train).predict(txt3_dev)\n",
    "validationStats(y3_svm_pred, y_actual, 'features from title only.', 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, using SVM increases precision quite a bit, but at a high cost of low recall. Conceptually, this makes sense. SVM are better at splitting between the two classes as the algorithm keeps running until differences are smaller than a threshold. However, this also means the algorithm may not be computationally tractable and is prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Testing Set\n",
    "The best performing setup so far was complement naive Bayes with all three fields as feature. It strictly dominates all the other naive Bayes method, and while the precision is not as good as using SVM with titles only, the recall is so much higher that it makes up for it. At the same time, it does not suffer from computational complexity problems of SVM algorithm. Therefore, it is best to predict the test set using this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features on test set and predict the Y\n",
    "txt3_test = concatColsForFeat(test, ['title','abstract','keywords'])\n",
    "y3_test = NB_pipe_TAK.predict(txt3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output file\n",
    "with open('wu-prog4.txt', 'w') as f:\n",
    "    for x in zip(test['docID'], y3_test):\n",
    "        f.write('%s\\t%i\\n' % (x[0], -1 if x[1]==0 else 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
