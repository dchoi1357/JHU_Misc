{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Programming Assignment (Summer)\n",
    "\n",
    "## Directions\n",
    "\n",
    "There are general instructions on Blackboard and in the Syllabus for Programming Assignments. This Notebook also has instructions specific to this assignment. Read all the instructions carefully and make sure you understand them. Please ask questions on the discussion boards or email me at `EN605.445@gmail.com` if you do not understand something.\n",
    "\n",
    "<div style=\"background: mistyrose; color: firebrick; border: 2px solid darkred; padding: 5px; margin: 10px;\">\n",
    "You must follow the directions *exactly* or you will get a 0 on the assignment.\n",
    "</div>\n",
    "\n",
    "You must submit *only* your IPython notebook to Blackboard. It should be cleanly executed and named:\n",
    "\n",
    "```\n",
    "<jhed_id>.ipynb\n",
    "```\n",
    "\n",
    "An HTML version of the notebook will be generated and graded and the notebook will be used only for reference. To see what the HTML version of your notebook will look like, apply the following command:\n",
    "\n",
    "> ipython nbconvert <jhed_id>.ipynb\n",
    "\n",
    "or use the File menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "When we last left our agent in Module 4, it was wandering around a world filled with plains, forests, swamps, hills and mountains. This presupposes a map with known terrain:\n",
    "\n",
    "```\n",
    "......\n",
    "...**.\n",
    "...***\n",
    "..^...\n",
    "..~^..\n",
    "```\n",
    "\n",
    "but what if all we know is that we have some area of interest, that we've reduced to a GPS grid:\n",
    "\n",
    "```\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "```\n",
    "\n",
    "and the agent has to determine what kind of terrain is to the left, front and right of it?\n",
    "\n",
    "Assuming the agent has a very simple visual sensor that constructs a 4x4 grayscale image for each of the three directions, it might it could see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAFzCAYAAAC+dom9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe737bea210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random, math\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray', interpolation='none')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray', interpolation='none')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray', interpolation='none')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "For this programming assignment your tasks are:\n",
    "\n",
    "1. Write a logistic regression that simply determines if something is a hill or not (two class problem). \n",
    "2. You will also evaluate that logistic regression by generating a *confusion matrix*.\n",
    "\n",
    "For a starting point, you can refer to **module-8-pseudocode.pdf** and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray', interpolation='none')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8DCzLA4PM8vi8DCzLA4PM8vy/0VZaizWdRVNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe737b09f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw8yyODzMLMv/Az1729WY2nOjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7379c70d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe737a15450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "4. `calculate_confusion_matrix`\n",
    "\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, a logistic regression that determines if a sensor image is hills (1) or not (0).\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes, in this case \"hills\" and \"not hills\". This means you should probably generate training data with, say, 100 hills and then 100 of all the other types of terrain combined.\n",
    "\n",
    "When you send your data to the actual `learn_model` function, it will need to have all the String labels transformed to 0 or 1 appropriately. Remember, you also need to set $x_0$ = 1.0; *where* you do that is up to you but you need to be consistent (if you do it in `generate_data` then don't also do it in `learn_model` or `apply_model`.\n",
    "\n",
    "You can make `generate_data` as sophisticated as you like. But it should at least take n and a label so that:\n",
    "\n",
    "`generate_data( clean_data, 100, \"hills\")`\n",
    "\n",
    "generates 100 hills, 100 not hills and has transformed the String labels into 1 and 0, respectively.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the logistic regression model. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "I should also mention that gradient descent is not the usual approach to linear|logistic regression because the error function actually has an *exact* solution. However, in the case of large data sets, the exact solution often fails and in any case, the use of gradient descent will prepare you for neural networks next week.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller. \n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the List of Thetas.\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes a List of Thetas (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a Tuple of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19).\n",
    "\n",
    "If the data is labeled, you will return a Tuple of the actual value (0 or 1) and the predicted value (0 or 1). In this case, you return a List of something like [(0, 1), (1, 1), (0, 0), (1, 0)].\n",
    "\n",
    "### `calculate_confusion_matrix`\n",
    "\n",
    "The `calculate_confusion_matrix` takes the results of `apply_model` when labeled=True and prints a nice HTML version of a confusion matrix and include statistics for error rate, true positive rate and true negative rate.\n",
    "\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (and not to be modifying a copy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper functions\n",
    "\n",
    "**logistic(x, theta)**  \n",
    "Given a matrix x and a vector $\\theta$, calculate the logistic function:  \n",
    "$$ \\hat{y}= \\frac{1}{1+e^{-\\mathbf{x} \\mathbf{\\theta}}} $$\n",
    "\n",
    "**logisticError(x, theta, y)**  \n",
    "Calculate the error of the logistic regression given a matrix of `x`, a vector of $\\theta$, and actual value `y`. \n",
    "$$Err(\\mathbf{x},\\mathbf{\\theta},\\mathbf{y})=-\\frac{1}{n}\\sum_i\ty_i\tlog(\\hat{y_i}) + (1\t- y_i)log(1\t- \\hat{y_i})$$\n",
    "\n",
    "**updateTheta(a, yhat, y, x, th, errDiff)**  \n",
    "Update the $\\theta$ based on $\\hat{y}$ and $\\alpha$, using the equation  \n",
    "$$\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{n}\\sum_i(\\hat{y_i}  - y_i)x_{ij}$$\n",
    "$$\\theta_{t+1} = \\theta_{t} - \\alpha \\cdot \\frac{\\partial J}{\\partial \\theta_j}$$\n",
    "\n",
    "**makeIndepDepData(data)**  \n",
    "Given a matrix of input data of dimension i x j, where the first j-1 columns are the independent variables, and column j is the actual, the function outputs matrix of the first j-1 columns prepended with a vertical vector of ones (for the intercept), and the y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic(x, beta):\n",
    "    xbeta = [sum([xi*Bi for xi,Bi in zip(n,beta)]) for n in x]\n",
    "    return [1.0 / (1 + math.exp(-n)) for n in xbeta]\n",
    "\n",
    "################################################################################\n",
    "def logisticError(x, theta, y):\n",
    "    yhat = logistic(x, theta)\n",
    "    e = [yi*math.log(yHi) + (1-yi)*math.log(1-yHi) for yi,yHi in zip(y,yhat)]\n",
    "    return -sum(e)/len(e), yhat\n",
    "    \n",
    "def updateTheta(a, yhat, y, x, th, errDiff):\n",
    "    d = [0 for xx in y]\n",
    "    e = [yHi-yi for yHi,yi in zip(yhat,y)]    \n",
    "    dMat = [[ej*xij for xij in xj] for ej,xj in zip(e,x)]\n",
    "    d = [sum([dd[i] for dd in dMat])/len(y) for i in range(len(x[0]))]\n",
    "    \n",
    "    return [tHj - (a*dj) for tHj,dj in zip(th,d)]\n",
    "\n",
    "def makeIndepDepData(data):\n",
    "    x = [[1] + d[:-1] for d in data]\n",
    "    y = [d[-1] for d in data]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 10 blurred \"hills\" examples with balanced (same number of) \"non hills\" examples to see that the function is working.\n",
    "\n",
    "**generate_data( data, n, label)**  \n",
    "Generate n blurred data points of the `label` category by choosing instances of data points within that category, as well as n random blurred data points instances that belongs to other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.165', '0.019209', '0.15426', '0.090246', '0.048995', '0.10095', '0.11043', '0.86349', '0.1211', '0.18517', '0.91435', '0.92341', '0.1777', '0.9857', '0.86768', '1', '1']\n",
      "['0.1185', '0.069004', '0.071652', '0.13758', '0.12143', '0.019913', '0.11242', '0.95113', '0.081767', '0', '0.90001', '0.99336', '0.093588', '0.82476', '0.97279', '0.80282', '1']\n",
      "['0.11541', '0.17301', '0.085161', '0.093355', '0.12517', '0.12439', '0.84935', '0.11385', '0.12379', '0.86129', '0.93266', '1', '1', '0.82651', '0.79003', '0.93947', '1']\n",
      "['0.10099', '0.10107', '0.12331', '0.18214', '0', '0.17397', '0.78121', '0.043599', '0.099743', '0.8296', '0.93054', '0.6755', '0.82318', '0.80135', '0.99716', '0.94802', '1']\n",
      "['0.13505', '0', '0.12173', '0.14292', '0.11169', '0.16031', '0.94923', '0.092742', '0.03872', '0.92934', '0.92973', '0.86644', '1', '0.80339', '0.98179', '1', '1']\n",
      "['0.18651', '0.095897', '0.13828', '0.095902', '0.93926', '0.22267', '0.095197', '0.11811', '0.9296', '0.964', '0.12937', '0.14262', '0.94979', '0.95118', '0.91214', '0.091284', '1']\n",
      "['0.1133', '0.11673', '0.12627', '0.12392', '0.049327', '0.10473', '0.11991', '0.77235', '0.16845', '0.15308', '0.82905', '0.9189', '0.11572', '1', '0.88751', '0.86144', '1']\n",
      "['0.12523', '0.16063', '0.040323', '0.21579', '0.088772', '0.029923', '0.15612', '1', '0.11868', '0.080624', '0.92386', '1', '0.071135', '0.67429', '0.914', '0.96417', '1']\n",
      "['0.18523', '0.1272', '0.10411', '0.14191', '0.11197', '0.19056', '0.88005', '0.13448', '0.1773', '1', '1', '0.93001', '0.90049', '0.87645', '0.96082', '0.78509', '1']\n",
      "['0.071937', '0.12066', '0.12707', '0.093966', '0.79392', '0.12052', '0.05779', '0.089439', '1', '0.79929', '0.10213', '0.040839', '0.7923', '0.94113', '0.91476', '0.11726', '1']\n",
      "['0.11744', '0.082084', '0.082562', '0.11628', '0.023426', '0.060702', '0.13172', '0.11673', '0.046151', '0.078502', '0.1036', '0.15035', '0.99199', '0.86088', '0.93274', '0.91538', '0']\n",
      "['0.11766', '0.043106', '0.13502', '0.18844', '0.13329', '0.052895', '0.007198', '0.15306', '0.85827', '0.080677', '0.90312', '0.12013', '0.80679', '0.89174', '0.82409', '1', '0']\n",
      "['0.049134', '0.025447', '0.1462', '0.13712', '0.054013', '0.026164', '0.092363', '0.098112', '0.96776', '0.11226', '1', '0.16141', '0.89941', '0.9148', '0.92528', '0.84464', '0']\n",
      "['0', '0.096084', '0.11262', '0.05972', '0.087581', '0.14203', '0.1037', '0.080161', '0.0056364', '1', '0.10253', '0.8397', '0.97669', '0.88316', '0.85193', '0.8385', '0']\n",
      "['0.23139', '0.123', '0.89181', '0.16755', '0.1443', '0.91146', '0.75792', '1', '0.87837', '0.80706', '0.969', '0.97764', '0.099372', '0.11071', '0.94177', '0.15095', '0']\n",
      "['0.16685', '0.085044', '0.020036', '0.047016', '0.0522', '0.09055', '0.057294', '0.20935', '0.86417', '0.11052', '0.89678', '0.0057125', '0.73168', '0.88454', '0.91564', '0.92441', '0']\n",
      "['0.08781', '0.094749', '0.12571', '0.90772', '0.10459', '0.08742', '0.80673', '0.94666', '0.051826', '0.88415', '0.93', '1', '0.18824', '0.10704', '0.034896', '0.78079', '0']\n",
      "['0.068235', '0.087128', '0.074954', '1', '0.084591', '0.15553', '0.83759', '0.80972', '0.10422', '0.71136', '0.86681', '0.74181', '0.04605', '0.15417', '0.023864', '0.88359', '0']\n",
      "['0.072544', '0.14056', '0.11806', '0.6145', '0.10077', '0.15968', '0.92091', '0.89634', '0.10704', '1', '0.90354', '0.94507', '0.15373', '0.14867', '0.10513', '0.92317', '0']\n",
      "['0', '0.027128', '0.073726', '0.13642', '0', '0.039439', '0.16625', '0.088025', '0.070634', '0.091714', '0.090037', '0.089584', '1', '0.96779', '0.91926', '0.92648', '0']\n"
     ]
    }
   ],
   "source": [
    "def generate_data( data, n, label):\n",
    "    outK = [k for k in data.keys() if k!=label]\n",
    "    inPts = [blur(data[label][random.randrange(len(data[label]))])[:-1] + [1] \\\n",
    "             for x in xrange(n)]\n",
    "    outPts = list()\n",
    "    for x in xrange(n):\n",
    "        tp = random.sample(outK, 1)[0]\n",
    "        outPts.append(blur(data[tp][random.randrange(len(data[tp]))][:-1]+[0]))\n",
    "    return inPts + outPts\n",
    "\n",
    "results = generate_data( clean_data, 10, \"hills\")\n",
    "for result in results:\n",
    "    print [\"{0:0.5g}\".format(i) for i in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a logistic regression model for classifying sensor images as \"hills\" or \"not hills\". Use your `generate_data` function to generate a training set with 100 hills examples. **Set Verbose to True**\n",
    "\n",
    "**learn_model( data, alpha, eps, verbose=False)**  \n",
    "Using gradient descent, fit a logistic regression to the input data by adjusting the parameters to find one that minimizes the error as calculated `logisticError()`. The algorithm runs until the successive differences between the errors of the iteration is less than `eps` in the parameter. Each iteration updates the $\\theta$ according to the derivative. When the error difference increases, the alpha gets divided by 10. The algorithm goes for 1 million iterations before stopping, even though when the error difference has not reached epsilon yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #0, error: 1.044651\n",
      "Iter #1000, error: 0.363056\n",
      "Iter #2000, error: 0.264144\n",
      "Iter #3000, error: 0.213503\n",
      "Iter #4000, error: 0.181954\n",
      "Iter #5000, error: 0.160155\n",
      "Iter #6000, error: 0.144076\n",
      "Iter #7000, error: 0.131662\n",
      "Iter #8000, error: 0.121750\n",
      "Iter #9000, error: 0.113626\n",
      "Iter #10000, error: 0.106829\n",
      "Iter #11000, error: 0.101044\n",
      "Iter #12000, error: 0.096052\n",
      "Iter #13000, error: 0.091692\n",
      "Iter #14000, error: 0.087845\n",
      "Iter #15000, error: 0.084422\n",
      "Iter #16000, error: 0.081352\n",
      "Iter #17000, error: 0.078580\n",
      "Iter #18000, error: 0.076062\n",
      "Iter #19000, error: 0.073763\n",
      "Iter #20000, error: 0.071653\n",
      "Iter #21000, error: 0.069709\n",
      "Iter #22000, error: 0.067910\n",
      "Iter #23000, error: 0.066239\n",
      "Iter #24000, error: 0.064683\n",
      "Iter #25000, error: 0.063229\n",
      "Iter #26000, error: 0.061867\n",
      "Iter #27000, error: 0.060587\n",
      "Iter #28000, error: 0.059382\n",
      "Iter #29000, error: 0.058244\n",
      "Iter #30000, error: 0.057168\n",
      "Iter #31000, error: 0.056149\n",
      "Iter #32000, error: 0.055181\n",
      "Iter #33000, error: 0.054261\n",
      "Iter #34000, error: 0.053385\n",
      "Iter #35000, error: 0.052549\n",
      "Iter #36000, error: 0.051751\n",
      "Iter #37000, error: 0.050987\n",
      "Iter #38000, error: 0.050256\n",
      "Iter #39000, error: 0.049555\n",
      "Iter #40000, error: 0.048882\n",
      "Iter #41000, error: 0.048236\n",
      "Iter #42000, error: 0.047614\n",
      "Iter #43000, error: 0.047015\n",
      "Iter #44000, error: 0.046438\n",
      "Iter #45000, error: 0.045881\n",
      "Iter #46000, error: 0.045344\n",
      "Iter #47000, error: 0.044824\n",
      "Iter #48000, error: 0.044322\n",
      "Iter #49000, error: 0.043836\n",
      "Iter #50000, error: 0.043366\n",
      "Iter #51000, error: 0.042910\n",
      "Iter #52000, error: 0.042468\n",
      "Iter #53000, error: 0.042039\n",
      "Iter #54000, error: 0.041622\n",
      "Iter #55000, error: 0.041218\n",
      "Iter #56000, error: 0.040825\n",
      "Iter #57000, error: 0.040442\n",
      "Iter #58000, error: 0.040070\n",
      "Iter #59000, error: 0.039708\n",
      "Iter #60000, error: 0.039356\n",
      "Iter #61000, error: 0.039012\n",
      "Iter #62000, error: 0.038677\n",
      "Iter #63000, error: 0.038350\n",
      "Iter #64000, error: 0.038031\n",
      "Iter #65000, error: 0.037720\n",
      "Iter #66000, error: 0.037416\n",
      "Iter #67000, error: 0.037119\n",
      "Iter #68000, error: 0.036829\n",
      "Iter #69000, error: 0.036545\n",
      "Iter #70000, error: 0.036268\n",
      "Iter #71000, error: 0.035997\n",
      "Iter #72000, error: 0.035731\n",
      "Iter #73000, error: 0.035471\n",
      "Iter #74000, error: 0.035217\n",
      "Iter #75000, error: 0.034968\n",
      "Iter #76000, error: 0.034723\n",
      "Iter #77000, error: 0.034484\n",
      "Iter #78000, error: 0.034249\n",
      "Iter #79000, error: 0.034019\n",
      "Iter #80000, error: 0.033793\n",
      "Iter #81000, error: 0.033572\n",
      "Iter #82000, error: 0.033355\n",
      "Iter #83000, error: 0.033141\n",
      "Iter #84000, error: 0.032932\n",
      "Iter #85000, error: 0.032726\n",
      "Iter #86000, error: 0.032524\n",
      "Iter #87000, error: 0.032325\n",
      "Iter #88000, error: 0.032130\n",
      "Iter #89000, error: 0.031938\n",
      "Iter #90000, error: 0.031750\n",
      "Iter #91000, error: 0.031564\n",
      "Iter #92000, error: 0.031382\n",
      "Iter #93000, error: 0.031202\n",
      "Iter #94000, error: 0.031026\n",
      "Iter #95000, error: 0.030852\n",
      "Iter #96000, error: 0.030681\n",
      "Iter #97000, error: 0.030513\n",
      "Iter #98000, error: 0.030347\n",
      "Iter #99000, error: 0.030184\n",
      "Iter #100000, error: 0.030023\n",
      "Iter #101000, error: 0.029865\n",
      "Iter #102000, error: 0.029709\n",
      "Iter #103000, error: 0.029555\n",
      "Iter #104000, error: 0.029403\n",
      "Iter #105000, error: 0.029254\n",
      "Iter #106000, error: 0.029107\n",
      "Iter #107000, error: 0.028961\n",
      "Iter #108000, error: 0.028818\n",
      "Iter #109000, error: 0.028677\n",
      "Iter #110000, error: 0.028538\n",
      "Iter #111000, error: 0.028400\n",
      "Iter #112000, error: 0.028265\n",
      "Iter #113000, error: 0.028131\n",
      "Iter #114000, error: 0.027999\n",
      "Iter #115000, error: 0.027868\n",
      "Iter #116000, error: 0.027740\n",
      "Iter #117000, error: 0.027612\n",
      "Iter #118000, error: 0.027487\n",
      "Iter #119000, error: 0.027363\n",
      "Iter #120000, error: 0.027241\n",
      "Iter #121000, error: 0.027120\n",
      "Iter #122000, error: 0.027001\n",
      "Iter #123000, error: 0.026883\n",
      "Iter #124000, error: 0.026766\n",
      "Iter #125000, error: 0.026651\n",
      "Iter #126000, error: 0.026537\n",
      "Iter #127000, error: 0.026425\n",
      "Iter #128000, error: 0.026313\n",
      "Iter #129000, error: 0.026204\n",
      "Iter #130000, error: 0.026095\n",
      "Iter #131000, error: 0.025987\n",
      "Iter #132000, error: 0.025881\n",
      "Iter #133000, error: 0.025776\n",
      "Iter #134000, error: 0.025672\n",
      "Iter #135000, error: 0.025570\n",
      "Iter #136000, error: 0.025468\n",
      "Iter #137000, error: 0.025367\n",
      "Final iteration #137008, error: 0.025366\n",
      "Coefficients: [-15.892972766578197, -6.112934470003568, -16.184604301187097, -18.07645807583095, -8.298408178705623, 7.488454860467905, 2.396122430415923, 2.2811211744460254, 10.663971441577972, -9.337033849895082, 14.081247982912737, 11.55654605368065, -10.8448151711147, -7.8729890499978, 12.915317493695351, 11.046327185678498, -4.741833814156054]\n"
     ]
    }
   ],
   "source": [
    "def learn_model( data, alpha, eps, verbose=False):\n",
    "    x,y = makeIndepDepData(data)\n",
    "    theta = [random.random()*2-1 for n in data[0]] # initialize Theta\n",
    "    lastErr = 0\n",
    "    err,yhat = logisticError(x, theta, y)\n",
    "\n",
    "    c = 0\n",
    "    while (abs(err-lastErr) > eps) and c<1e6:\n",
    "        if c % 1000 == 0 and verbose:\n",
    "            print('Iter #%u, error: %f'%(c,err))\n",
    "        theta = updateTheta(alpha, yhat, y, x, theta, err-lastErr)\n",
    "        lastErr = err\n",
    "        err,yhat = logisticError(x, theta, y)\n",
    "        if err > lastErr:\n",
    "            alpha /= 10\n",
    "        c += 1\n",
    "    \n",
    "    print('Final iteration #%u, error: %f' % (c-1,err) )\n",
    "    print('Coefficients: %s' % str(theta))\n",
    "    return theta\n",
    "\n",
    "\n",
    "train_data = generate_data( clean_data, 100, \"hills\")\n",
    "model = learn_model( train_data, 0.1, 1e-7, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred \"hills\" examples with balanced \"non hills\" examples and use this as your test data. Set labeled=True and generate results to use in `calculate_confusion_matrix`. Print out the first 10 results, one per line.\n",
    "\n",
    "**apply_model( model, test_data, labeled=False)**  \n",
    "Given a list of $\\theta$, calculate the predicted $\\hat{y}$ from the input data. If `labeled` is false, it returns tuples of predicated true/false as well as the actual probability. If not labeled, then return tuples of actual true/false and predicted true/false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = generate_data( clean_data, 100, \"hills\")\n",
    "\n",
    "def apply_model( model, test_data, labeled=False):\n",
    "    x,y = makeIndepDepData(test_data)\n",
    "    yhat = logistic(x, model)\n",
    "    pred = [1 if n > 0.5 else 0 for n in yhat]\n",
    "    if labeled:\n",
    "        return zip([int(round(n)) for n in y], pred)\n",
    "    else:\n",
    "        return zip(pred, yhat)\n",
    "\n",
    "results = apply_model( model, test_data, True)\n",
    "for n in range(10):\n",
    "    print results[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results above, show your confusion matrix for your model.\n",
    "\n",
    "**calculate_confusion_matrix(results)**  \n",
    "Given a labeled result from `apply_model(...)`, prints an html table of confusion matrix. Also prints out the error rate, true positive rate, and true negative rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>n = 200</td><td>Pred: False</td><td>Pred: True</td></tr><tr><td>Actual: False</td><td>97</td><td>3</td></tr><tr><td>Actual: True</td><td>2</td><td>98</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 2.5%\n",
      "True positive rate: 98.0%\n",
      "True negative rate: 97.0%\n"
     ]
    }
   ],
   "source": [
    "def calculate_confusion_matrix( results):\n",
    "    h = [[0,0], [0,0]]\n",
    "    for act,pred in results:\n",
    "        h[act][pred] += 1\n",
    "    t = [['n = %u'%len(results), 'Pred: False', 'Pred: True'],\n",
    "         ['Actual: False'] + h[0], ['Actual: True'] + h[1]]\n",
    "    s = '<table>%s</table>'%''.join(['<tr>%s</tr>'% ''.join(\n",
    "                ['<td>%s</td>'%str(x) for x in row]) for row in t])\n",
    "    print('')\n",
    "    display(HTML(s))\n",
    "\n",
    "    errRate = (h[0][1] + h[1][0] + 0.0) / len(results) * 100\n",
    "    tpRate = h[1][1] / (h[1][0] + h[1][1] + 0.0) * 100\n",
    "    tnRate = h[0][0] / (h[0][0] + h[0][1] + 0.0) * 100\n",
    "    print('Error rate: %.1f%%' % errRate)\n",
    "    print('True positive rate: %.1f%%' % tpRate)\n",
    "    print('True negative rate: %.1f%%' % tnRate)\n",
    "\n",
    "calculate_confusion_matrix(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
