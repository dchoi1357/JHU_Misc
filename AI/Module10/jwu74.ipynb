{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10 - Programming Assignment (Summer)\n",
    "\n",
    "## Directions\n",
    "\n",
    "There are general instructions on Blackboard and in the Syllabus for Programming Assignments. This Notebook also has instructions specific to this assignment. Read all the instructions carefully and make sure you understand them. Please ask questions on the discussion boards or email me at `EN605.445@gmail.com` if you do not understand something.\n",
    "\n",
    "<div style=\"background: mistyrose; color: firebrick; border: 2px solid darkred; padding: 5px; margin: 10px;\">\n",
    "You must follow the directions *exactly* or you will get a 0 on the assignment.\n",
    "</div>\n",
    "\n",
    "You must submit *only* your IPython notebook to Blackboard. It should be cleanly executed and named:\n",
    "\n",
    "```\n",
    "<jhed_id>.ipynb\n",
    "```\n",
    "\n",
    "An HTML version of the notebook will be generated and graded and the notebook will be used only for reference. To see what the HTML version of your notebook will look like, apply the following command:\n",
    "\n",
    "> ipython nbconvert <jhed_id>.ipynb\n",
    "\n",
    "or use the File menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Last week we left our agent with a simple logistic regression that it could use to classify a picture from its cheap visual \"sensor\" as hills or not hills. We *could* make a logistic regression for each train type (hills/not hills, plains/not plains, swamp/not swamp, forest/not forest) and pick the one with the largest probability but that's exactly the kind of a problem a Multi-Layer Perceptron (MLP) Artificial Neural Network (ANN) was designed to solve.\n",
    "\n",
    "Here are the \"pure\" images again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAFzCAYAAAC+dom9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2da524250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random, math\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray', interpolation='None')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray', interpolation='None')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray', interpolation='None')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "For this programming assignment your tasks are:\n",
    "\n",
    "1. Write an ANN regression that simply determines what kind of terrain it is. This is a multi-class problem.\n",
    "2. You will also evaluate your model for at least 3 different numbers of nodes in the hidden layer (2, 4, 8) and determine which one has the lowest *error rate*.\n",
    "\n",
    "For a starting point, you can refer to **module-10-pseudocode.pdf** and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As before, we have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray', interpolation='None')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8DCzLA4PM8vi8DCzLA4PM8vy/0VZaizWdRVNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2da030ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw8yyODzMLMv/Az1729WY2nOjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2da2fc110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2da239350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "4. `generate_validation_curves`\n",
    "\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, an ANN that determines if a sensor image is hills, swamp, forest or plains.\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes for each class. This means you should probably generate training data with, say, 100 of each type.\n",
    "\n",
    "But what do we do about the class label with the neural network?\n",
    "\n",
    "In this case, we can do \"one hot\". Instead of `generate_data` outputing a single 0 or 1, it should output a vector of 0's and 1's so that $y$ is now a vector as well as $x$. We can use the first position for hill, the second for swamp, the third for forest and the fourth for plains:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "what am I? swamp.\n",
    "\n",
    "Unlike logistic regression, you should set the *biases* inside the neural network (the implict $x_0$ = 1) because there are going to be lot of them (one for every hidden and output node).\n",
    "\n",
    "`generate_data` now only needs to take how many you want of each class:\n",
    "\n",
    "`generate_data( clean_data, 100)`\n",
    "\n",
    "generates 100 hills, 100 swamp, 100 forest, 100 plains and transforms $y$ into the respective \"one hot\" encoding.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the ANN. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "You should add a parameter to indicate how many nodes the hidden layer should have.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller.\n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the neural network. The hidden layer will be one vector of thetas for each hidden node. And the output layer will have its own thetas, one for each output (4 in this case). Return it as a Tuple: (List of List, List of List).\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes the ANN (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a List of Tuples of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19) so you have [(0, 0.30), (1, 0.98), (0, 0.87), (0, 0.12)]. Note that unlike the logistic regression, the threshold for 1 is not 0.5 but which value is largest (0.98 in this case).\n",
    "\n",
    "If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1). For a single data point, you'll have the pairs of actual values [(0, 1), (0, 0), (0, 0), (1, 0)] is a misclassification and [(0, 0), (0, 0), (1, 1), (0, 0)] will be a correct classification. Then you have a List of *those*, one for each observation.\n",
    "\n",
    "### `generate_validation_curves`\n",
    "\n",
    "The `generate_validation_curves` is going to be a bit different than the confusion matrix version last week. It should take the information required to plot validation curves over the train and test sets for the specified parameter values.\n",
    "\n",
    "So basically, you have:\n",
    "\n",
    "1. generate training set\n",
    "2. generate test set\n",
    "3. loop over [2, 4, 8]\n",
    "    1. train model and apply to train data, calculate error rate.\n",
    "    2. apply to test data and calculae error rate.\n",
    "    3. plot both curves.\n",
    "\n",
    "The net results should be one plot of 2 curves over 3 parameter values. Please state in a markdown field afterwards which number of hidden nodes had the lowest error rate.\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (and not to be modifying a copy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions\n",
    "\n",
    "**sigm(x)**  \n",
    "Given a matrix x , calculate the logistic function for each element of the matrix.  \n",
    "$$ \\hat{y}= \\frac{1}{1+e^{-\\mathbf{-x}}} $$\n",
    "\n",
    "**mmult(\\*args)**  \n",
    "Perform element-wise multiplication of the matrices $x[n]$ in the the parameter such that the elements of the output matrix $m_{i,j}$:\n",
    "\n",
    "$$m_{i,j} = \\prod_{n} x[n]_{i,j}$$\n",
    "\n",
    "**feedForward(x, wtHidd, wtOut)**  \n",
    "Given hidden and output layer weights and in matrix form, calculate the $\\hat{y}$ for the hidden nodes and output nodes through matrix multiplication. \n",
    "$$\\hat{y} =logistic[{\\sum_i{\\theta_i x_i}}]$$\n",
    "\n",
    "Returns the output in matrix format.\n",
    "\n",
    "**ffbp(data, wtHidd, wtOut, a)**  \n",
    "The algorithm performs feed-forward back-propagation algorithm. Takes as input a matrix array of input vectors, where the first n elements are the value of the input nodes with a 1 for bias, and the last elements are the actual values. The algorithm first performs the two-layer feedforward. With the error, it calculates the changes to the weights of the output layer and hidden layer. Returns the change to the weights as well as the errors of the network such that:\n",
    "\n",
    "$$\\delta^o = \\hat{y} (1-\\hat{y}) (y-\\hat{y})$$\n",
    "$$\\delta^o = \\hat{y} (1-\\hat{y}) \\sum_i{\\theta^{i,o} \\delta^{i,o}}$$\n",
    "$$Err(\\mathbf{x},\\mathbf{\\theta},\\mathbf{y})=-\\frac{1}{n}\\sum_i\ty_i\tlog(\\hat{y_i}) + (1\t- y_i)log(1\t- \\hat{y_i})$$\n",
    "\n",
    "**initTheta(dataDim, nHidd, nOut, xMax)**  \n",
    "Initialize the weights such that the output of the individual nodes land between -5 and 5 so that the gradients are not flat.\n",
    "\n",
    "**errorRate(labeldResult)**  \n",
    "Given an input of labeled result data, calculate the error rate where the predicated classification is different from the actual classification. $$\\frac{\\sum_i^n{I_{[c\\neq\\hat{c}]}(\\theta,x)}}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terrainList = ['hills', 'swamp' ,'forest' , 'plains']\n",
    "\n",
    "def sigm(x):\n",
    "    return 1.0 / ( 1 + np.exp(-x) )\n",
    "\n",
    "def mmult(*args):\n",
    "    return reduce(np.multiply, args)\n",
    "\n",
    "def feedForward(x, wtHidd, wtOut):\n",
    "    yHatHidd = np.vstack(( sigm(wtHidd * x), np.matrix(1) ))\n",
    "    yHat = sigm(wtOut * yHatHidd)\n",
    "    return yHatHidd, yHat\n",
    "\n",
    "def ffbp(data, wtHidd, wtOut, a):\n",
    "    x, y = np.split( data.T, [-4])\n",
    "    yHatHidd, yHat = feedForward(x, wtHidd, wtOut)\n",
    "    \n",
    "    deltaOut = mmult(y-yHat, 1-yHat, yHat)\n",
    "    outChg = (a * deltaOut) * yHatHidd.T\n",
    "    \n",
    "    deltaHidd = mmult(1-yHatHidd, yHatHidd, (deltaOut.T * wtOut).T)\n",
    "    hiddChg = (a * deltaHidd[:-1]) * x.T\n",
    "    err = -(y.T*np.log(yHat) + (1-y).T*np.log(1-yHat)) / len(y)\n",
    "    \n",
    "    return outChg, hiddChg, float(err)\n",
    "\n",
    "def initTheta(dataDim, nHidd, nOut, xMax):\n",
    "    hidden = (np.random.rand(nHidd, dataDim-nOut)) *xMax / (dataDim-nOut)\n",
    "    outter = (np.random.rand(nOut, nHidd+1)) * xMax / nHidd\n",
    "    return np.matrix(hidden), np.matrix(outter)\n",
    "\n",
    "def errorRate(labeldResult):\n",
    "    discord = sum([1 if pred!=act else 0 for pred,act in labeldResult])\n",
    "    return discord / (len(labeldResult)+0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Put your helper functions above here.\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 10 blurred \"hills\" examples with balanced (same number of) \"non hills\" examples to see that the function is working.\n",
    "\n",
    "**generate_data( data, n)**  \n",
    "Generate n blurred data points for each category of terrains by randomly choosing instances of data points within that category. Shuffle the results so that the terrains are randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07816084  0.05568035  0.11798945  0.04177141  0.02667341  0.08287283\n",
      "   0.79886617  0.14286324  0.12435166  0.80063875  0.82674614  0.93316699\n",
      "   1.          0.78507538  0.89670375  0.75913367  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.05928444  0.03368247  0.07393702  0.1062142   0.06799432  0.14766701\n",
      "   0.07735414  0.11263209  0.93383582  0.08901511  1.          0.14611399\n",
      "   0.94602592  0.74984311  0.98018801  0.95215234  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.03051399  0.09379177  0.12118087  0.08548744  0.14175614  0.02933583\n",
      "   0.10208636  0.15409446  0.07295571  0.02224191  0.07520018  0.12614161\n",
      "   0.88437739  0.85251149  0.85561854  0.77077151  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.12116669  0.03308374  0.14359761  0.06809919  0.11959726  0.0562735\n",
      "   0.11869147  0.0248035   0.13490882  0.15121583  0.13448605  0.12050358\n",
      "   0.93626667  1.          0.7536046   1.          1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.08504401  0.19504668  0.04260081  0.09198581  0.1068198   0.14786577\n",
      "   0.81935584  0.12189831  0.1326648   0.8174065   0.81259526  0.95551189\n",
      "   1.          0.81807828  0.59349569  1.          1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.          0.24382153  0.05579484  0.04237407  0.16738103  0.14129254\n",
      "   0.07466116  1.          0.13966059  0.14246563  0.79982249  0.75825079\n",
      "   0.11656643  0.92918983  0.86438889  0.89494486  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.10492669  0.09534134  0.0893588   0.24195118  0.04719365  0.01656132\n",
      "   0.04548497  0.89312375  0.07568607  0.03061959  0.89811813  0.88085171\n",
      "   0.06180986  1.          0.7582104   0.88923273  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.20388392  0.16660367  0.14672745  0.          0.13967779  0.0699684\n",
      "   0.14927651  0.07610592  0.89107804  0.10592692  0.86414605  0.08033506\n",
      "   0.85611174  1.          1.          0.84140486  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.08258586  1.          0.0311795   0.10108457  1.          0.94625258\n",
      "   0.99476332  0.09314231  0.84532356  0.83157423  0.87488526  0.96276687\n",
      "   0.1401116   0.75497502  0.11888049  0.14198969  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.10541283  0.11498984  0.01905177  0.13068267  0.0920664   0.09622517\n",
      "   0.14707841  1.          0.15433888  0.14918099  0.8835859   1.\n",
      "   0.10692978  0.90295558  0.97329535  0.85704591  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.09902445  0.13916006  0.07346251  0.0233417   0.14544324  0.09134713\n",
      "   0.          0.16323863  0.14139066  0.11871013  0.04337926  0.12187851\n",
      "   0.96242288  0.86848767  0.96502035  0.79978079  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 1.          0.09233207  0.11388166  0.13863713  0.91529392  1.\n",
      "   0.06344675  0.02906746  0.82308035  0.85185982  0.73408189  0.06455397\n",
      "   0.87932166  0.06380184  0.23817273  0.13516042  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.06162894  0.05889055  0.1403195   0.79125563  0.10890703  0.0454434\n",
      "   1.          0.91185426  0.09032721  0.92016366  0.85470486  0.8771419\n",
      "   0.09557836  0.06879754  0.06039338  0.87377157  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.08937179  0.06543885  0.94474955  0.11194316  0.04577686  0.69750214\n",
      "   0.76104616  0.94198786  0.84908481  0.82982548  1.          1.\n",
      "   0.07187735  0.13936767  0.94611235  0.06965054  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.14791125  0.18777776  0.15778356  0.06158221  0.06649967  0.86629161\n",
      "   0.          0.16108373  0.58140638  0.83250961  0.90344266  0.10810245\n",
      "   1.          0.81049253  0.91690727  0.80667152  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.07194214  0.15799172  0.08727127  0.13607657  0.11421641  0.93694691\n",
      "   0.07818979  0.17976095  0.8504278   1.          1.          0.11277091\n",
      "   0.83944373  1.          1.          0.9504749   1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.05351418  1.          0.10323512  0.04757227  1.          0.99647602\n",
      "   0.93065318  0.05458779  0.85545328  1.          1.          0.90311488\n",
      "   0.          0.79124963  0.12009479  0.12177104  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.15558538  0.08831743  0.1029053   0.          0.11908225  0.\n",
      "   0.99247185  0.08766586  0.09626857  1.          0.68658464  1.\n",
      "   0.84457763  0.96460852  0.80743939  0.86524604  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.06656844  0.12104317  0.020584    0.21607433  0.05834031  0.06795972\n",
      "   0.10866709  0.07387473  0.0904116   0.07718772  0.18001555  0.1721637\n",
      "   0.7318558   0.85257962  0.79285689  0.96615978  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.11263199  0.18342287  0.08332341  0.17771333  0.09544449  0.11123087\n",
      "   0.14671625  0.0964838   0.12430647  0.0993384   0.18785252  0.06586041\n",
      "   1.          0.88955057  0.79253841  0.99500359  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.09274876  0.05362253  0.01896788  0.06484735  0.06117763  0.13123822\n",
      "   0.13288304  0.06841438  0.06494538  0.10817402  0.06768652  0.12032049\n",
      "   0.92307249  1.          0.95557381  0.88803307  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.11701465  0.07779742  0.93419326  0.07815066  0.1162571   0.77252396\n",
      "   0.86232532  0.9573756   0.80121961  0.92366632  0.78582665  0.75153255\n",
      "   0.11348207  0.02101544  0.84552605  0.07158695  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[  1.39280183e-01   1.23894642e-01   3.87088140e-02   1.26239389e-01\n",
      "    5.69907675e-02   0.00000000e+00   9.00111622e-04   1.06337041e-02\n",
      "    3.63337037e-02   6.86480006e-02   0.00000000e+00   6.16909213e-02\n",
      "    8.34451585e-01   9.49454934e-01   9.89047697e-01   7.48951087e-01\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00]]\n",
      "[[ 0.02917693  0.13932825  0.10390145  0.01975379  0.08024618  0.20965111\n",
      "   0.07622225  0.13941572  0.85581021  0.11721353  0.80020123  0.0704993\n",
      "   1.          1.          0.74689516  0.9509817   1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.06339781  0.2370959   0.72661078  0.09101851  0.11059145  0.99493089\n",
      "   0.95880369  0.99109423  1.          1.          0.92281544  0.89426808\n",
      "   0.00488358  0.05457453  1.          0.11679793  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.10243531  0.05662909  0.1597862   0.10506549  0.08302742  0.11488549\n",
      "   0.06523448  0.02794671  0.11524766  0.93768109  0.1799074   0.92140157\n",
      "   0.71380419  0.82234384  0.97594251  0.88601036  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.10695096  0.12094234  0.          0.10070868  0.12655755  0.14412767\n",
      "   0.15285872  0.07137989  0.8141815   0.11566363  0.83707381  0.09800594\n",
      "   0.65517276  1.          0.91744561  0.80102588  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.02154049  0.07649698  0.03187013  0.12567789  0.0688084   0.0630734\n",
      "   0.13919203  0.1733857   0.83473801  0.01335979  0.98557197  0.\n",
      "   0.82480337  1.          0.90427443  0.93385151  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[  1.47223746e-01   5.42639455e-02   9.25776974e-02   3.34799280e-02\n",
      "    9.75919043e-04   1.26921387e-01   2.72905101e-02   1.34029691e-01\n",
      "    6.25326476e-01   1.68628340e-01   8.13125919e-01   8.66770780e-02\n",
      "    9.55344011e-01   8.43202445e-01   9.11270813e-01   7.37848665e-01\n",
      "    1.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]]\n",
      "[[ 0.78801148  0.05978861  0.01693527  0.11581129  0.85467225  0.91345725\n",
      "   0.19831163  0.25871541  1.          1.          0.84934925  0.17044328\n",
      "   1.          0.14175253  0.13669525  0.04737896  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.06365343  0.791105    0.12805482  0.17168728  0.86543123  0.84224057\n",
      "   1.          0.14409368  0.926087    0.88149489  0.93638573  0.8883158\n",
      "   0.11974028  0.9222253   0.03873127  0.08624913  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.1422161   0.1051321   0.01958087  0.15761754  0.06542148  0.06793193\n",
      "   0.          0.07896435  0.15114176  0.05402103  0.08078209  0.17656804\n",
      "   0.91117646  0.79550448  0.84584078  0.7998312   1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.0863558   0.10141932  0.15136119  0.09166791  0.08583148  0.08919172\n",
      "   0.10131431  0.04198678  0.85604828  0.10372273  1.          0.13626611\n",
      "   0.93577782  0.77867249  0.81190009  1.          1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.11070557  0.06021516  0.14072853  0.14942754  0.1338083   0.00361186\n",
      "   0.26542015  0.11303243  0.08951187  0.91569533  0.07642514  0.71211575\n",
      "   0.88819053  1.          0.92896264  1.          1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.08271117  0.17040255  0.12074051  0.67346387  0.14638025  0.11805191\n",
      "   0.98721227  0.77664618  0.00536676  0.82497877  0.79837989  0.82547474\n",
      "   0.08222012  0.07335646  0.12998465  0.78708811  1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "[[ 0.05737327  0.12633312  0.05772807  0.05497107  0.08296804  0.09951777\n",
      "   0.08218496  0.10793388  1.          0.20697372  1.          0.11364613\n",
      "   0.75272063  1.          0.97451439  0.9232932   1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.08984175  0.16126558  0.13771581  0.14481693  0.09662391  0.12557425\n",
      "   0.05239938  0.94643041  0.11089817  0.14550802  0.91093741  0.77479427\n",
      "   0.10480465  0.89414802  0.91300571  0.94413239  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.1222588   0.02760966  0.07264692  0.13741827  0.08140194  0.16129896\n",
      "   0.09514041  0.14319244  0.06473823  0.0541926   0.05925138  0.09540375\n",
      "   0.9208716   0.91335455  0.81934328  0.91069817  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.02205756  0.14097483  0.10619692  0.09961302  0.07448677  0.1174011\n",
      "   0.14123674  0.17382987  0.06593148  0.05198877  0.04769596  0.18922012\n",
      "   0.96614727  0.82668683  0.88738776  1.          1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.20449524  0.07837125  0.10420023  0.13880991  0.10113632  0.85088394\n",
      "   0.09778646  0.12862552  0.91639267  0.92435804  0.77718973  0.09342113\n",
      "   0.98562409  0.87901752  0.93807194  0.95629125  1.          1.          0.\n",
      "   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def generate_data( data, n):\n",
    "    out = list()\n",
    "    for idx,tp in enumerate(terrainList):\n",
    "        for c in xrange(n):\n",
    "            x = blur(data[tp][random.randrange(len(data[tp]))])\n",
    "            y = [1 if i==idx else 0 for i in xrange(4)]\n",
    "            out.append(np.matrix( x[:-1] + [1] + y ))\n",
    "    random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "results = generate_data( clean_data, 10)\n",
    "for result in results:\n",
    "    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a ANN model for classifying sensor images as hills, swamps, plains or forest. Use your `generate_data` function to generate a training set with 100 examples for each. **Set Verbose to True**\n",
    "\n",
    "**learn_model( data, nHidd, alpha, eps, verbose=False)**  \n",
    "Train the neural network by adjusting hidden and output layer weights. The program performs the feed-foward back-propagation algorithm by looping through all the data points in the data set. The algorithm runs until either\n",
    "1. the successive errors is less than $\\epsilon$ as specified in the parameter\n",
    "1. less than 20 rounds of training has happened\n",
    "1. error reaches less than 0.02\n",
    "1. less than 3 error increases in the last 5 rounds\n",
    "\n",
    "$\\alpha$ gets divided by 1.5 if there are more than 3 error increases in the last 5 rounds as long as $\\alpha$ is more than 0.05.\n",
    "\n",
    "If `verbose` is set to True, it prints the error and $\\alpha$ every 5 rounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round #0, error: 0.103195, alpha: 2.000000\n",
      "Round #5, error: 0.059938, alpha: 2.000000\n",
      "Round #10, error: 0.092054, alpha: 2.000000\n",
      "Round #15, error: 0.086839, alpha: 0.888889\n",
      "Final round #19, error: 0.067616, alpha: 0.263374\n"
     ]
    }
   ],
   "source": [
    "def learn_model( data, nHidd, alpha, eps, verbose=False):\n",
    "    wtHidd, wtOut = initTheta(data[0].shape[1], nHidd, 4, 0.5)\n",
    "\n",
    "    rd = 0\n",
    "    errDiff = np.zeros(10)\n",
    "    err, lastErr = 1, 0\n",
    "    while abs(err-lastErr) > eps and rd<30 and err>0.02 and \\\n",
    "        (errDiff[:5] > 0).sum() <= 3:\n",
    "        lastErr = err\n",
    "        for n,d in enumerate(data):\n",
    "            wtOutChg, wtHiddChg, err = ffbp(d, wtHidd, wtOut, alpha)\n",
    "            wtOut, wtHidd = (wtOut+wtOutChg, wtHidd+wtHiddChg) # update weights\n",
    "        errDiff = np.hstack( (err-lastErr, errDiff[:-1]) )\n",
    "        if (errDiff>0).sum() > 3 and alpha > 0.05:\n",
    "            alpha = (alpha/1.5)\n",
    "        \n",
    "        if rd%5==0 and verbose: # print every 50\n",
    "            print('Round #%u, error: %f, alpha: %f'%(rd,err,alpha))\n",
    "        rd += 1\n",
    "        \n",
    "    print('Final round #%u, error: %f, alpha: %f' % (rd,err, alpha) )\n",
    "    return wtHidd.tolist(), wtOut.tolist()\n",
    "\n",
    "\n",
    "train_data = generate_data( clean_data, 100)\n",
    "model = learn_model( train_data, 2, 2, 1e-7, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each terrain and use this as your test data. Print out the first 10 results, one per line.\n",
    "\n",
    "**apply_model( model, test_data, labeled=False)**  \n",
    "Given two sets of $\\theta$, calculate the predicted output layer $\\hat{y}$ from the input data. For each set of outputs, find the index of the highest probability and the calssification of the terrain based on it. If `labeled` is false, it returns tuples of predicated classification as well as the highest probability. If labeled, then return tuples of actual classification and predicted classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22229888  0.14102788  0.07236336  0.05422195  0.0441275   0.15366904\n",
      "   1.          0.07720752  0.0112161   0.91324961  0.94207268  0.84130131\n",
      "   0.92804405  0.91940683  0.91658458  0.95905144  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.07927123  0.15000461  0.04932453  0.08896673  0.1785252   0.03080604\n",
      "   0.07787041  0.0592698   0.83915941  0.14600686  0.92881395  0.02352398\n",
      "   0.85559033  1.          0.9926231   0.97240795  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.16636736  0.06008912  0.17966122  0.26393172  0.10286862  0.10236926\n",
      "   0.10104248  0.08866445  0.04882229  0.01043191  0.13468809  0.09749608\n",
      "   0.7954086   0.83460157  0.85887267  0.76154223  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.18346198  0.17180483  0.04878709  0.08448029  0.15966097  0.11932429\n",
      "   0.07039341  0.13673704  0.15713047  0.03636245  0.05861221  0.06902607\n",
      "   0.95591848  0.94146373  0.78857355  0.95377103  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.03447127  0.0959661   0.1068395   0.18961439  0.83119624  0.05299729\n",
      "   0.05977671  0.16179218  1.          1.          0.10829582  0.15901587\n",
      "   0.86587137  0.85430452  0.98781962  0.08571163  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.04029444  0.05162064  0.00348548  0.05904194  0.12972296  0.16988275\n",
      "   0.11339715  0.93624526  0.10797823  0.05471335  0.88156581  0.9692407\n",
      "   0.07302701  0.94115054  0.87025591  0.80527923  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.11874464  0.06229584  0.06276769  0.01085453  0.11764716  0.12532389\n",
      "   0.06224726  0.09227885  0.1092301   0.12188113  0.01842193  0.10383152\n",
      "   0.83786216  0.89728346  0.86830672  0.87915811  1.          0.          0.\n",
      "   0.          1.        ]]\n",
      "[[ 0.10232878  0.12521995  0.05819614  0.0975349   0.13690154  0.14650213\n",
      "   0.08942885  0.09205126  0.93971136  0.0766305   0.88128382  0.09438617\n",
      "   0.7344164   0.93330055  1.          0.90350381  1.          0.          1.\n",
      "   0.          0.        ]]\n",
      "[[ 0.04747448  0.12909517  0.09322914  0.          0.98328421  0.14356232\n",
      "   0.11049933  0.13166695  0.83377876  0.8412022   0.16295759  0.0938208\n",
      "   0.72549179  0.87895021  0.76490966  0.05951987  1.          1.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 0.05023658  0.17104342  0.16418333  0.8980116   0.12684505  0.13206119\n",
      "   0.86915445  0.79999679  0.10462094  0.87533156  0.90087939  0.77013911\n",
      "   0.07300486  0.04442898  0.1187123   0.7127217   1.          0.          0.\n",
      "   1.          0.        ]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "test_data = generate_data( clean_data, 100)\n",
    "for x in xrange(10):\n",
    "    print test_data[x]\n",
    "\n",
    "\n",
    "def apply_model( model, test_data, labeled=False):\n",
    "    wtHidd, wtOut = np.matrix(model[0]), np.matrix(model[1])\n",
    "    categ, prob, actual = list(), list(), list()\n",
    "    for n, d in enumerate(test_data):\n",
    "        x, y = np.split( d.T, [-4])\n",
    "        yHat = feedForward(x, wtHidd, wtOut)[1]\n",
    "        prob.append(yHat.max())\n",
    "        categ.append(yHat.argmax())\n",
    "        actual.append(y.argmax())\n",
    "        \n",
    "    if labeled:\n",
    "        return zip(categ, actual)\n",
    "    else:\n",
    "        return zip(categ, prob)\n",
    "\n",
    "\n",
    "results = apply_model( model, test_data)\n",
    "#print results\n",
    "print sum([1 if x[0]==x[1] else 0 for x in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're pretty sure your algorithm works (the error rate during training is going down, and you can evaluate `apply_model` results for its error rate, learn validation curves:\n",
    "\n",
    "**generate_validation_curves(hyperParm, data)**  \n",
    "Plots the validation curves for both training and testing data. The `hyperParm` input is the number of nodes in the hidden layer. The function plots both the training error rate and the testing error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_curves(hyperParm, data):\n",
    "    plt.plot(hyperParm, zip(*data)[0], label='Training Data')\n",
    "    plt.plot(hyperParm, zip(*data)[1], label='Testing Data')\n",
    "    plt.legend(loc=0)\n",
    "    plt.axis([min(hyperParm)-0.2, max(hyperParm)+0.2, -0.1, 1.05])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final round #8, error: 0.051651, alpha: 1.333333\n",
      "Final round #7, error: 0.019238, alpha: 2.000000\n",
      "Final round #6, error: 0.018590, alpha: 2.000000\n",
      "Final round #7, error: 0.018848, alpha: 2.000000\n",
      "Final round #5, error: 0.019129, alpha: 2.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD7CAYAAAClvBX1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2da3c2b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = generate_data( clean_data, 100)\n",
    "test  = generate_data( clean_data, 100)\n",
    "\n",
    "hyperParm = [2, 3, 4, 6, 8]\n",
    "valCurveData = list()\n",
    "for n in hyperParm:\n",
    "    model = learn_model( train, n, 2, 1e-7, False)\n",
    "    train_results = apply_model( model, train, True)\n",
    "    test_results = apply_model( model, test, True)\n",
    "    valCurveData.append(( errorRate(train_results),errorRate(test_results) ))\n",
    "\n",
    "generate_validation_curves(hyperParm, valCurveData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which number of hidden nodes is best? generally the more the better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
