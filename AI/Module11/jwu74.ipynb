{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "There are general instructions on Blackboard and in the Syllabus for Programming Assignments. This Notebook also has instructions specific to this assignment. Read all the instructions carefully and make sure you understand them. Please ask questions on the discussion boards or email me at `EN605.445@gmail.com` if you do not understand something.\n",
    "\n",
    "<div style=\"background: mistyrose; color: firebrick; border: 2px solid darkred; padding: 5px; margin: 10px;\">\n",
    "You must follow the directions *exactly* or you will get a 0 on the assignment.\n",
    "</div>\n",
    "\n",
    "You must submit a zip file of your assignment and associated files (if there are any) to Blackboard. The zip file will be named after you JHED ID: `<jhed_id>.zip`. It will not include any other information. Inside this zip file should be the following directory structure:\n",
    "\n",
    "```\n",
    "<jhed_id>\n",
    "    |\n",
    "    +--module-01-programming.ipynb\n",
    "    +--module-01-programming.html\n",
    "    +--(any other files)\n",
    "```\n",
    "\n",
    "For example, do not name  your directory `programming_assignment_01` and do not name your directory `smith122_pr1` or any else. It must be only your JHED ID. Make sure you submit both an .ipynb and .html version of your *completed* notebook. You can generate the HTML version using:\n",
    "\n",
    "> ipython nbconvert [notebookname].ipynb\n",
    "\n",
    "or use the File menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add whatever additional imports you require here. Stick with the standard libraries and those required by the class. The import\n",
    "gives you access to these functions: http://ipython.org/ipython-doc/stable/api/generated/IPython.core.display.html (Copy this link)\n",
    "Which, among other things, will permit you to display HTML as the result of evaluated code (see HTML() or display_html())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division # so that 1/2 = 0.5 and not 0\n",
    "from IPython.core.display import *\n",
    "import numpy as np\n",
    "import copy, math, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "You can download the two files and read them to find out the attributes, attribute values and class labels as well as their locations in the file.\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. In C4.5, missing values were handled by treating \"?\" as an implicit attribute value for every feature. For example, if the attribute was \"size\" then the domain would be [\"small\", \"medium\", \"large\", \"?\"]. Another approach is to skip instances with missing values. Yet another approach is to infer the missing value conditioned on the class. For example, if the class is \"safe\" and the color is missing, then we would infer the attribute value that is most often associated with \"safe\", perhaps \"red\". **Use the \"?\" approach for this assignment.**\n",
    "\n",
    "As we did with the neural network, you should randomize your data (always randomize your data...you don't know if it is in some particular order like date of collection, by class label, etc.) and split it into two (2) sets. Train on the first set then test on the second set. Then train on the second set and test on the first set.\n",
    "\n",
    "For regression, we almost always use something like Mean Squared Error to judge the performance of a model. For classification, there are a lot more options but for this assignment we will just look at classification error:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "You must implement four functions. `train` takes training_data and returns the Decision Tree as a data structure or object (for this one, I'm removing the OOP restriction...people often feel more comfortable writing a Tree in an OOP fashion). Make sure your Tree can be represented somehow.\n",
    "\n",
    "```\n",
    "def train( training_data):\n",
    "   # returns a decision tree data structure\n",
    "```\n",
    "\n",
    "and `view` takes a tree and prints it out:\n",
    "\n",
    "```\n",
    "def view( tree):\n",
    "    pass # probably doesn't return anything.\n",
    "```\n",
    "\n",
    "the purpose of the function is to be able to see what the tree looks like. It should be legible/pretty. You can use ASCII if you like or use something like NetworkX.\n",
    "\n",
    "and `classify` takes a tree and a List of instances (possibly just one) and returns the classifications:\n",
    "\n",
    "```\n",
    "def classify( tree, test_data):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "and `evaluate` takes the classifications and the test_data and returns the error rate:\n",
    "\n",
    "```\n",
    "def evaluate( test_data, classifications):\n",
    "    # returns an error rate\n",
    "```\n",
    "\n",
    "Basically, you're going to:\n",
    "\n",
    "1. learn the tree for set 1\n",
    "2. view the tree\n",
    "3. classify set 2\n",
    "4. evaluate the tree\n",
    "5. learn the tree for set 2\n",
    "6. view the tree\n",
    "7. classify set 1\n",
    "8. evalute the tree\n",
    "9. average the classification error.\n",
    "\n",
    "This is all that is required for this assignment. I'm leaving more of the particulars up to you but you can definitely use the last module as a guide.\n",
    "\n",
    "**This is a very important assignment to reflect on the use of deepcopy because it has a natural recursive implementation**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Decision Tree class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DTnode:\n",
    "    def __init__(self, attrib):\n",
    "        self.attrib = attrib\n",
    "        self.isLeaf = True\n",
    "        self.children = dict()\n",
    "\n",
    "    def addChild(self, node, val):\n",
    "        self.isLeaf = False\n",
    "        self.children[val] = node\n",
    "        \n",
    "    def getChild(self, val):\n",
    "        return self.children[val]\n",
    "    \n",
    "    def getValues(self):\n",
    "        return set(self.children.keys())\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.isLeaf:\n",
    "            childTxt = 'terminal'\n",
    "        else:\n",
    "            childTxt = 'child: ' + str(list(self.children.keys()))\n",
    "        return '[Node for %s, %s ]'%(self.attrib, childTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def Hlog2(pr):\n",
    "    out = np.zeros(pr.shape)\n",
    "    z = np.logical_or(pr==0,pr==1)\n",
    "    out[~z] = np.log2(pr[~z])\n",
    "    return out\n",
    "\n",
    "def H(d, A):\n",
    "    vals, N = np.unique(d[A], return_counts=True)\n",
    "    p = N/d.size\n",
    "    return -np.sum( p*Hlog2(p) )\n",
    "\n",
    "def B(p):\n",
    "    return 0 if p==1 or p==0 else -(p*np.log2(p) + (1-p)*np.log2(1-p))\n",
    "\n",
    "def edibleProb(d):\n",
    "    return np.count_nonzero(d['class']=='e') / d.size\n",
    "    \n",
    "def Remainder(d, Attr):\n",
    "    vals,N = np.unique(d[Attr], return_counts=True )\n",
    "    entropies = [B(edibleProb(d[d[Attr]==v])) for v in vals]\n",
    "    return np.sum(N/d.size * entropies)\n",
    "\n",
    "def Importance(d, attribs):\n",
    "    entropy = B(edibleProb(d))\n",
    "    #print(entropy)\n",
    "    gains = list(zip(*[(entropy - Remainder(d,A),A) for A in attribs]))\n",
    "    return gains[1][np.argmax(gains[0])], np.max(gains[0])\n",
    "\n",
    "def readCSV(filePath):\n",
    "    with open(filePath, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        l = list(reader)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def id3(d, attribs, default):\n",
    "    if d.size == 0: # empty data\n",
    "        return DTnode(default)\n",
    "    prEd = edibleProb(d)\n",
    "    majority = 'e' if prEd > 0.5 else 'p'\n",
    "    if prEd in [0,1] or len(attribs)==0: # homogenous or no attribs left\n",
    "        return DTnode(majority) \n",
    "    \n",
    "    bestAttr, gain = Importance(d, attribs)\n",
    "    attribSubset = attribs - set([bestAttr])\n",
    "    nd = DTnode(bestAttr) # new node at the best attribute\n",
    "    for v in set(d[bestAttr]):\n",
    "        child = id3(d[d[bestAttr]==v], attribSubset, majority)\n",
    "        nd.addChild(child, v)\n",
    "    return nd\n",
    "\n",
    "def train(data):\n",
    "    return id3(data, attribSet, 'e' if edibleProb(data) > 0.5 else 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def view(tree):\n",
    "    def toStr(nd, level=0):\n",
    "        if nd.isLeaf:\n",
    "            return 'class: %s\\n' % nd.attrib\n",
    "        else:\n",
    "            ret = 'Attribute [' + nd.attrib + \"]:\\n\"\n",
    "            nx = level + 1\n",
    "            for key in nd.children:\n",
    "                ret += \"\\t\"*nx + 'val=%s, '%key + toStr(nd.children[key],nx)\n",
    "            return ret\n",
    "    \n",
    "    print(toStr(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, data):\n",
    "    def recurClass(d, nd, idx, res):\n",
    "        if nd.isLeaf:\n",
    "            res[idx] = nd.attrib\n",
    "            return out\n",
    "        else:\n",
    "            for k in nd.children:\n",
    "                recurClass(d, nd.children[k], \\\n",
    "                           np.logical_and(idx, d[nd.attrib]==k), res)\n",
    "            return out\n",
    "        \n",
    "    ind = np.array([True] * data.size)\n",
    "    out = np.array([None] * data.size)\n",
    "    return recurClass(data, tree, ind, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data, classes):\n",
    "    return sum(data['class'] != classes) / data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reading Data File ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['class', 'cap-shape', 'cap-surface', 'cap-color' , 'bruises', 'odor', \n",
    "           'gill-attachment' , 'gill-spacing', 'gill-size', 'gill-color' , 'stalk-shape',\n",
    "           'stalk-root', 'stalk-surface-above-ring' , 'stalk-surface-below-ring',\n",
    "           'stalk-color-above-ring', 'stalk-color-below-ring' , 'veil-type', 'veil-color',\n",
    "           'ring-number' , 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "attribSet = set(headers) - set(['class'])\n",
    "\n",
    "raw = np.rec.fromrecords( readCSV('agaricus-lepiota.data') , names=headers)\n",
    "np.random.shuffle(raw) # shuffle the data\n",
    "data1 = raw[:np.floor(raw.size/2)] # first half of data\n",
    "data2 = raw[np.floor(raw.size/2):] # second half of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Decision Tree 1 from set 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree1 = train(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [odor]:\n",
      "\tval=p, class: p\n",
      "\tval=f, class: p\n",
      "\tval=n, Attribute [spore-print-color]:\n",
      "\t\tval=h, class: e\n",
      "\t\tval=w, Attribute [ring-number]:\n",
      "\t\t\tval=o, Attribute [stalk-surface-above-ring]:\n",
      "\t\t\t\tval=f, class: e\n",
      "\t\t\t\tval=k, class: p\n",
      "\t\t\t\tval=y, class: p\n",
      "\t\t\t\tval=s, Attribute [cap-color]:\n",
      "\t\t\t\t\tval=c, class: e\n",
      "\t\t\t\t\tval=w, class: p\n",
      "\t\t\t\t\tval=n, class: e\n",
      "\t\t\tval=t, class: e\n",
      "\t\tval=n, class: e\n",
      "\t\tval=y, class: e\n",
      "\t\tval=o, class: e\n",
      "\t\tval=r, class: p\n",
      "\t\tval=k, class: e\n",
      "\t\tval=b, class: e\n",
      "\tval=y, class: p\n",
      "\tval=s, class: p\n",
      "\tval=c, class: p\n",
      "\tval=a, class: e\n",
      "\tval=l, class: e\n",
      "\tval=m, class: p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view(tree1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify set 2 with tree 1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k2 = classify(tree1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "** Train Decision Tree 2 from set 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree2 = train(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [odor]:\n",
      "\tval=p, class: p\n",
      "\tval=f, class: p\n",
      "\tval=n, Attribute [spore-print-color]:\n",
      "\t\tval=h, class: e\n",
      "\t\tval=w, Attribute [habitat]:\n",
      "\t\t\tval=p, class: e\n",
      "\t\t\tval=w, class: e\n",
      "\t\t\tval=g, class: e\n",
      "\t\t\tval=l, Attribute [cap-color]:\n",
      "\t\t\t\tval=c, class: e\n",
      "\t\t\t\tval=w, class: p\n",
      "\t\t\t\tval=n, class: e\n",
      "\t\t\t\tval=y, class: p\n",
      "\t\t\tval=d, Attribute [population]:\n",
      "\t\t\t\tval=v, class: p\n",
      "\t\t\t\tval=y, class: e\n",
      "\t\tval=n, class: e\n",
      "\t\tval=y, class: e\n",
      "\t\tval=o, class: e\n",
      "\t\tval=r, class: p\n",
      "\t\tval=k, class: e\n",
      "\t\tval=b, class: e\n",
      "\tval=y, class: p\n",
      "\tval=s, class: p\n",
      "\tval=c, class: p\n",
      "\tval=a, class: e\n",
      "\tval=l, class: e\n",
      "\tval=m, class: p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view(tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify set 1 with tree 2 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1 = classify(tree1, data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Evaulate average erro rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "e = evaluate(np.hstack((data1,data2)), np.hstack((k1,k2)))*100\n",
    "print('Average error rate: %.2f%%' % e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
