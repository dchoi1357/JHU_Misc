{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "There are general instructions on Blackboard and in the Syllabus for Programming Assignments. This Notebook also has instructions specific to this assignment. Read all the instructions carefully and make sure you understand them. Please ask questions on the discussion boards or email me at `EN605.445@gmail.com` if you do not understand something.\n",
    "\n",
    "<div style=\"background: mistyrose; color: firebrick; border: 2px solid darkred; padding: 5px; margin: 10px;\">\n",
    "You must follow the directions *exactly* or you will get a 0 on the assignment.\n",
    "</div>\n",
    "\n",
    "You must submit a zip file of your assignment and associated files (if there are any) to Blackboard. The zip file will be named after you JHED ID: `<jhed_id>.zip`. It will not include any other information. Inside this zip file should be the following directory structure:\n",
    "\n",
    "```\n",
    "<jhed_id>\n",
    "    |\n",
    "    +--module-01-programming.ipynb\n",
    "    +--module-01-programming.html\n",
    "    +--(any other files)\n",
    "```\n",
    "\n",
    "For example, do not name  your directory `programming_assignment_01` and do not name your directory `smith122_pr1` or any else. It must be only your JHED ID. Make sure you submit both an .ipynb and .html version of your *completed* notebook. You can generate the HTML version using:\n",
    "\n",
    "> ipython nbconvert [notebookname].ipynb\n",
    "\n",
    "or use the File menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add whatever additional imports you require here. Stick with the standard libraries and those required by the class. The import\n",
    "gives you access to these functions: http://ipython.org/ipython-doc/stable/api/generated/IPython.core.display.html (Copy this link)\n",
    "Which, among other things, will permit you to display HTML as the result of evaluated code (see HTML() or display_html())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division # so that 1/2 = 0.5 and not 0\n",
    "from IPython.core.display import *\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "You can download the two files and read them to find out the attributes, attribute values and class labels as well as their locations in the file.\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. In C4.5, missing values were handled by treating \"?\" as an implicit attribute value for every feature. For example, if the attribute was \"size\" then the domain would be [\"small\", \"medium\", \"large\", \"?\"]. Another approach is to skip instances with missing values. Yet another approach is to infer the missing value conditioned on the class. For example, if the class is \"safe\" and the color is missing, then we would infer the attribute value that is most often associated with \"safe\", perhaps \"red\". **Use the \"?\" approach for this assignment.**\n",
    "\n",
    "As we did with the neural network, you should randomize your data (always randomize your data...you don't know if it is in some particular order like date of collection, by class label, etc.) and split it into two (2) sets. Train on the first set then test on the second set. Then train on the second set and test on the first set.\n",
    "\n",
    "For regression, we almost always use something like Mean Squared Error to judge the performance of a model. For classification, there are a lot more options but for this assignment we will just look at classification error:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "You must implement four functions. `train` takes training_data and returns the Decision Tree as a data structure or object (for this one, I'm removing the OOP restriction...people often feel more comfortable writing a Tree in an OOP fashion). Make sure your Tree can be represented somehow.\n",
    "\n",
    "```\n",
    "def train( training_data):\n",
    "   # returns a decision tree data structure\n",
    "```\n",
    "\n",
    "and `view` takes a tree and prints it out:\n",
    "\n",
    "```\n",
    "def view( tree):\n",
    "    pass # probably doesn't return anything.\n",
    "```\n",
    "\n",
    "the purpose of the function is to be able to see what the tree looks like. It should be legible/pretty. You can use ASCII if you like or use something like NetworkX.\n",
    "\n",
    "and `classify` takes a tree and a List of instances (possibly just one) and returns the classifications:\n",
    "\n",
    "```\n",
    "def classify( tree, test_data):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "and `evaluate` takes the classifications and the test_data and returns the error rate:\n",
    "\n",
    "```\n",
    "def evaluate( test_data, classifications):\n",
    "    # returns an error rate\n",
    "```\n",
    "\n",
    "Basically, you're going to:\n",
    "\n",
    "1. learn the tree for set 1\n",
    "2. view the tree\n",
    "3. classify set 2\n",
    "4. evaluate the tree\n",
    "5. learn the tree for set 2\n",
    "6. view the tree\n",
    "7. classify set 1\n",
    "8. evalute the tree\n",
    "9. average the classification error.\n",
    "\n",
    "This is all that is required for this assignment. I'm leaving more of the particulars up to you but you can definitely use the last module as a guide.\n",
    "\n",
    "**This is a very important assignment to reflect on the use of deepcopy because it has a natural recursive implementation**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Decision Tree class ###  \n",
    "The decision tree is implemented as `DTnode` as a tree with root at a ndoe. The class contains three fields: `attrib`, `isLeaf`, and `children`. The first is the attribute which the decision tree is split on. The second denotes whether the node is a leaf node. For a leaf node, the attribut becomes the classification. The `children` is a `dict` containing the child nodes keyed by the values of the attribute.\n",
    "\n",
    "To instantiate a `DTnode`, one passes a string argument as the attribute for which the node is supposed to represent. \n",
    "\n",
    "The **addChild(nd, val)** function adds a child node `nd` with the `val` of the attribute.\n",
    "\n",
    "The **getChild(val)** function returns the child node for `val` value of attribute.\n",
    "\n",
    "The **getValues()** function returns set of all possible values for the attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DTnode:\n",
    "    def __init__(self, attrib):\n",
    "        self.attrib = attrib\n",
    "        self.isLeaf = True\n",
    "        self.children = dict()\n",
    "\n",
    "    def addChild(self, node, val):\n",
    "        self.isLeaf = False\n",
    "        self.children[val] = node\n",
    "        \n",
    "    def getChild(self, val):\n",
    "        return self.children[val]\n",
    "    \n",
    "    def getValues(self):\n",
    "        return self.children.keys()\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.isLeaf:\n",
    "            childTxt = 'terminal'\n",
    "        else:\n",
    "            childTxt = 'child: ' + str(list(self.children.keys()))\n",
    "        return '[Node for %s, %s ]'%(self.attrib, childTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reading in data ###\n",
    "\n",
    "The function **readCSV(filePath** reads a CSV file and returns the content of the file as a list of lists of strings.\n",
    "\n",
    "The header of the data is encoded below, which are used to 1) produce a set of attributes for the training of the decision tree, and 2) mark the fields of the numpy recarray which are used to contain the data and make programming easier.\n",
    "\n",
    "The rows of data are shuffled and split into two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV(filePath):\n",
    "    with open(filePath, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        l = list(reader)\n",
    "    return l\n",
    "\n",
    "headers = ['class', 'cap-shape', 'cap-surface', 'cap-color' , 'bruises', 'odor', \n",
    "           'gill-attachment' , 'gill-spacing', 'gill-size', 'gill-color' , 'stalk-shape',\n",
    "           'stalk-root', 'stalk-surface-above-ring' , 'stalk-surface-below-ring',\n",
    "           'stalk-color-above-ring', 'stalk-color-below-ring' , 'veil-type', 'veil-color',\n",
    "           'ring-number' , 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "attribSet = set(headers) - set(['class'])\n",
    "\n",
    "raw = np.rec.fromrecords( readCSV('agaricus-lepiota.data') , names=headers)\n",
    "np.random.shuffle(raw) # shuffle the data\n",
    "data1 = raw[:np.floor(raw.size/2)] # first half of data\n",
    "data2 = raw[np.floor(raw.size/2):] # second half of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions ###\n",
    "\n",
    "**B(p)**  \n",
    "Entropy function for binary variables. Returns:\n",
    "$$B(q) = -[q \\lg({q}) + (1-q) \\lg({1-q})]$$\n",
    "Where $q$ is the proportion of data taking one of the binary values.\n",
    "\n",
    "**edibleProb(d)**  \n",
    "The function calculates the proportion of the data `d` which are within the class of edible mushrooms.\n",
    "\n",
    "** Remainer(d, Attr)**  \n",
    "For a specific attribute `Attr` with d distinct values divides the training set E into subsets $E_1, ... , E_d$. Each subset $E_k$ has $p_k$ positive examples and $n_k$ negative examples. The function calculates the expected entropy of using `Attr` as the dividing attribute for the data `d`. Formally, it calculates:\n",
    "$$\\sum_{k=1}^{d}{\\frac{p_k+n_k}{p+n}B(\\frac{p_k}{p_k+n_k})}$$\n",
    "\n",
    "** Importance(d, attribs)**  \n",
    "Given a data set as a recarray `d` and a set of attributes for which to divide the data with, the function returns a tuple containing the most important attribute by information gain and the information gain. Formally, it calcualtes\n",
    "\n",
    "$$argmax_{A\\in attributes} Gain(A)$$\n",
    "where\n",
    "$$Gain(A) = B(\\frac{p}{p+n}) - Remainer(A)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def B(p):\n",
    "    return 0 if p==1 or p==0 else -(p*np.log2(p) + (1-p)*np.log2(1-p))\n",
    "\n",
    "def edibleProb(d):\n",
    "    return np.count_nonzero(d['class']=='e') / d.size\n",
    "    \n",
    "def Remainder(d, Attr):\n",
    "    vals,N = np.unique(d[Attr], return_counts=True )\n",
    "    entropies = [B(edibleProb(d[d[Attr]==v])) for v in vals]\n",
    "    return np.sum(N/d.size * entropies)\n",
    "\n",
    "def Importance(d, attribs):\n",
    "    entropy = B(edibleProb(d))\n",
    "    gains = list(zip(*[(entropy - Remainder(d,A),A) for A in attribs]))\n",
    "    return gains[1][np.argmax(gains[0])], np.max(gains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training function implements the id3 algorithm by recursively picking attributes of the data which gives the most information gain. For each value of the attribute, a child node is added to the tree and the data is subsetted which are homogenous on the given attribute. The algorithm stops when all data are of the same class, the data subset is empty, or there are no more attributes to split the data on. The the latter two, the algorithm chooses the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    def id3(d, attribs, default):\n",
    "        if d.size == 0: # empty data\n",
    "            return DTnode(default)\n",
    "        prEd = edibleProb(d)\n",
    "        majority = 'e' if prEd > 0.5 else 'p'\n",
    "        if prEd in [0,1] or len(attribs)==0: # homogenous or no attribs\n",
    "            return DTnode(majority) \n",
    "\n",
    "        bestAttr, gain = Importance(d, attribs)\n",
    "        attribSubset = attribs - set([bestAttr])\n",
    "        nd = DTnode(bestAttr) # new node at the best attribute\n",
    "        for v in set(d[bestAttr]):\n",
    "            child = id3(d[d[bestAttr]==v], attribSubset, majority)\n",
    "            nd.addChild(child, v)\n",
    "        return nd\n",
    "\n",
    "    return id3(data, attribSet, 'e' if edibleProb(data) > 0.5 else 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **view(tree)** function printes an ASCII tree where each child node is printed at an additional indent level of its parent. For leaf node, the tree is printed with the class. The algorithm is recursive and prints the tree via in-order traversal. The tree looks like:\n",
    "````\n",
    "Attribute [var1]:\n",
    "\tvalue = a, class: p\n",
    "    value = b, Attribute [var2]:\n",
    "    \tvalue = c, class: p\n",
    "\t\tvalue = d, class: n\n",
    "\tvalue = e, class = n\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def view(tree):\n",
    "    def toStr(nd, level=0):\n",
    "        if nd.isLeaf:\n",
    "            return 'class: %s\\n' % nd.attrib\n",
    "        else:\n",
    "            ret = 'Attribute [' + nd.attrib + \"]:\\n\"\n",
    "            nx = level + 1\n",
    "            for key in nd.children:\n",
    "                ret += \"\\t\"*nx + 'value = %s, '%key \\\n",
    "                    + toStr(nd.children[key],nx)\n",
    "            return ret\n",
    "    \n",
    "    print(toStr(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **class(tree, data)** function uses the decision tree `tree` to classifiy `data` and returning the classification as a numpy array. The algorithm performs in-order traversal of the decision tree through recursion and mark the appropriate subset data with the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, data):\n",
    "    def recurClass(d, nd, idx, res):\n",
    "        if nd.isLeaf:\n",
    "            res[idx] = nd.attrib\n",
    "            return out\n",
    "        else:\n",
    "            for k in nd.getValues():\n",
    "                recurClass(d, nd.getChild(k), \\\n",
    "                           np.logical_and(idx, d[nd.attrib]==k), res)\n",
    "            return out\n",
    "        \n",
    "    ind = np.array([True] * data.size)\n",
    "    out = np.array([None] * data.size)\n",
    "    return recurClass(data, tree, ind, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **evaulate(data, classes)** function calculates the error rate of the classification, or formally:\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i}^{n}{I_{k_i\\ne\\hat{k_i}}(i\\in x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data, classes):\n",
    "    return sum(data['class'] != classes) / data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training Decision Trees and Evaulation###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Decision Tree 1 from set 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree1 = train(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [odor]:\n",
      "\tvalue = a, class: e\n",
      "\tvalue = n, Attribute [spore-print-color]:\n",
      "\t\tvalue = h, class: e\n",
      "\t\tvalue = w, Attribute [habitat]:\n",
      "\t\t\tvalue = w, class: e\n",
      "\t\t\tvalue = g, class: e\n",
      "\t\t\tvalue = d, Attribute [stalk-root]:\n",
      "\t\t\t\tvalue = b, class: e\n",
      "\t\t\t\tvalue = ?, class: p\n",
      "\t\t\tvalue = l, Attribute [stalk-color-below-ring]:\n",
      "\t\t\t\tvalue = w, class: p\n",
      "\t\t\t\tvalue = n, class: e\n",
      "\t\t\t\tvalue = y, class: p\n",
      "\t\t\tvalue = p, class: e\n",
      "\t\tvalue = n, class: e\n",
      "\t\tvalue = k, class: e\n",
      "\t\tvalue = y, class: e\n",
      "\t\tvalue = o, class: e\n",
      "\t\tvalue = r, class: p\n",
      "\t\tvalue = b, class: e\n",
      "\tvalue = f, class: p\n",
      "\tvalue = p, class: p\n",
      "\tvalue = y, class: p\n",
      "\tvalue = s, class: p\n",
      "\tvalue = m, class: p\n",
      "\tvalue = c, class: p\n",
      "\tvalue = l, class: e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view(tree1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify set 2 with tree 1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k2 = classify(tree1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Decision Tree 2 from set 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree2 = train(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [odor]:\n",
      "\tvalue = a, class: e\n",
      "\tvalue = n, Attribute [spore-print-color]:\n",
      "\t\tvalue = h, class: e\n",
      "\t\tvalue = w, Attribute [stalk-surface-below-ring]:\n",
      "\t\t\tvalue = s, Attribute [cap-surface]:\n",
      "\t\t\t\tvalue = y, class: e\n",
      "\t\t\t\tvalue = g, class: p\n",
      "\t\t\t\tvalue = f, class: e\n",
      "\t\t\t\tvalue = s, class: e\n",
      "\t\t\tvalue = f, class: e\n",
      "\t\t\tvalue = y, Attribute [stalk-root]:\n",
      "\t\t\t\tvalue = ?, class: p\n",
      "\t\t\t\tvalue = b, class: e\n",
      "\t\t\t\tvalue = c, class: p\n",
      "\t\t\tvalue = k, class: e\n",
      "\t\tvalue = n, class: e\n",
      "\t\tvalue = k, class: e\n",
      "\t\tvalue = y, class: e\n",
      "\t\tvalue = o, class: e\n",
      "\t\tvalue = r, class: p\n",
      "\t\tvalue = b, class: e\n",
      "\tvalue = f, class: p\n",
      "\tvalue = p, class: p\n",
      "\tvalue = y, class: p\n",
      "\tvalue = s, class: p\n",
      "\tvalue = m, class: p\n",
      "\tvalue = c, class: p\n",
      "\tvalue = l, class: e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view(tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify set 1 with tree 2 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1 = classify(tree2, data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Evaulate average error rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate: 0.05%\n"
     ]
    }
   ],
   "source": [
    "e = evaluate(np.hstack((data1,data2)), np.hstack((k1,k2)))*100\n",
    "print('Average error rate: %.2f%%' % e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
