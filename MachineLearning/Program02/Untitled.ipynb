{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(5, size=[10,4]) +10\n",
    "y = np.random.randint(5, size=[10,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseDist(x, y=None):\n",
    "    if y is None:\n",
    "        y = x\n",
    "    return np.sum((x[:,None]-y)**2,axis=2)**0.5\n",
    "\n",
    "def arrayDist(x,y):\n",
    "    return np.sum((x-y)**2,axis=1)**0.5\n",
    "\n",
    "def errRates(pred, actual):\n",
    "    return (actual!=pred).sum() / pred.size # return error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initMeans(data, n, algo=1):\n",
    "    if algo==1: # choose n random points\n",
    "        idx = np.random.choice(range(data.shape[0]), n, False) # no replace\n",
    "        out = data[idx,]\n",
    "    if algo==2: # random means points (0,1)\n",
    "        out = np.random.random([n,data.shape[1]])\n",
    "    if algo==3: # always take first n point as centroid\n",
    "        out = data[:n,]\n",
    "    return out\n",
    "\n",
    "def shortestCentroid(centr, mat):\n",
    "    tmpDist = pairwiseDist(centr,mat) # dist between means and all data pts\n",
    "    return tmpDist.argmin(axis=0) # find group where distance is smallest\n",
    "\n",
    "def updateMeans(data, means):\n",
    "    ## Assign each pt to the mean for which it has the shortest distance\n",
    "    tmpDist = pairwiseDist(means,data) # dist between means and all data pts\n",
    "    minDist = tmpDist.argmin(axis=0) # find group where distance is smallest\n",
    "\n",
    "    ## Calculate new means to be centroid of all the points in the group\n",
    "    newMeans = np.zeros([len(means),data.shape[1]]) # new mean points\n",
    "    for n,x in enumerate(means): # loop over all clusters\n",
    "        tmp = np.vstack( (data[minDist==n,],x) ) # concat data pt and centroid\n",
    "        newMeans[n] = tmp.mean(axis=0) # new mean = centroid of all pts \n",
    "    \n",
    "    return newMeans,minDist\n",
    "\n",
    "################################################################################\n",
    "def kMeans(data, k, trace=False, initAlgo=1):\n",
    "    means = initMeans(data, k, initAlgo) # initialize mean points\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        newMeans,grpIdx = updateMeans(data, means)\n",
    "        converged = np.allclose(means,newMeans)\n",
    "        if trace:\n",
    "            print(means)\n",
    "        means = newMeans\n",
    "        \n",
    "    return means,grpIdx # return final centroids and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[13.33333333, 14.        , 14.        , 13.        ],\n",
       "        [11.        , 12.5       , 10.375     , 11.875     ],\n",
       "        [10.        , 11.        , 14.        , 12.        ]]),\n",
       " array([0, 1, 2, 1, 1, 1, 1, 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateMeans(x, x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37447605 0.12174801 0.34172695 0.38724677]\n",
      " [0.29682263 0.21363869 0.96782684 0.33721441]]\n",
      "[[2.34361901 2.530437   0.08543174 1.59681169]\n",
      " [6.73871237 7.95631326 7.38710149 7.6854008 ]]\n",
      "[[2.34361901 2.530437   0.08543174 1.59681169]\n",
      " [6.73871237 7.95631326 7.38710149 7.6854008 ]]\n",
      "[[ 1.57669264  2.68458518  1.55322107  2.23607379]\n",
      " [11.06715567 12.17784666 11.12610014 11.6986728 ]]\n",
      "[[ 1.57669264  2.68458518  1.55322107  2.23607379]\n",
      " [11.06715567 12.17784666 11.12610014 11.6986728 ]]\n",
      "[[ 1.50697206  2.69859865  1.68665646  2.29418853]\n",
      " [11.46065052 12.56162242 11.4660091  12.06351571]]\n",
      "[[ 1.50697206  2.69859865  1.68665646  2.29418853]\n",
      " [11.46065052 12.56162242 11.4660091  12.06351571]]\n",
      "[[ 1.50063382  2.6998726   1.69878695  2.29947168]\n",
      " [11.49642277 12.59651113 11.49690992 12.09668325]]\n",
      "[[ 1.50063382  2.6998726   1.69878695  2.29947168]\n",
      " [11.49642277 12.59651113 11.49690992 12.09668325]]\n",
      "[[ 1.50005762  2.69998842  1.69988972  2.29995197]\n",
      " [11.4996748  12.59968283 11.49971908 12.09969848]]\n",
      "[[ 1.50005762  2.69998842  1.69988972  2.29995197]\n",
      " [11.4996748  12.59968283 11.49971908 12.09969848]]\n",
      "[[ 1.50000524  2.69999895  1.69998997  2.29999563]\n",
      " [11.49997044 12.59997117 11.49997446 12.09997259]]\n",
      "[[ 1.50000524  2.69999895  1.69998997  2.29999563]\n",
      " [11.49997044 12.59997117 11.49997446 12.09997259]]\n",
      "[[ 1.50000048  2.6999999   1.69999909  2.2999996 ]\n",
      " [11.49999731 12.59999738 11.49999768 12.09999751]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.50000048,  2.6999999 ,  1.69999909,  2.2999996 ],\n",
       "        [11.49999731, 12.59999738, 11.49999768, 12.09999751]]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.vstack([x,y])\n",
    "\n",
    "kMeans(z, 2, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectBestFeature(dataMat, selected, Nk):\n",
    "    # get list of index of currently unselected features\n",
    "    unselect = np.where(~np.isin(np.arange(dataMat.shape[1]),selected))[0]\n",
    "    bestCoeff = -1-1e-9 # worst possible coefficient value is -1\n",
    "    for n,j in enumerate(unselect): # loop over unselected features\n",
    "        testSet = np.hstack([selected,j]) # add curr feature to selected ones\n",
    "        means,labels = kMeans(dataMat[:,testSet], Nk) # cluster w/ test features\n",
    "        coeff = Silhouette(dataMat,labels).mean() # mean silhouette coeff\n",
    "        #print((coeff,bestCoeff))\n",
    "        if coeff > bestCoeff: # if this feature produce better coeff\n",
    "            bestCoeff = coeff # record new best coeff\n",
    "            outs = (j,coeff,means,labels) # record output variables\n",
    "    #print(unselect)\n",
    "    return outs # output: the feature, best coeff, means, and labels\n",
    "################################################################################\n",
    "\n",
    "def ForwardSelect(data, k):\n",
    "    selected = np.zeros(0, int) # idx of selected features, start w/ empty\n",
    "    baseCoeff = -1-1e-9 # -1 is worst possible performance\n",
    "    converged = False\n",
    "    while not converged: # loop until convergence\n",
    "        bestFeat,bestCoeff,means,labels = SelectBestFeature(data, selected, k) \n",
    "        if bestCoeff <= baseCoeff: # if new feature doesn't improve performance\n",
    "            converged = True\n",
    "        else: # if new feature improves performance\n",
    "            print(bestCoeff-baseCoeff)\n",
    "            selected = np.hstack([selected,bestFeat]) # add feature to selection\n",
    "            baseCoeff = bestCoeff # set new coeff as baseline performance\n",
    "            outs = (means,labels) # save output vars\n",
    "            if len(selected) == data.shape[1]: \n",
    "                converged = True # algo converged if all features selected\n",
    "    return (selected,)+outs # return selected features, means, cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1044337798534718\n",
      "0.0027974021309899316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 4], dtype=int64), array([[2.03225794, 4.59677437],\n",
       "        [7.39473531, 3.02631531]]), array([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = np.random.randint(0,10,[100,8])\n",
    "\n",
    "ForwardSelect(testData,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def Silhouette(data, labels):\n",
    "    distMat = pairwiseDist(data) # pre-calc all pairwise dist for memoization\n",
    "    grpIdx = pd.Series(labels).groupby(labels).groups.items() # idx for each grp\n",
    "    \n",
    "    aVals = np.zeros(data.shape[0]) # pre-allocate a and b-values for data\n",
    "    bVals = np.zeros(data.shape[0])\n",
    "    for grp,idx in grpIdx: # loop over all groups\n",
    "        aVals[idx] = distMat[np.ix_(idx,idx)].mean(axis=1) # a's for curr grp\n",
    "        \n",
    "        # loop over all groups that's not the current gruop\n",
    "        tmp = np.zeros([len(grpIdx)-1,len(idx)]) # tmp for all b's for curr grp\n",
    "        for n,(_,outIdx) in enumerate([x for x in grpIdx if x[0]!=grp]):\n",
    "            # calculate mean dist of points within cluster to out of cluster\n",
    "            tmp[n,] = distMat[np.ix_(idx,outIdx)].mean(axis=1) \n",
    "        #print(tmp.shape)\n",
    "        #print(idx.shape)\n",
    "        bVals[idx] = tmp.min(axis=0) # pick min b of all out-groups\n",
    "\n",
    "    return (bVals-aVals)/np.maximum(aVals,bVals) # return silhouette coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.218264548496111\n",
      "0.10202167454565866\n",
      "0.011917492844527922\n",
      "0.0915066380507315\n",
      "0.010737041792362234\n",
      "0.013112969092185567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([5, 4, 7, 6, 3, 2], dtype=int64),\n",
       " array([[2.44444449e-01, 7.25177778e+01, 1.74999996e-01, 1.25800000e+01,\n",
       "         1.30888889e+00, 1.69444481e-01],\n",
       "        [1.65925926e-01, 7.17748148e+01, 2.96296296e-02, 9.58481481e+00,\n",
       "         8.69259259e-01, 3.69074074e+00],\n",
       "        [3.33999997e-01, 7.21999999e+01, 1.96666675e-01, 9.68799987e+00,\n",
       "         1.65866667e+00, 1.97333337e+00],\n",
       "        [5.66260163e-01, 7.28155285e+01, 5.20325203e-03, 8.38772358e+00,\n",
       "         1.37284553e+00, 3.50658537e+00],\n",
       "        [3.46399994e+00, 7.10260000e+01, 1.00399998e+00, 6.19600003e+00,\n",
       "         2.71799998e+00, 1.82800003e+00],\n",
       "        [2.11923077e-01, 7.34469231e+01, 9.57692308e-01, 8.59884615e+00,\n",
       "         2.10961538e+00, 6.69230771e-02]]),\n",
       " array([1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 1,\n",
       "        3, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 0, 0,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3,\n",
       "        3, 3, 3, 1, 3, 3, 3, 3, 1, 4, 2, 2, 0, 0, 5, 0, 0, 4, 4, 0, 2, 0,\n",
       "        2, 2, 2, 2, 5, 2, 0, 0, 5, 4, 4, 3, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64))"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisFile = os.path.join('./data/', 'iris.data')\n",
    "irisName = ['sepalLen', 'sepalWth', 'petalLen', 'petalWth', 'class']\n",
    "raw = pd.read_csv(irisFile , names=irisName)  # read CSV file\n",
    "irisFeats = irisName[:-1]\n",
    "irisMat = raw[irisFeats].values\n",
    "irisK = len(raw['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5459229763687348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2], dtype=int64), array([[4.43181827],\n",
       "        [5.82647044],\n",
       "        [1.46400021]]), array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForwardSelect(irisMat, irisK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassData = os.path.join('./data/', 'glass.data')\n",
    "glassNames = ['id','RI','Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'class']\n",
    "raw = pd.read_csv(glassData , names=glassNames)  # read CSV file\n",
    "\n",
    "glassFeats = glassNames[1:-1] # list of feature names\n",
    "glassMat = raw[glassFeats].values # 2d-array of feature values\n",
    "glassK = len(raw['class'].unique()) # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.280279874484533\n",
      "0.05061651564669223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([5, 2], dtype=int64), array([[5.04      , 0.        ],\n",
       "        [0.78533314, 2.91400041],\n",
       "        [0.11724138, 3.71275862],\n",
       "        [0.32625   , 1.91      ],\n",
       "        [0.15365854, 0.02707317],\n",
       "        [0.58681818, 3.55854545]]), array([2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 5, 5, 2,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 5, 5, 5, 2,\n",
       "        5, 5, 5, 2, 2, 5, 2, 5, 1, 1, 1, 1, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5,\n",
       "        5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 2, 1, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 4,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 2, 5, 5, 5, 5, 2, 2, 5,\n",
       "        5, 5, 5, 2, 5, 5, 5, 2, 2, 1, 3, 3, 3, 4, 4, 4, 4, 0, 0, 4, 3, 4,\n",
       "        3, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 5, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int64))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForwardSelect(glassMat, glassK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamData = os.path.join('./data/', 'spambase.data')\n",
    "spamNames = ['make', 'address', 'all', '3d', 'our', 'over', 'remove',\n",
    "\t'internet', 'order', 'mail', 'receive', 'will', 'people', 'report',\n",
    "\t'addresses', 'free', 'business', 'email', 'you', 'credit', 'your', 'font',\n",
    "\t'0', 'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857',\n",
    "\t'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct', 'cs',\n",
    "\t'meeting', 'original', 'project', 're', 'edu', 'table', 'conference',\n",
    "\t'semicolon', 'paren', 'bracket', 'exclaim', 'dollar', 'pound', 'capsAvg',\n",
    "\t'capsMax', 'capsTotal', 'class']\n",
    "raw = pd.read_csv(spamData , names=spamNames)  # read CSV file\n",
    "\n",
    "spamFeats = spamNames[:-1] # list of feature names\n",
    "spamMat = raw[spamFeats].values # 2d-array of feature values\n",
    "spamK = len(raw['class'].unique()) # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.842031262105331\n"
     ]
    }
   ],
   "source": [
    "ForwardSelect(spamMat, spamK) # run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.04280722  1.07598526  1.055384  ]\n",
      " [10.04850651 10.07301026 10.0161049 ]\n",
      " [11.09731025 11.05113568 11.09967267]\n",
      " [11.05970864 10.00012083 11.01400918]\n",
      " [ 2.04633279  2.09427173  1.06731713]\n",
      " [ 1.51476797  1.57534432  1.59872265]\n",
      " [12.09157277 12.03561811 12.02184439]]\n"
     ]
    }
   ],
   "source": [
    "testX = np.array([[1,1,1],[10,10,10],[11,11,11],[11,10,11],\n",
    "                  [2,2,1],[1.5,1.5,1.5],[12,12,12]]) + np.random.random([7,3])/10\n",
    "testY = np.array([1,2,2,2,1,1,2])\n",
    "testY_bad = np.array([2,2,1,2,1,2,1])\n",
    "print(testX)\n",
    "\n",
    "print(Silhouette(testX,testY))\n",
    "print(Silhouette(testX,testY_bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "- [A Modified k-means Algorithm to Avoid Empty Clusters](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.3148&rep=rep1&type=pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
