{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import itertools\n",
    "from Bresenham import getPath\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelList = [1,0,-1]\n",
    "velocList = range(-5,6)\n",
    "accels = list(itertools.product(accelList,accelList))\n",
    "velocs = list(itertools.product(velocList,velocList))\n",
    "actsPrint = {(0,0): \"o\", (1,1): \"\\N{North East Arrow}\", \n",
    "             (1,0): \"\\N{Rightwards Arrow}\", (1,-1): \"\\N{South East Arrow}\",\n",
    "             (0,-1): \"\\N{Downwards Arrow}\", (-1,-1): \"\\N{South West Arrow}\",\n",
    "             (-1,0): \"\\N{Leftwards Arrow}\", (-1,1): \"\\N{North West Arrow}\",\n",
    "             (0,1): \"\\N{Upwards Arrow}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def readTrackFile(file):\n",
    "    with open(file, 'r') as f:\n",
    "        raw = [[s for s in l.strip()] for l in f.readlines()]\n",
    "        track = np.array(raw[1:]) # strip out lines with world size\n",
    "\n",
    "    locs,goals,starts = set(),set(),set()\n",
    "    for x,y in itertools.product(range(track.shape[0]), range(track.shape[1])):\n",
    "        space = track[y,x] # current track space\n",
    "        if space == '#': # wall space, not valid state\n",
    "            continue\n",
    "        else:\n",
    "            locs.add( (x,y) ) # valid state of car\n",
    "            if space == 'S': # starting points\n",
    "                starts.add( (x,y) ) # add to list of starting locations\n",
    "            if space == 'F': # is finish line space\n",
    "                goals.add( (x,y) ) # add to list of goal locations\n",
    "\n",
    "    states = set((x,y,a,b) for (x,y),(a,b) in itertools.product(locs,velocs))\n",
    "    return states,goals,track,starts\n",
    "    \n",
    "fPath = os.path.join('data','O-track.txt')\n",
    "O_states,O_goals,O_track,O_starts = readTrackFile(fPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def transFromState(state,actions,track):\n",
    "    size = track.shape\n",
    "    x0, y0, vx0, vy0 = state\n",
    "    trans = dict()\n",
    "    #trans = list()\n",
    "    for ax,ay in actions: # loop through all possible accelerations\n",
    "        vx1 = min(max(vx0 + ax,-5),5) # updated velocity\n",
    "        vy1 = min(max(vy0 + ay,-5),5)\n",
    "        paths = getPath(x0, y0, vx1, vy1) # path car takes with velocity vec\n",
    "\n",
    "        r = -1 # default reward\n",
    "        x1, y1 = (x0,y0) # set to starting location\n",
    "        for xC,yC in paths: # x,y coordinate of every step in path\n",
    "            #if not (0<=xC<size[0]) or not (0<=yC<size[1]): # out of bound\n",
    "            #    break\n",
    "            if track[yC,xC] == '#': # run into wall\n",
    "                vx1, vy1 = (0,0)\n",
    "                break\n",
    "            if track[yC,xC] == 'F': # goes over finish line\n",
    "                x1, y1 = (xC,yC)\n",
    "                vx1, vy1 = (0,0)\n",
    "                r = 0\n",
    "                break\n",
    "            x1, y1 = (xC,yC) # update location to new place\n",
    "        #trans.append( ((ax,ay),(x1,y1,vx1,vy1),r) ) # new state after transition\n",
    "        trans[(ax,ay)] = ((x1,y1,vx1,vy1),r)  # new state after transition\n",
    "    \n",
    "    return trans\n",
    "################################################################################\n",
    "def getTransitions(states,accelerations,world):\n",
    "    Rs = dict()\n",
    "    for st in states:\n",
    "        if world[st[1],st[0]] == 'F': # is finish line\n",
    "            immob = (st[0], st[1], 0, 0) # immobilize at curr goal position\n",
    "            Rs[st] = {(0,0): (immob, 0)} # only valid trans is staying put\n",
    "        else: # get all transitions from current state if not finish line\n",
    "            Rs[st] = transFromState(st,accelerations,world)\n",
    "    return Rs\n",
    "\n",
    "################################################################################\n",
    "def getVPolicyFromQ(Q):\n",
    "    acts = Q.keys()\n",
    "    pol = max(acts, key=(lambda k: Q[k])) # get the key with highest reward\n",
    "    return Q[pol], pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcQfromV(state, tr, V_0, failPr, gamma):\n",
    "    Q = {k:0 for k in tr} # initialize Q to all 0 for all actions\n",
    "    failSt = tr[(0,0)][0] # resultant state of a failed acceleration\n",
    "    \n",
    "    for accel,(newState,reward) in tr.items(): # loop over all transitions\n",
    "        tmp = (1-failPr)*V_0[newState] + failPr*V_0[failSt] # sum of pr*V\n",
    "        Q[accel] = reward + gamma * tmp # E[r|s,a] + gamma * sum(V)\n",
    "    return Q\n",
    "\n",
    "def maxDiffTwoVs(v1, v2):\n",
    "    pairedVals = zip(v1.values(), v2.values()) # get all values from both V vals\n",
    "    return max([abs(x-y) for x,y in pairedVals]) # return max diff of all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def valueIteration(states, track, accels, gamma=0.9, eps=1e-9, pr_fail=0.2, \n",
    "                   trace=False):\n",
    "    TRs_all = getTransitions(states, accels, track) # all trans from all states\n",
    "    \n",
    "    Vs = {k:0 for k in states}\n",
    "    Qs = {k:None for k in states}\n",
    "    pols = dict()\n",
    "    \n",
    "    for t in itertools.count(): # loop until converged\n",
    "        Vs_old = Vs.copy() # copy of Vs as old V values\n",
    "        for st in states: # loop over all states\n",
    "            Qs[st] = calcQfromV(st, TRs_all[st], Vs_old, pr_fail, gamma)\n",
    "            Vs[st],pols[st] = getVPolicyFromQ(Qs[st], TRs_all[st])\n",
    "        \n",
    "        maxDiff = maxDiffTwoVs(Vs, Vs_old)\n",
    "        if trace and (t % 10 == 0):\n",
    "            print('[%05d]: diff=%f'%(t,maxDiff))\n",
    "        \n",
    "        if (maxDiff<eps) or (t >= 1e4): # max 1000 iters if not converged\n",
    "            break\n",
    "\n",
    "    if trace:\n",
    "        print('Total iters: %d, max util diff = %f'%(t,maxDiff))\n",
    "    return pols, t, maxDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsGreedy(Q, acts, temp=1):\n",
    "    qs = np.array( [Q[k] for k in acts] ) # all Q(s,a) values\n",
    "    P_a = np.exp(qs / temp) # numerator of softmax, exp[Q(s,a)]\n",
    "    P_a = P_a / P_a.sum() # array of probabilites\n",
    "    \n",
    "    idx = np.argmax(np.random.random() < P_a.cumsum())\n",
    "    return acts[idx]\n",
    "################################################################################\n",
    "def q_episode(st, Q, TRs, gm, et, prF, trk, fins, trace):\n",
    "    cumReward = 0\n",
    "    for t in itertools.count(): # loop for exploration\n",
    "        if st[:2] in fins: # if curr state is a goal\n",
    "            break\n",
    "            \n",
    "        tr = TRs[st] # all possible transitions from curr state\n",
    "        attempt = epsGreedy(Q[st], list(tr.keys())) # desired act, eps-greedy\n",
    "        if random.random() < prF: # failed to accelerate\n",
    "            actual = (0,0) # fail to accelerate\n",
    "        else: # successfully change accelerattion\n",
    "            actual = attempt \n",
    "            \n",
    "        newSt,reward = tr[actual] # next state and reward for action\n",
    "        maxQ = max( Q[nextSt][k] for k in TRs[newSt].keys() ) # Q of new state\n",
    "        Q[st][actual] += et*(reward + gm*maxQ - Q[st][actual]) # update Q(s,a)\n",
    "        st = newSt\n",
    "        cumReward += reward\n",
    "\n",
    "    return Q, t, cumReward # return Q, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def qLearning(states, accels, goals, nEpisodes=int(1e6), gamma=0.9, eta=0.1,\n",
    "              pr_fail=0.2, trace=False):\n",
    "    TRs = getTransitions(states, accels, track) # all trans from all states\n",
    "    states = [x for x in states if x[:2] not in goals] # remove goal states\n",
    "    \n",
    "    Qs = dict()\n",
    "    for st in states: # initialize Q table to all 0's\n",
    "        Qs[st] = {a: 0 for a in acts}\n",
    "        \n",
    "    epsLen = np.zeros(nEpisodes, int) # length of each episode\n",
    "    epsReward = np.zeros(nEpisodes, int) # length of each \n",
    "\n",
    "    for ep in range(nEpisodes):\n",
    "        start = random.choice(states) # choose random starting location\n",
    "        # run one episode of q-learning, get new Qs, ep. len, ep. cum. reward\n",
    "        Qs,epsLen[ep],epsReward[ep] = qEpisode(start, Qs, TRs, gamma, \n",
    "                                               eta, pr_fail, goals, trace)\n",
    "    \n",
    "    policy = dict() # pre-allocate policy\n",
    "    for st in states: # loop over all states to get policy for each state\n",
    "        tmp, policy[st] = getVPolicyFromQ(Qs) # best policy accord. to Qs\n",
    "    return policy, epsLen, epsReward # return policy and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TRss[(21,17,0,-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00000]: diff=1.000000\n",
      "[00010]: diff=0.348678\n",
      "[00020]: diff=0.121577\n",
      "[00030]: diff=0.004735\n",
      "[00040]: diff=0.000000\n",
      "Total iters: 45, max util diff = 0.000000\n"
     ]
    }
   ],
   "source": [
    "a,b,c = valueIteration(O_states, O_track, accels, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1), ((4, 14, 2, -1), -1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRss = getTransitions(O_states,accels,O_track)\n",
    "\n",
    "z = transFromState((2,15,1,-2),accels,O_track)\n",
    "list(z.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): ((4, 12, 0, 0), 0)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRss[next(iter(O_goals))+(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 17)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(O_states))[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
