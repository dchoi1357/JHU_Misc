{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import os\n",
    "from crossValidate import getXVFolds\n",
    "from NaiveBayes import NB_Train, NB_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(5, size=[6,3])\n",
    "wt = np.random.rand(3,4)*2\n",
    "print(x)\n",
    "print(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*  [[1,2,3],[4,5,6]]  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = softMax(x, wt)\n",
    "idx = np.argmax(yhat, axis=1)\n",
    "y = np.zeros([6,4], int)\n",
    "for r in np.arange(6):\n",
    "    y[r,idx[r]] = 1\n",
    "\n",
    "np.sum(-y*np.log(yhat),axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concateIntercept(x):\n",
    "    return np.hstack( [np.ones((x.shape[0],1), x.dtype), x] )\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def softMax(x, wts):\n",
    "    pr = np.exp(x @ wts)\n",
    "    return pr / np.sum(pr,axis=1)[:,None]\n",
    "\n",
    "\n",
    "def fitLogisticNK(x, y, eta, eps=1e-7, trace=False):\n",
    "    def crossEntNK(x, wts, y):\n",
    "        yhat = softMax(x, wts)\n",
    "        err = np.sum(-y*np.log(yhat), axis=1).mean()\n",
    "        return err, yhat\n",
    "    \n",
    "    def updateWeightNK(eta, yhat, y, x, wt):\n",
    "        d = ((y - yhat).T @ x).T / len(y)\n",
    "        return wt + (eta*d)\n",
    "    \n",
    "    x = concateIntercept(x)\n",
    "    nDim,nK = x.shape[1],y.shape[1]\n",
    "    wts = np.random.rand(nDim,nK)/50 - 0.01 # init wts to be (-0.01,0.01)\n",
    "    lastErr = np.inf # max error possible\n",
    "    err,yhat = crossEntNK(x, wts, y)\n",
    "\n",
    "    n = 0\n",
    "    while (abs(err-lastErr) > eps) and n < 1e6:\n",
    "        if n % 1000 == 0 and trace:\n",
    "            print('Iter #%u, error: %f'%(n,err))\n",
    "        wts = updateWeightNK(eta, yhat, y, x, wts)\n",
    "        lastErr = err\n",
    "        err,yhat = crossEntNK(x, wts, y)\n",
    "        if err > lastErr:\n",
    "            eta /= 10\n",
    "        n += 1\n",
    "    \n",
    "    print('Final iteration #%u, error: %f' % (n-1,err) )\n",
    "    return wts\n",
    "\n",
    "def predLogisticNK(x, wts):\n",
    "    x = concateIntercept(x)\n",
    "    yhat = softMax(x, wts) # calc posterior prob of all classes\n",
    "    return yhat.argmax(axis=1) # return class with largest probability\n",
    "\n",
    "\n",
    "def sigmoid(x, wt):\n",
    "    return 1.0 / ( 1 + np.exp(-x @ wt) )\n",
    "\n",
    "def fitLogisticReg(x, y, eta, eps=1e-7, trace=False):\n",
    "    def crossEntropy(x, wt, y):\n",
    "        yhat = sigmoid(x, wt)\n",
    "        err = -np.mean(y*np.log(yhat) + (1-y)*np.log(1-yhat))\n",
    "        return err, yhat\n",
    "    \n",
    "    def updateWeight(eta, yhat, y, x, wt):\n",
    "        d = (y - yhat) @ x / len(y)\n",
    "        return wt + (eta*d)\n",
    "    \n",
    "    x = concateIntercept(x)\n",
    "    wt = np.random.rand(x.shape[1])/50 - 0.01 # initialize weights\n",
    "    lastErr = 1\n",
    "    err,yhat = crossEntropy(x, wt, y)\n",
    "\n",
    "    n = 0\n",
    "    while (abs(err-lastErr) > eps) and n < 1e6:\n",
    "        if n % 1000 == 0 and trace:\n",
    "            print('Iter #%u, error: %f'%(n,err))\n",
    "        wt = updateWeight(eta, yhat, y, x, wt)\n",
    "        lastErr = err\n",
    "        err,yhat = crossEntropy(x, wt, y)\n",
    "        if err > lastErr:\n",
    "            eta /= 10\n",
    "        n += 1\n",
    "    \n",
    "    print('Final iteration #%u, error: %f' % (n-1,err) )\n",
    "    return wt\n",
    "\n",
    "def predLogistic(x, wt):\n",
    "    x = concateIntercept(x)\n",
    "    yhat = sigmoid(x, wt) # calc posterior prob of binary response\n",
    "    return (yhat > 0.5)*1 # whether posterior prob > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizeMean(inDF, useMed=False):\n",
    "    outDF = pd.DataFrame()\n",
    "    if useMed:\n",
    "        thresh = inDF.median()\n",
    "    else:\n",
    "        thresh = inDF.mean()\n",
    "    for v in list(inDF): # loop over all columns\n",
    "        outDF[v] = (inDF[v] > thresh[v])\n",
    "    return outDF.values * 1\n",
    "\n",
    "# generate one-hot coding for issues with lots of missing votes\n",
    "def oneHot(data, colNames):\n",
    "    outDF = pd.DataFrame()\n",
    "    for col in colNames:\n",
    "        x = data[col]\n",
    "        for val in x.unique():\n",
    "            suff = 'q' if val=='?' else str(val)\n",
    "            outDF[col+'_'+suff] = (x==val)\n",
    "    return outDF\n",
    "\n",
    "def normalizeDF(data):\n",
    "    mins = data.min() # min of every col\n",
    "    maxs = data.max() # max of every col\n",
    "    return ((data-mins) / (maxs-mins)).values # normalize to [0,1]\n",
    "\n",
    "def classVecToMat(classVec):\n",
    "    uniqK = np.unique(classVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soyData = os.path.join('./data', 'soybean-small.data')\n",
    "soyNames = ['c%02d'%(n+1) for n in range(35)] + ['class']\n",
    "raw = pd.read_csv(soyData, names=soyNames)\n",
    "feats = np.array(soyNames)[raw.nunique()!=1] # remove feats with only 1 value\n",
    "raw = raw[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat = oneHot(raw, raw.columns[1:-1])\n",
    "dataMat['class'] = raw['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassData = os.path.join('./data/', 'glass.txt')\n",
    "glassNames = ['id','RI','Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'type']\n",
    "raw = pd.read_csv(glassData , names=glassNames ) # read in glass file\n",
    "glassTypes = pd.concat([raw['type'].isin([1,3]), raw['type'].isin([2,4]),\n",
    "                        raw['type'].isin([5,6,7])], axis=1).values * 1\n",
    "feats = glassNames[1:-1]\n",
    "glassMat = normalizeDF(raw[feats])\n",
    "glassDiscMat = discretizeMean(raw[feats])\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitLogisticNK(glassDiscMat, glassTypes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisFile = os.path.join('./data/', 'iris.data')\n",
    "irisName = ['sepalLen', 'sepalWth', 'petalLen', 'petalWth', 'class']\n",
    "raw = pd.read_csv(irisFile , names=irisName)  # read CSV file\n",
    "irisTypes = pd.concat([raw['class']==x for x in raw['class'].unique()],\n",
    "                     axis=1).values * 1\n",
    "feats = irisName[:-1]\n",
    "irisMat = normalizeDF(raw[feats])\n",
    "irisDiscMat = discretizeMean(raw[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitLogisticNK(irisMat, irisTypes, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_WI_data = os.path.join('./data/', 'breast-cancer-wisconsin.data')\n",
    "bc_WI_names = ['id', 'clumpThick', 'unifSize', 'unifShape', 'margAdhsn', \n",
    "               'epithSize', 'bareNuclei', 'blandChrom', 'normNucleo', \n",
    "               'mitoses', 'class']\n",
    "raw = pd.read_csv(bc_WI_data , names=bc_WI_names)  # read CSV file\n",
    "missRow = (raw=='?').any(axis=1).values # rows with missing data\n",
    "raw = raw[~missRow] # remove rows with missing\n",
    "raw = raw.apply(pd.to_numeric, errors= 'coerce') # conv to numeric data\n",
    "bcFeats = bc_WI_names[1:-1] # list of feature variables\n",
    "bcMat = raw[bcFeats].values\n",
    "bcDiscMat = discretizeMean(raw[bcFeats])\n",
    "malign = (raw['class']==4).values *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = getXVFolds(bcDiscMat, malign, categorical=True)\n",
    "testIdx = folds[0]\n",
    "trainIdx = np.hstack(folds[1:])\n",
    "trainData,trainLabel = bcDiscMat[trainIdx],malign[trainIdx]\n",
    "testData,testLabel = bcDiscMat[testIdx],malign[testIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final iteration #7734, error: 0.096037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0364963503649635"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt = fitLogisticReg(trainData, trainLabel, 0.1)\n",
    "np.mean(predLogistic(testData,wt)!=testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.34981685, 0.65018315]),\n",
       " [array([0.15104167, 0.171875  , 0.140625  , 0.21875   , 0.26041667,\n",
       "         0.14583333, 0.1875    , 0.19270833, 0.55729167]),\n",
       "  array([0.78651685, 0.9747191 , 0.95505618, 0.90449438, 0.95786517,\n",
       "         0.94662921, 0.95786517, 0.94101124, 0.96629213])])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prbs = NB_Train(trainData, trainLabel)\n",
    "prbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021897810218978103"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(NB_Pred(testData, prbs)==testLabel)/len(testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote84Data = os.path.join('./data', 'house-votes-84.data')\n",
    "vote84Names = ['party', 'infant', 'water', 'budget', 'doctorfee','salvador',\n",
    "              'religion', 'satellite', 'contras', 'missile', 'immigration',\n",
    "              'synfuels', 'education', 'superfund', 'crime', 'exports',\n",
    "              'ZAF']\n",
    "raw = pd.read_csv(vote84Data , names=vote84Names ) # read in vote file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotCols = oneHot(raw,['water','education','ZAF'])\n",
    "# remove variables with completed one-hot coding from list of variables\n",
    "yesVars = np.setdiff1d(vote84Names[1:],['water','education','ZAF'])\n",
    "yesVote = raw.loc[:,yesVars] == 'y' # boolean for vote='yes' for rest of vars\n",
    "yesVote.columns = [s+'_y' for s in yesVote.columns]\n",
    "repub = raw.loc[:,['party']] == 'republican' # boolean for republicans\n",
    "voteData = pd.concat([yesVote,oneHotCols], axis=1) # concat two dataframes\n",
    "voteMat = voteData.values * 1 # give matrixs of 0 & 1 for calculation\n",
    "repubVec = repub.values.ravel() * 1 # vector of 0 & 1 for calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = getXVFolds(voteMat, repubVec, categorical=True)\n",
    "testIdx = folds[0]\n",
    "trainIdx = np.hstack(folds[1:])\n",
    "trainData,trainLabel = voteMat[trainIdx],repubVec[trainIdx]\n",
    "testData,testLabel = voteMat[testIdx],repubVec[testIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condProb(data, add): # data assumed to be class-homogenous\n",
    "    ''' Calculate the conditional probability of a class-homogenous data set.\n",
    "    The function returns the conditional probability with Laplace smoothing. \n",
    "    Data matrix has to be binary 0-1.\n",
    "    '''\n",
    "    condPr = np.zeros(data.shape[1]) # pre-allocate cond probilities\n",
    "    for n,x in enumerate(data.T): # loop over the columns of the data\n",
    "        condPr[n] = (sum(x==0)+add)/(len(x)+add) # laplace smooth if needed\n",
    "    return condPr\n",
    "\n",
    "def NB_Train(data, classVec, smooth=True):\n",
    "    ''' Trains Naive Bayes on an input data matrix and class label. \n",
    "    If smooth = True, then Laplace smoothing is performed.\n",
    "\n",
    "    Returns 3-tuple of probabilities, cond prob of C=0, cond prob of C=1\n",
    "    '''\n",
    "    smoothAdd = smooth*1 # addition to num and denom for smoothing\n",
    "    if classVec.ndim==1: # binary class vector, transform into 2D\n",
    "        classVec = np.vstack([classVec==0,classVec==1]).T *1 # [0's, 1's]\n",
    "\n",
    "        \n",
    "    pr_class = np.empty(classVec.shape[1], float) # probability of classes\n",
    "    condPrs = list()\n",
    "    for n,vec in enumerate(classVec.T): # loop over classes\n",
    "        idx = (vec==1) # all data points belonging to this class\n",
    "        pr_class[n] = sum(idx) / len(idx) # uncond probability\n",
    "        condPrs.append( condProb(data[idx],smoothAdd) ) # calc cond probs\n",
    "    \n",
    "    return (pr_class,condPrs) # return class prob and cond probs\n",
    "\n",
    "def NB_Pred(data, probs): # predicting based on conditional probs\n",
    "    PrX = np.empty([len(data), len(probs[0])], float) # T-by-K matrix\n",
    "    for n,(pr,cond) in enumerate(zip(*probs)): # loop over classes\n",
    "        tmp = (data==0)*cond + (data==1)*(1-cond) # cond prob in class\n",
    "        #PrX[:,n] = pr * tmp.prod(axis=1) # prod of uncond and cond probs\n",
    "        PrX[:,n] = np.log(pr) + np.log(tmp).sum(axis=1) # sum log probabilities\n",
    "\n",
    "    return PrX.argmax(axis=1) # return most likely classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.65018315, 0.34981685]),\n",
       " [array([0.78651685, 0.9747191 , 0.95505618, 0.90449438, 0.95786517,\n",
       "         0.94662921, 0.95786517, 0.94101124, 0.96629213]),\n",
       "  array([0.15104167, 0.171875  , 0.140625  , 0.21875   , 0.26041667,\n",
       "         0.14583333, 0.1875    , 0.19270833, 0.55729167])])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prbs = NB_Train(trainData, trainLabel)\n",
    "prbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9781021897810219"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(NB_Pred(testData, prbs)==testLabel)/len(testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predLogistic(testData,wt)!=testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0]\n",
      " [0 1 1 1 0]\n",
      " [0 0 1 1 1]\n",
      " [1 0 0 1 0]\n",
      " [0 1 1 0 1]\n",
      " [0 1 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 1 0 1]\n",
      " [0 1 0 1 0]]\n",
      "[0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "testX = np.array([[1,1,1,0,0], [0,1,1,1,0], [0,0,1,1,1], [1,0,0,1,0], \n",
    "                  [0,1,1,0,1], [0,1,0,1,0], [1,0,0,0,0], [0,1,0,0,0], \n",
    "                  [1,0,1,0,1], [0,1,0,1,0]])\n",
    "testY = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "print(testX)\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5, 0.5]),\n",
       " [array([0.6, 0.4, 0.2, 0.4, 0.6]), array([0.6, 0.4, 0.8, 0.6, 0.8])])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_Train(testX, testY, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.77052344 -4.46367062]\n",
      " [-2.95959323 -4.46367062]\n",
      " [-3.77052344 -6.25543009]\n",
      " [-5.1568178  -3.88830648]\n",
      " [-3.77052344 -5.44449988]\n",
      " [-4.34588759 -3.07737626]\n",
      " [-5.56228291 -3.48284137]\n",
      " [-4.7513527  -2.67191115]\n",
      " [-4.58145366 -6.25543009]\n",
      " [-4.34588759 -3.07737626]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_Pred(testX, NB_Train(testX, testY, False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
