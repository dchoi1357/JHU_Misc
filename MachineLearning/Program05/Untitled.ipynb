{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concateIntercept(x):\n",
    "    return np.hstack( [np.ones((x.shape[0],1), x.dtype), x] )\n",
    "\n",
    "################################################################################\n",
    "def sigmoid(x, wt):\n",
    "    return 1.0 / ( 1 + np.exp(-x @ wt) )\n",
    "\n",
    "def crossEntropy(x, wt, y):\n",
    "    yhat = sigmoid(x, wt)\n",
    "    err = -np.mean(y*np.log(yhat) + (1-y)*np.log(1-yhat))\n",
    "    return err, yhat\n",
    "    \n",
    "def updateWeight(eta, yhat, y, x, wt):\n",
    "    d = (y - yhat) @ x / len(y)\n",
    "    return wt + (eta*d)\n",
    "\n",
    "def fitLogisticReg(x, y, eta, eps=1e-7, trace=False):\n",
    "    x = concateIntercept(x)\n",
    "    wt = np.random.rand(x.shape[1])/50 - 0.01 # initialize weights\n",
    "    lastErr = 0\n",
    "    err,yhat = crossEntropy(x, wt, y)\n",
    "\n",
    "    n = 0\n",
    "    while (abs(err-lastErr) > eps) and n < 1e6:\n",
    "        if n % 1000 == 0 and trace:\n",
    "            print('Iter #%u, error: %f'%(n,err))\n",
    "        wt = updateWeight(eta, yhat, y, x, wt)\n",
    "        lastErr = err\n",
    "        err,yhat = crossEntropy(x, wt, y)\n",
    "        if err > lastErr:\n",
    "            eta /= 10\n",
    "        n += 1\n",
    "    \n",
    "    print('Final iteration #%u, error: %f' % (n-1,err) )\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote84Data = os.path.join('./data', 'house-votes-84.data')\n",
    "vote84Names = ['party', 'infant', 'water', 'budget', 'doctorfee','salvador',\n",
    "              'religion', 'satellite', 'contras', 'missile', 'immigration',\n",
    "              'synfuels', 'education', 'superfund', 'crime', 'exports',\n",
    "              'ZAF']\n",
    "raw = pd.read_csv(vote84Data , names=vote84Names ) # read in vote file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one-hot coding for issues with lots of missing votes\n",
    "def oneHot(data, colName):\n",
    "    x = data.loc[:,colName]\n",
    "    oneHotMat = pd.concat([(x=='y'),(x=='n'),(x=='?')], axis=1)\n",
    "    oneHotMat.columns = [colName+'_'+suff for suff in ['y','n','q']]\n",
    "    return oneHotMat\n",
    "\n",
    "oneHotCols = pd.concat([oneHot(raw,'water'), oneHot(raw,'education'), \n",
    "                        oneHot(raw,'ZAF')], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXVFolds(dataMat, classVec, nFolds=5, categorical=False):\n",
    "    ''' Cut N-fold cross validation of the data set\n",
    "    Given a data matrix, a class vector, and the number of folds, the function\n",
    "    randomly cuts a 5-fold cross validation. If the data is categorical, \n",
    "    stratified sampling is used.\n",
    "    '''\n",
    "\n",
    "    idx = np.arange(dataMat.shape[0]) # construct index of data rows\n",
    "    if categorical:\n",
    "        unqs = np.unique(classVec)\n",
    "        tmpHold = [None] * len(unqs)\n",
    "        for n,k in enumerate(unqs):\n",
    "            grpIdx = idx[classVec==k] # idx of all elems in current class\n",
    "            np.random.shuffle(grpIdx) # permutate idx for random selection\n",
    "            tmpHold[n] = np.array_split(grpIdx, nFolds) # split: N equals\n",
    "        chunks = [np.hstack(k) for k in zip(*tmpHold)] # concat sub chunks\n",
    "    else:\n",
    "        np.random.shuffle(idx) # random shuffle data\n",
    "        chunks = np.array_split(idx, nFolds) # split into N equal sized chunks\n",
    "\n",
    "    return chunks # return the prediction of the last fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove variables with completed one-hot coding from list of variables\n",
    "yesVars = np.setdiff1d(vote84Names[1:],['water','education','ZAF'])\n",
    "yesVote = raw.loc[:,yesVars] == 'y' # boolean for vote='yes' for rest of vars\n",
    "yesVote.columns = [s+'_y' for s in yesVote.columns]\n",
    "repub = raw.loc[:,['party']] == 'republican' # boolean for republicans\n",
    "voteData = pd.concat([yesVote,oneHotCols], axis=1) # concat two dataframes\n",
    "voteMat = voteData.values * 1 # give matrixs of 0 & 1 for calculation\n",
    "repubVec = repub.values.ravel() * 1 # vector of 0 & 1 for calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = getXVFolds(voteMat, repubVec, categorical=True)\n",
    "trainIdx = folds[0]\n",
    "testIdx = np.hstack(folds[1:])\n",
    "trainData,trainLabel = voteMat[trainIdx],repubVec[trainIdx]\n",
    "testData,testLabel = voteMat[testIdx],repubVec[testIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #0, error: 0.687436\n",
      "Iter #1000, error: 0.073454\n",
      "Iter #2000, error: 0.050947\n",
      "Iter #3000, error: 0.039593\n",
      "Iter #4000, error: 0.032469\n",
      "Iter #5000, error: 0.027536\n",
      "Iter #6000, error: 0.023910\n",
      "Iter #7000, error: 0.021129\n",
      "Iter #8000, error: 0.018928\n",
      "Iter #9000, error: 0.017142\n",
      "Iter #10000, error: 0.015665\n",
      "Iter #11000, error: 0.014422\n",
      "Iter #12000, error: 0.013362\n",
      "Iter #13000, error: 0.012448\n",
      "Iter #14000, error: 0.011650\n",
      "Iter #15000, error: 0.010949\n",
      "Iter #16000, error: 0.010328\n",
      "Iter #17000, error: 0.009774\n",
      "Iter #18000, error: 0.009276\n",
      "Iter #19000, error: 0.008826\n",
      "Iter #20000, error: 0.008419\n",
      "Iter #21000, error: 0.008047\n",
      "Iter #22000, error: 0.007707\n",
      "Iter #23000, error: 0.007395\n",
      "Iter #24000, error: 0.007107\n",
      "Iter #25000, error: 0.006840\n",
      "Iter #26000, error: 0.006593\n",
      "Iter #27000, error: 0.006364\n",
      "Iter #28000, error: 0.006149\n",
      "Iter #29000, error: 0.005949\n",
      "Iter #30000, error: 0.005762\n",
      "Iter #31000, error: 0.005586\n",
      "Iter #32000, error: 0.005420\n",
      "Iter #33000, error: 0.005264\n",
      "Iter #34000, error: 0.005117\n",
      "Iter #35000, error: 0.004978\n",
      "Iter #36000, error: 0.004846\n",
      "Iter #37000, error: 0.004721\n",
      "Iter #38000, error: 0.004603\n",
      "Iter #39000, error: 0.004490\n",
      "Iter #40000, error: 0.004383\n",
      "Final iteration #40977, error: 0.004283\n"
     ]
    }
   ],
   "source": [
    "wts = fitLogisticReg(trainData, trainLabel, 0.1, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394812680115274"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((sigmoid(concateIntercept(testData), wts)>0.5)*1==testLabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
