{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def prepData(dataPathDir, fieldNames, featSlices, labelName, \n",
    "\t\t\t sep=',', transf=None):\n",
    "\traw = np.genfromtxt(dataPathDir, delimiter=sep, dtype=None,\n",
    "                        names=fieldNames, encoding='utf-8') # read dlm file\n",
    "\tif isinstance(featSlices, slice):\n",
    "\t\tdataFeats = fieldNames[featSlices] # list of feature names\n",
    "\telse:\n",
    "\t\tdataFeats = [fieldNames[i] for i in featSlices]\n",
    "\treturn raw[dataFeats],dataFeats,raw[labelName]\n",
    "\n",
    "def errRate(pred, actual, categorical=True):\n",
    "\tif categorical: # if categ., return classification err rate\n",
    "\t\treturn sum(pred!=actual) / pred.size\n",
    "\telse: # if numeric, return RMSE\n",
    "\t\treturn np.linalg.norm(pred-actual)/np.sqrt(pred.size)\n",
    "    \n",
    "def getCrossValidFolds(dataMat, classVec, nFolds=5, categorical=False):\n",
    "\t''' Cut N-fold cross validation of the data set\n",
    "\tGiven a data matrix, a class vector, and the number of folds, the function\n",
    "\trandomly cuts a 5-fold cross validation. If the data is categorical, \n",
    "\tstratified sampling is used.\n",
    "\t'''\n",
    "\t\n",
    "\tidx = np.arange(dataMat.shape[0]) # construct index of data rows\n",
    "\tif categorical:\n",
    "\t\tunqs = np.unique(classVec)\n",
    "\t\ttmpHold = [None] * len(unqs)\n",
    "\t\tfor n,k in enumerate(unqs):\n",
    "\t\t\tgrpIdx = idx[classVec==k] # idx of all elems in current class\n",
    "\t\t\tnp.random.shuffle(grpIdx) # permutate idx for random selection\n",
    "\t\t\ttmpHold[n] = np.array_split(grpIdx, nFolds) # split: N equals\n",
    "\t\tchunks = [np.hstack(k) for k in zip(*tmpHold)] # concat sub chunks\n",
    "\telse:\n",
    "\t\tnp.random.shuffle(idx) # random shuffle data\n",
    "\t\tchunks = np.array_split(idx, nFolds) # split into N equal sized chunks\n",
    "\n",
    "\treturn chunks # return the indices for folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 634),\n",
       " ('11', 487),\n",
       " ('12', 267),\n",
       " ('13', 203),\n",
       " ('14', 126),\n",
       " ('15', 103),\n",
       " ('16+', 261),\n",
       " ('6', 259),\n",
       " ('7', 391),\n",
       " ('8', 568),\n",
       " ('9', 689),\n",
       " ('<5', 189)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(ringLabel, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('M', 0.455, 0.365, 0.095, 0.514 , 0.2245, 0.101 , 0.15 ),\n",
       "       ('M', 0.35 , 0.265, 0.09 , 0.2255, 0.0995, 0.0485, 0.07 ),\n",
       "       ('F', 0.53 , 0.42 , 0.135, 0.677 , 0.2565, 0.1415, 0.21 ), ...,\n",
       "       ('M', 0.6  , 0.475, 0.205, 1.176 , 0.5255, 0.2875, 0.308),\n",
       "       ('F', 0.625, 0.485, 0.15 , 1.0945, 0.531 , 0.261 , 0.296),\n",
       "       ('M', 0.71 , 0.555, 0.195, 1.9485, 0.9455, 0.3765, 0.495)],\n",
       "      dtype=[('sex', '<U1'), ('length', '<f8'), ('diameter', '<f8'), ('height', '<f8'), ('wholeHt', '<f8'), ('shuckWt', '<f8'), ('visceraWt', '<f8'), ('shellWt', '<f8')])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.genfromtxt(abalonePath, delimiter=',', dtype=None, names=abaloneNames, encoding='utf-8')\n",
    "z[abaloneFeats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "class DTnode:\n",
    "    def __init__(self, attrib, splitPt=None, majority=None):\n",
    "        self.attrib = attrib\n",
    "        self.preEval = majority # early evaluation based on training majority\n",
    "        self.splitPoint = splitPt # if None, then categorical\n",
    "        self.isLeaf = True\n",
    "        self.children = dict()\n",
    "\n",
    "    def addChild(self, node, val):\n",
    "        self.isLeaf = False\n",
    "        self.children[val] = node\n",
    "        \n",
    "    def getChild(self, val):\n",
    "        return self.children[val]\n",
    "    \n",
    "    def getValues(self):\n",
    "        return self.children.keys()\n",
    "\n",
    "    def __repre__(self):\n",
    "        if self.isLeaf:\n",
    "            childTxt = 'terminal'\n",
    "        else:\n",
    "            childTxt = 'child: ' + str(list(self.children.keys()))\n",
    "        return '[Node for %s, %s ]'%(self.attrib, childTxt)\n",
    "    \n",
    "    def toStr(self, level=0):\n",
    "        if self.isLeaf:\n",
    "            return 'class: %s\\n' % self.attrib\n",
    "        else:\n",
    "            ret = 'Attribute [' + self.attrib + \"]:\\n\"\n",
    "            nx = level + 1\n",
    "            for key in self.children:\n",
    "                if self.splitPoint is None: # categorical var\n",
    "                    txt = '= %s'%key\n",
    "                else: # numerical var\n",
    "                    txt = '%s %f'%(key,self.splitPoint)\n",
    "                ret += \" \"*nx*4 + 'value %s, '%txt \\\n",
    "                    + self.children[key].toStr(nx)\n",
    "            return ret\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.toStr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [feat1]:\n",
      "  value < 2.450000, Attribute [feat2]:\n",
      "    value = a, class: class2\n",
      "    value = b, class: class3\n",
      "  value > 2.450000, class: class1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = DTnode('feat1', 2.45)\n",
    "a.addChild(DTnode('feat2'), '<')\n",
    "a.addChild(DTnode('class1'), '>')\n",
    "a.getChild('<').addChild(DTnode('class2'), 'a')\n",
    "a.getChild('<').addChild(DTnode('class3'), 'b')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "abalonePath = './data/abalone.data'\n",
    "abaloneNames = ['sex', 'length', 'diameter', 'height', 'wholeHt',\n",
    "                'shuckWt', 'visceraWt', 'shellWt', 'rings']\n",
    "abaloneData, abaloneFeats, ringVec = prepData(abalonePath,\n",
    "                                              abaloneNames, slice(-1),'rings')\n",
    "ringLabel = ringVec.astype(str)\n",
    "ringLabel[ringVec<=5] = '<5'\n",
    "ringLabel[ringVec>=16] = '16+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', '8', '16+'], dtype='<U11')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ringLabel[[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(array):\n",
    "    counts = np.unique(array, return_counts=True)[1]\n",
    "    probs = counts / counts.sum()\n",
    "    return -(probs*np.log2(probs)).sum()\n",
    "\n",
    "def IntInfo(counts):\n",
    "    s = sum(counts)\n",
    "    return -np.sum(np.log2(counts)*counts)/s + np.log2(s)\n",
    "\n",
    "################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitPoints(data,labels):\n",
    "    srtIdx = np.argsort(data) # get sorted index for data vector\n",
    "    srtdData = data[srtIdx] # data in sorted order\n",
    "    midpoints = (srtdData[:-1] + srtdData[1:])/2 # midpoints between data pts\n",
    "    srtdLabls = labels[srtIdx] # rearrange labels by sorted data order\n",
    "    diffLabel = srtdLabls[:-1] != srtdLabls[1:] # find midpt where labels changed\n",
    "    return midpoints[diffLabel] # return midpts where labels are different\n",
    "\n",
    "def getBestSplitInfo(data, labels, splitPts):\n",
    "    bestEntropy = np.Inf\n",
    "    bestPoint = None\n",
    "    bestPr = -1\n",
    "    for n,pt in enumerate(splitPts):\n",
    "        LT = data < pt\n",
    "        prLT = sum(LT) / data.size\n",
    "        ent = prLT*Entropy(labels[LT]) + (1-prLT)*Entropy(labels[~LT])\n",
    "        if ent < bestEntropy:\n",
    "            bestEntropy = ent\n",
    "            bestPoint = pt\n",
    "            bestPr = prLT\n",
    "    intrInfo = -bestPr*np.log2(bestPr) - (1-bestPr)*np.log2(1-bestPr)\n",
    "    return bestEntropy,bestPoint,intrInfo\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def SplitInfo(xs, ys):\n",
    "    if np.issubdtype(xs.dtype, np.number): # numeric features\n",
    "        splitPts = getSplitPoints(xs, ys)\n",
    "        meanEnt,splitPt,intrinsVal = getBestSplitInfo(xs, ys, splitPts)\n",
    "    else: # categorical features\n",
    "        vals, Ns = np.unique(xs, return_counts=True)\n",
    "        meanEnt = sum(Ns/len(ys) * [Entropy(ys[xs==v]) for v in vals])\n",
    "        intrinsVal = Entropy(xs)\n",
    "        splitPt = None\n",
    "    return meanEnt,intrinsVal,splitPt\n",
    "\n",
    "def selectBestFeature(data, labels, useRatio=True):\n",
    "    features = data.dtype.names\n",
    "    info = Entropy(labels)\n",
    "    gainRatios = np.empty(len(features))\n",
    "    splitPts = [None] * len(features)\n",
    "    for n,feat in enumerate(features):\n",
    "        expEntropy,intrnVal,splitPts[n] = SplitInfo(data[feat], labels)\n",
    "        try:\n",
    "            gainRatios[n] = (info - expEntropy) / (intrnVal if useRatio else 1)\n",
    "        except:\n",
    "            print((info,expEntropy,intrnVal))\n",
    "            print(data)\n",
    "            print(labels)\n",
    "            print(feat)\n",
    "            print((data.size),(labels.size))\n",
    "            print(Entropy(data))\n",
    "            print(Entropy(labels))\n",
    "            raise\n",
    "        #print(\"%s exp ent: %f\"%(feat,gainRatios[n]))\n",
    "    maxIdx = np.argmax(gainRatios)\n",
    "    return features[maxIdx],gainRatios[maxIdx],splitPts[maxIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def TrainDTree(allData, allLabels):\n",
    "    def c4_5(idx, featureSet, defLabel):\n",
    "        #print(allLabels)\n",
    "        #print(type(allLabels))\n",
    "        if sum(idx) == 0:# empty data, class = default label\n",
    "            return DTnode(defLabel)\n",
    "        data,labels = allData[idx][list(featureSet)],allLabels[idx]\n",
    "        \n",
    "        #print(labels)\n",
    "        #raise\n",
    "        \n",
    "        (values,counts) = np.unique(labels, return_counts=True)\n",
    "        majority = values[np.argmax(counts)] # get majority class as default\n",
    "        if len(counts)==1 or not featureSet: # homogenous or no attribs\n",
    "            return DTnode(majority)\n",
    "        \n",
    "        bestFeat,gainRatio,splitPt = selectBestFeature(data,labels)\n",
    "        featSubset = featureSet - set([bestFeat])\n",
    "        node = DTnode(bestFeat, splitPt, majority)\n",
    "        if splitPt is None: # no split point, categorical feature\n",
    "            for val in set(data[bestFeat]):\n",
    "                subIdx = idx[data[bestFeat] == val]\n",
    "                child = c4_5(subIdx, featSubset, majority)\n",
    "                node.addChild(child, val)\n",
    "        else: # numerical feature, 2 child nodes\n",
    "            subIdx = idx[data[bestFeat] < splitPt]\n",
    "            child = c4_5(subIdx, featSubset, majority)\n",
    "            node.addChild(child, '<')\n",
    "            subIdx = idx[data[bestFeat] > splitPt]\n",
    "            child = c4_5(subIdx, featSubset, majority)\n",
    "            node.addChild(child, '>')\n",
    "        return node\n",
    "################################################################################\n",
    "\n",
    "    uniqLabels,uniqCounts = np.unique(allLabels, return_counts=True)\n",
    "    labelMajority = uniqLabels[np.argmax(uniqCounts)]\n",
    "    allFeatures = set(allData.dtype.names) # set of all features\n",
    "    allIdx = np.arange(allData.size) # numeric idx of all rows\n",
    "    return c4_5(allIdx, allFeatures, labelMajority) # root of DTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = TrainDTree(abaloneData, ringLabel)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [Outlook]:\n",
      "    value = Rainy, Attribute [Windy]:\n",
      "        value = True, class: N\n",
      "        value = False, class: P\n",
      "    value = Sunny, Attribute [Humidity]:\n",
      "        value = Normal, class: P\n",
      "        value = High, class: N\n",
      "    value = Overcast, class: P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testTree = TrainDTree(testData, testLabel)\n",
    "print(testTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictDTree(tree, data):\n",
    "    def classify(d, node, idx):\n",
    "        if node.isLeaf:\n",
    "            result[idx] = node.attrib\n",
    "            return\n",
    "        else:\n",
    "            feat = node.attrib\n",
    "            if node.splitPoint is None: # categorical\n",
    "                for k in node.getValues():\n",
    "                    subIdx = np.logical_and(idx, data[feat]==k)\n",
    "                    classify(d, node.getChild(k), subIdx)\n",
    "            else: # numeric\n",
    "                subIdx = np.logical_and(idx, data[feat]<node.splitPoint)\n",
    "                \n",
    "################################################################################    \n",
    "    allIdx = np.ones(data.size, bool)\n",
    "    result = np.empty(data.size, object)\n",
    "    classify(data, tree, allIdx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8464393446710154, 4.5, 1.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(range(10))\n",
    "y = np.array(['A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'A'])\n",
    "\n",
    "getBestSplitInfo(x,y, getSplitPts(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 20, 10, 20, 20, 20, 30, 30, 50, 40, 40]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array( [10,10,20,10,20,20,20,30, 30,50,40,40] )\n",
    "aCounts = np.unique(a,return_counts=True)[1]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1409071979108386, 10), (0.22956749465992676, 10), (0.24396124711773237, 20), (0.2848779032897587, 10), (0.43729318365272074, 20), (0.5744742472226008, 20), (0.7917719120373218, 20), (0.8103201792707221, 30), (0.8234293458874453, 30), (0.8484049041354896, 50), (0.9442117713873419, 40), (0.993248981122507, 40)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23676437, 0.26441958, 0.36108554, 0.80104605, 0.83591713,\n",
       "       0.89630834])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(len(a))\n",
    "x.sort()\n",
    "print(list(zip(x,a)))\n",
    "\n",
    "getSplitPts(x,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Outlook', 0.24674981977443933, None)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = np.array([('Sunny', 'Hot', 'High', 'False', 'N'),\n",
    "                ('Sunny', 'Hot', 'High', 'True', 'N'),\n",
    "                ('Overcast', 'Hot', 'High', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'High', 'False', 'P'), \n",
    "                ('Rainy', 'Cool', 'Normal', 'False', 'P'), \n",
    "                ('Rainy', 'Cool', 'Normal', 'True', 'N'), \n",
    "                ('Overcast', 'Cool', 'Normal', 'True', 'P'), \n",
    "                ('Sunny', 'Mild', 'High', 'False', 'N'), \n",
    "                ('Sunny', 'Cool', 'Normal', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'Normal', 'False', 'P'), \n",
    "                ('Sunny', 'Mild', 'Normal', 'True', 'P'),\n",
    "                ('Overcast', 'Mild', 'High', 'True', 'P'),\n",
    "                ('Overcast', 'Hot', 'Normal', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'High', 'True', 'N')],\n",
    "               dtype=[('Outlook','U8'), ('Temperature','U4'), ('Humidity','U6'),\n",
    "                      ('Windy','U5'), ('Class','U1')]\n",
    "            )\n",
    "testData = raw[['Outlook','Temperature','Humidity','Windy']]\n",
    "testLabel = raw['Class']\n",
    "\n",
    "SplitInfo(testData['Temperature'], testLabel)\n",
    "selectBestFeature(testData, testLabel, useRatio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testData.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
