{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(dataPathDir, fieldNames, featSlices, labelName, \n",
    "\t\t\t sep=',', transf=None):\n",
    "\traw = pd.read_csv(dataPathDir , sep=sep, names=fieldNames) # read dlm file\n",
    "\tif isinstance(featSlices, slice):\n",
    "\t\tdataFeats = fieldNames[featSlices] # list of feature names\n",
    "\telse:\n",
    "\t\tdataFeats = [fieldNames[i] for i in featSlices]\n",
    "\tif transf is None: # no transformation\n",
    "\t\tdataMat = raw[dataFeats].values # original values\n",
    "\telif transf.lower() == 'std' : # if choose to standardize data\n",
    "\t\tmeanVals = raw[dataFeats].mean().values # mean of all features\n",
    "\t\tstdVals = raw[dataFeats].std().values # standard deviations\n",
    "\t\tdataMat = (raw[dataFeats].values - meanVals) / stdVals # [x-E(x)]/S(X)\n",
    "\telif transf.lower() == 'rescale': # rescale to values in [0,1]\n",
    "\t\tmins = raw[dataFeats].min().values # min of feature vals\n",
    "\t\tmaxs = raw[dataFeats].max().values # max of feature vals\n",
    "\t\tdataMat = (raw[dataFeats].values-mins) / (maxs-mins) # x-min/range(x)\n",
    "\telse: # error out\n",
    "\t\traise Exception('No such transformation available')\n",
    "\treturn dataMat,dataFeats,raw[labelName].values\n",
    "\n",
    "def errRate(pred, actual, categorical=True):\n",
    "\tif categorical: # if categ., return classification err rate\n",
    "\t\treturn sum(pred!=actual) / pred.size\n",
    "\telse: # if numeric, return RMSE\n",
    "\t\treturn np.linalg.norm(pred-actual)/np.sqrt(pred.size)\n",
    "    \n",
    "def getCrossValidFolds(dataMat, classVec, nFolds=5, categorical=False):\n",
    "\t''' Cut N-fold cross validation of the data set\n",
    "\tGiven a data matrix, a class vector, and the number of folds, the function\n",
    "\trandomly cuts a 5-fold cross validation. If the data is categorical, \n",
    "\tstratified sampling is used.\n",
    "\t'''\n",
    "\t\n",
    "\tidx = np.arange(dataMat.shape[0]) # construct index of data rows\n",
    "\tif categorical:\n",
    "\t\tunqs = np.unique(classVec)\n",
    "\t\ttmpHold = [None] * len(unqs)\n",
    "\t\tfor n,k in enumerate(unqs):\n",
    "\t\t\tgrpIdx = idx[classVec==k] # idx of all elems in current class\n",
    "\t\t\tnp.random.shuffle(grpIdx) # permutate idx for random selection\n",
    "\t\t\ttmpHold[n] = np.array_split(grpIdx, nFolds) # split: N equals\n",
    "\t\tchunks = [np.hstack(k) for k in zip(*tmpHold)] # concat sub chunks\n",
    "\telse:\n",
    "\t\tnp.random.shuffle(idx) # random shuffle data\n",
    "\t\tchunks = np.array_split(idx, nFolds) # split into N equal sized chunks\n",
    "\n",
    "\treturn chunks # return the indices for folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTnode:\n",
    "    def __init__(self, attrib):\n",
    "        self.attrib = attrib\n",
    "        self.isLeaf = True\n",
    "        self.children = dict()\n",
    "\n",
    "    def addChild(self, node, val):\n",
    "        self.isLeaf = False\n",
    "        self.children[val] = node\n",
    "        \n",
    "    def getChild(self, val):\n",
    "        return self.children[val]\n",
    "    \n",
    "    def getValues(self):\n",
    "        return self.children.keys()\n",
    "\n",
    "    def __repre__(self):\n",
    "        if self.isLeaf:\n",
    "            childTxt = 'terminal'\n",
    "        else:\n",
    "            childTxt = 'child: ' + str(list(self.children.keys()))\n",
    "        return '[Node for %s, %s ]'%(self.attrib, childTxt)\n",
    "    \n",
    "    def toStr(nd, level=0):\n",
    "        if nd.isLeaf:\n",
    "            return 'class: %s\\n' % nd.attrib\n",
    "        else:\n",
    "            ret = 'Attribute [' + nd.attrib + \"]:\\n\"\n",
    "            nx = level + 1\n",
    "            for key in nd.children:\n",
    "                ret += \" \"*nx*2 + 'value %s, '%key \\\n",
    "                    + toStr(nd.children[key],nx)\n",
    "            return ret\n",
    "    \n",
    "    def __str__(self):\n",
    "        return toStr(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(probs):\n",
    "    return sum(probs*np.log2(probs))\n",
    "\n",
    "def getProbs(labels):\n",
    "    uniqLbl,counts = np.unique(labels, return_counts=True)\n",
    "    return uniqLbl,counts/len(labels)\n",
    "\n",
    "def getSplitPts(data,labels):\n",
    "    srtIdx = np.argsort(data)\n",
    "    srtdData = data[srtIdx]\n",
    "    midpoints = (srtdData[:-1] + srtdData[1:])/2\n",
    "    srtdLabls = labels[srtIdx]\n",
    "    diffLabel = srtdLabls[:-1] != srtdLabls[1:]\n",
    "    return midpoints[diffLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entropy(np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array( [10,10,20,10,20,20,20,30, 30,50,40,40] )\n",
    "x,y = getProbs(np.array([1,1,1,1,1]))\n",
    "Entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1409071979108386, 10), (0.22956749465992676, 10), (0.24396124711773237, 20), (0.2848779032897587, 10), (0.43729318365272074, 20), (0.5744742472226008, 20), (0.7917719120373218, 20), (0.8103201792707221, 30), (0.8234293458874453, 30), (0.8484049041354896, 50), (0.9442117713873419, 40), (0.993248981122507, 40)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23676437, 0.26441958, 0.36108554, 0.80104605, 0.83591713,\n",
       "       0.89630834])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(len(a))\n",
    "x.sort()\n",
    "print(list(zip(x,a)))\n",
    "\n",
    "getSplitPts(x,a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
