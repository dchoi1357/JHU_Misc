{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def prepData(dataPathDir, fieldNames, featSlices, labelName, \n",
    "\t\t\t sep=',', transf=None):\n",
    "\traw = np.genfromtxt(dataPathDir, delimiter=sep, dtype=None,\n",
    "                        names=fieldNames, encoding='utf-8') # read dlm file\n",
    "\tif isinstance(featSlices, slice):\n",
    "\t\tdataFeats = fieldNames[featSlices] # list of feature names\n",
    "\telse:\n",
    "\t\tdataFeats = [fieldNames[i] for i in featSlices]\n",
    "\treturn raw[dataFeats],dataFeats,raw[labelName]\n",
    "\n",
    "def errRate(pred, actual, categorical=True):\n",
    "\tif categorical: # if categ., return classification err rate\n",
    "\t\treturn sum(pred!=actual) / pred.size\n",
    "\telse: # if numeric, return RMSE\n",
    "\t\treturn np.linalg.norm(pred-actual)/np.sqrt(pred.size)\n",
    "    \n",
    "def getCrossValidFolds(dataMat, classVec, nFolds=5, categorical=False):\n",
    "\t''' Cut N-fold cross validation of the data set\n",
    "\tGiven a data matrix, a class vector, and the number of folds, the function\n",
    "\trandomly cuts a 5-fold cross validation. If the data is categorical, \n",
    "\tstratified sampling is used.\n",
    "\t'''\n",
    "\t\n",
    "\tidx = np.arange(dataMat.shape[0]) # construct index of data rows\n",
    "\tif categorical:\n",
    "\t\tunqs = np.unique(classVec)\n",
    "\t\ttmpHold = [None] * len(unqs)\n",
    "\t\tfor n,k in enumerate(unqs):\n",
    "\t\t\tgrpIdx = idx[classVec==k] # idx of all elems in current class\n",
    "\t\t\tnp.random.shuffle(grpIdx) # permutate idx for random selection\n",
    "\t\t\ttmpHold[n] = np.array_split(grpIdx, nFolds) # split: N equals\n",
    "\t\tchunks = [np.hstack(k) for k in zip(*tmpHold)] # concat sub chunks\n",
    "\telse:\n",
    "\t\tnp.random.shuffle(idx) # random shuffle data\n",
    "\t\tchunks = np.array_split(idx, nFolds) # split into N equal sized chunks\n",
    "\n",
    "\treturn chunks # return the indices for folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 634),\n",
       " ('11', 487),\n",
       " ('12', 267),\n",
       " ('13', 203),\n",
       " ('14', 126),\n",
       " ('15', 103),\n",
       " ('16+', 261),\n",
       " ('6', 259),\n",
       " ('7', 391),\n",
       " ('8', 568),\n",
       " ('9', 689),\n",
       " ('<5', 189)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(ringLabel, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "class DTnode:\n",
    "    def __init__(self, attrib, splitPt=None, majority=None):\n",
    "        self.attrib = attrib\n",
    "        self.preEval = majority # early evaluation based on training majority\n",
    "        self.splitPoint = splitPt # if None, then categorical\n",
    "        self.isLeaf = True\n",
    "        self.children = dict()\n",
    "        self.nCorr = -1 # for storing error info for pruning\n",
    "\n",
    "    def addChild(self, node, val):\n",
    "        self.isLeaf = False\n",
    "        self.children[val] = node\n",
    "        \n",
    "    def getChild(self, val):\n",
    "        return self.children[val]\n",
    "    \n",
    "    def getValues(self):\n",
    "        return self.children.keys()\n",
    "    \n",
    "    def getChildCorrNum(self):\n",
    "        return [nd.nCorr for k,nd in self.children.items()]\n",
    "    \n",
    "    def makeLeafNode(self, attrib, nCorrPred=-1):\n",
    "        self.attrib = attrib\n",
    "        self.preEval = None\n",
    "        self.isLeaf = True\n",
    "        self.children = dict()\n",
    "        self.nCorr = nCorrPred\n",
    "    \n",
    "    def combineChildNodes(self):\n",
    "        if self.isLeaf:\n",
    "            return set([self.attrib])\n",
    "        subLabl = set()\n",
    "        for k,child in self.children.items(): # loop over all child nodes\n",
    "            subLabl.update( child.combineChildNodes() )\n",
    "        if len(subLabl) == 1: # only one class for all child nodes\n",
    "            self.makeLeafNode( next(iter(subLabl)) )\n",
    "        return subLabl\n",
    "\n",
    "    def __repre__(self):\n",
    "        if self.isLeaf:\n",
    "            childTxt = 'terminal'\n",
    "        else:\n",
    "            childTxt = 'child: ' + str(list(self.children.keys()))\n",
    "        return '[Node for %s, %s ]'%(self.attrib, childTxt)\n",
    "    \n",
    "    def toStr(self, level=0):\n",
    "        if self.isLeaf:\n",
    "            return 'class: %s\\n' % self.attrib\n",
    "        else:\n",
    "            ret = 'Attribute [' + self.attrib + \"]:\\n\"\n",
    "            nx = level + 1\n",
    "            for key in self.children:\n",
    "                if self.splitPoint is None: # categorical var\n",
    "                    txt = '= %s'%key\n",
    "                else: # numerical var\n",
    "                    txt = '%s %f'%(key,self.splitPoint)\n",
    "                ret += \" \"*nx*4 + 'value %s, '%txt \\\n",
    "                    + self.children[key].toStr(nx)\n",
    "            return ret\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.toStr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [feat1]:\n",
      "    value < 2.450000, Attribute [feat2]:\n",
      "        value = a, class: class2\n",
      "        value = b, class: class2\n",
      "    value > 2.450000, class: class1\n",
      "\n",
      "Attribute [feat1]:\n",
      "    value < 2.450000, class: class2\n",
      "    value > 2.450000, class: class1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = DTnode('feat1', 2.45)\n",
    "a.addChild(DTnode('feat2'), '<')\n",
    "a.addChild(DTnode('class1'), '>')\n",
    "a.getChild('<').addChild(DTnode('class2'), 'a')\n",
    "a.getChild('<').addChild(DTnode('class2'), 'b')\n",
    "print(a)\n",
    "\n",
    "a.combineChildNodes()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(array):\n",
    "    counts = np.unique(array, return_counts=True)[1]\n",
    "    probs = counts / counts.sum()\n",
    "    return -(probs*np.log2(probs)).sum()\n",
    "\n",
    "def IntInfo(counts):\n",
    "    s = sum(counts)\n",
    "    return -np.sum(np.log2(counts)*counts)/s + np.log2(s)\n",
    "\n",
    "################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitPoints(data,labels):\n",
    "    srtIdx = np.argsort(data) # get sorted index for data vector\n",
    "    srtdData = data[srtIdx] # data in sorted order\n",
    "    midpoints = (srtdData[:-1] + srtdData[1:])/2 # midpoints between data pts\n",
    "    srtdLabls = labels[srtIdx] # rearrange labels by sorted data order\n",
    "    diffLabel = srtdLabls[:-1] != srtdLabls[1:] # find midpt where labels changed\n",
    "    return midpoints[diffLabel] # return midpts where labels are different\n",
    "\n",
    "def getBestSplitInfo(data, labels, splitPts):\n",
    "    bestEntropy = np.Inf\n",
    "    bestPoint = None\n",
    "    bestPr = -1\n",
    "    for n,pt in enumerate(splitPts):\n",
    "        LT = data < pt\n",
    "        prLT = sum(LT) / data.size\n",
    "        ent = prLT*Entropy(labels[LT]) + (1-prLT)*Entropy(labels[~LT])\n",
    "        if ent < bestEntropy:\n",
    "            bestEntropy = ent\n",
    "            bestPoint = pt\n",
    "            bestPr = prLT\n",
    "            \n",
    "    if (bestPr-0) < np.finfo(bestPr.dtype).eps: # if homogenous data, prob=0\n",
    "        intrInfo = 0\n",
    "    else:\n",
    "        intrInfo = -bestPr*np.log2(bestPr) - (1-bestPr)*np.log2(1-bestPr)\n",
    "    return bestEntropy,bestPoint,intrInfo\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def SplitInfo(xs, ys):\n",
    "    if np.issubdtype(xs.dtype, np.number): # numeric features\n",
    "        splitPts = getSplitPoints(xs, ys)\n",
    "        meanEnt,splitPt,intrinsVal = getBestSplitInfo(xs, ys, splitPts)\n",
    "    else: # categorical features\n",
    "        vals, Ns = np.unique(xs, return_counts=True)\n",
    "        meanEnt = sum(Ns/len(ys) * [Entropy(ys[xs==v]) for v in vals])\n",
    "        intrinsVal = Entropy(xs)\n",
    "        splitPt = None\n",
    "    return meanEnt,intrinsVal,splitPt\n",
    "\n",
    "def selectBestFeature(data, labels, useRatio=True):\n",
    "    features = data.dtype.names\n",
    "    info = Entropy(labels)\n",
    "    gains = np.empty(len(features))\n",
    "    gainRatios = np.empty(len(features))\n",
    "    splitPts = [None] * len(features)\n",
    "    for n,feat in enumerate(features):\n",
    "        expEntropy,intrnVal,splitPts[n] = SplitInfo(data[feat], labels)\n",
    "        gains[n] = info-expEntropy\n",
    "        gainRatios[n] = gains[n] / (0.01+intrnVal if useRatio else 1)\n",
    "        #print(\"%s exp ent: %f\"%(feat,gainRatios[n]))\n",
    "    maxN = np.argmax(gainRatios)\n",
    "    return features[maxN],gainRatios[maxN],splitPts[maxN],gains[maxN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def TrainDTree(allData, allLabels, minGain=0):\n",
    "    def c4_5(idx, featureSet, defLabel):\n",
    "        if sum(idx) == 0:# empty data, class = default label\n",
    "            return DTnode(defLabel)\n",
    "        data,labels = allData[idx][list(featureSet)],allLabels[idx]\n",
    "        \n",
    "        (values,counts) = np.unique(labels, return_counts=True)\n",
    "        majority = values[np.argmax(counts)] # get majority class as default\n",
    "        if len(counts)==1 or not featureSet: # homogenous or no attribs\n",
    "            return DTnode(majority)\n",
    "        \n",
    "        bestFeat,gainRatio,splitPt,gain = selectBestFeature(data,labels)\n",
    "        #print('GainR=%f, Gain=%f'%(gainRatio,gain))\n",
    "        if gainRatio < minGain: # early stopping if gain < defined thresh\n",
    "            return DTnode(majority)\n",
    "        \n",
    "        featSubset = featureSet - set([bestFeat])\n",
    "        node = DTnode(bestFeat, splitPt, majority)\n",
    "        if splitPt is None: # no split point, categorical feature\n",
    "            for val in set(data[bestFeat]):\n",
    "                subIdx = idx[data[bestFeat] == val]\n",
    "                child = c4_5(subIdx, featSubset, majority)\n",
    "                node.addChild(child, val)\n",
    "        else: # numerical feature, 2 child nodes\n",
    "            subIdx = idx[data[bestFeat] < splitPt]\n",
    "            child = c4_5(subIdx, featSubset, majority)\n",
    "            node.addChild(child, '<')\n",
    "            subIdx = idx[data[bestFeat] > splitPt]\n",
    "            child = c4_5(subIdx, featSubset, majority)\n",
    "            node.addChild(child, '>')\n",
    "        return node\n",
    "################################################################################\n",
    "\n",
    "    uniqLabels,uniqCounts = np.unique(allLabels, return_counts=True)\n",
    "    labelMajority = uniqLabels[np.argmax(uniqCounts)]\n",
    "    allFeatures = set(allData.dtype.names) # set of all features\n",
    "    allIdx = np.arange(allData.size) # numeric idx of all rows\n",
    "    return c4_5(allIdx, allFeatures, labelMajority) # root of DTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "abalonePath = './data/abalone.data'\n",
    "abaloneNames = ['sex', 'length', 'diameter', 'height', 'wholeHt',\n",
    "                'shuckWt', 'visceraWt', 'shellWt', 'rings']\n",
    "abaloneData, abaloneFeats, ringVec = prepData(abalonePath,\n",
    "                                              abaloneNames, slice(-1),'rings')\n",
    "ringLabel = ringVec.astype(str)\n",
    "ringLabel[ringVec<=5] = '<5'\n",
    "ringLabel[ringVec>=16] = '16+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = TrainDTree(abaloneData, ringLabel, 0.1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.combineChildNodes())\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [Outlook]:\n",
      "    value = Rainy, Attribute [Windy]:\n",
      "        value = True, class: N\n",
      "        value = False, class: P\n",
      "    value = Sunny, Attribute [Humidity]:\n",
      "        value = Normal, class: P\n",
      "        value = High, class: N\n",
      "    value = Overcast, class: P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testTree = TrainDTree(testData, testLabel)\n",
    "print(testTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictDTree(tree, data):\n",
    "    def classify(node, idx):\n",
    "        ndData = data[idx] # portion of data for this node\n",
    "        if node.isLeaf:\n",
    "            result[idx] = node.attrib\n",
    "            return\n",
    "        else:\n",
    "            feat = node.attrib\n",
    "            if node.splitPoint is None: # categorical\n",
    "                for k in node.getValues():\n",
    "                    subIdx = idx[ ndData[feat]==k ]\n",
    "                    classify(node.getChild(k), subIdx)\n",
    "            else: # numeric\n",
    "                subIdx = idx[ ndData[feat]<node.splitPoint ]\n",
    "                classify(node.getChild('<'), subIdx)\n",
    "                subIdx = idx[ ndData[feat]>node.splitPoint ]\n",
    "                classify(node.getChild('>'), subIdx)\n",
    "            return\n",
    "\n",
    "    allIdx = np.arange(data.size)\n",
    "    result = np.empty(data.size, object)\n",
    "    classify(tree, allIdx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################    \n",
    "def PruneDTree(tree, data, actuals):\n",
    "    def prune(node, idx):\n",
    "        ndData,ndActs = data[idx],actuals[idx] # data and labels for the node\n",
    "        if node.isLeaf:\n",
    "            result[idx] = node.attrib\n",
    "            node.nCorr = sum(result[idx]==ndActs) # save nCorrect preds\n",
    "            return\n",
    "        else:\n",
    "            feat = node.attrib\n",
    "            if node.splitPoint is None: # categorical\n",
    "                for k in node.getValues():\n",
    "                    subIdx = idx[ ndData[feat]==k ]\n",
    "                    prune(node.getChild(k), subIdx)\n",
    "            else: # numeric\n",
    "                subIdx = idx[ ndData[feat]<node.splitPoint ]\n",
    "                prune(node.getChild('<'), subIdx)\n",
    "                subIdx = idx[ ndData[feat]>node.splitPoint ]\n",
    "                prune(node.getChild('>'), subIdx)\n",
    "            \n",
    "            node.nCorr = sum(node.getChildCorrNum()) # sum childNodes error nums\n",
    "            nCorrNaive = sum(ndActs==node.preEval) # nCorr using label majority\n",
    "            if nCorrNaive > node.nCorr: # if majority class is better than C4.5\n",
    "                node.makeLeafNode(node.preEval, nCorrNaive)\n",
    "            return\n",
    "                \n",
    "################################################################################    \n",
    "    allIdx = np.arange(data.size)\n",
    "    prune(tree, allIdx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8464393446710154, 4.5, 1.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(range(10))\n",
    "y = np.array(['A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'A'])\n",
    "\n",
    "getBestSplitInfo(x,y, getSplitPts(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 20, 10, 20, 20, 20, 30, 30, 50, 40, 40]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array( [10,10,20,10,20,20,20,30, 30,50,40,40] )\n",
    "aCounts = np.unique(a,return_counts=True)[1]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Outlook', 0.24674981977443933, None, 0.24674981977443933)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = np.array([('Sunny', 'Hot', 'High', 'False', 'N'),\n",
    "                ('Sunny', 'Hot', 'High', 'True', 'N'),\n",
    "                ('Overcast', 'Hot', 'High', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'High', 'False', 'P'), \n",
    "                ('Rainy', 'Cool', 'Normal', 'False', 'P'), \n",
    "                ('Rainy', 'Cool', 'Normal', 'True', 'N'), \n",
    "                ('Overcast', 'Cool', 'Normal', 'True', 'P'), \n",
    "                ('Sunny', 'Mild', 'High', 'False', 'N'), \n",
    "                ('Sunny', 'Cool', 'Normal', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'Normal', 'False', 'P'), \n",
    "                ('Sunny', 'Mild', 'Normal', 'True', 'P'),\n",
    "                ('Overcast', 'Mild', 'High', 'True', 'P'),\n",
    "                ('Overcast', 'Hot', 'Normal', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'High', 'True', 'N')],\n",
    "               dtype=[('Outlook','U8'), ('Temperature','U4'), ('Humidity','U6'),\n",
    "                      ('Windy','U5'), ('Class','U1')]\n",
    "            )\n",
    "testData = raw[['Outlook','Temperature','Humidity','Windy']]\n",
    "testLabel = raw['Class']\n",
    "\n",
    "SplitInfo(testData['Temperature'], testLabel)\n",
    "selectBestFeature(testData, testLabel, useRatio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute [Outlook]:\n",
      "    value = Sunny, Attribute [Humidity]:\n",
      "        value = Normal, class: P\n",
      "        value = High, class: N\n",
      "    value = Overcast, class: P\n",
      "    value = Rainy, Attribute [Windy]:\n",
      "        value = True, class: N\n",
      "        value = False, class: P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testTree = TrainDTree(testData,testLabel)\n",
    "print(testTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.array([('Sunny', 'Hot', 'High', 'False', 'N'),\n",
    "                ('Sunny', 'Hot', 'High', 'True', 'P'),\n",
    "                ('Overcast', 'Hot', 'High', 'False', 'P'), \n",
    "                ('Rainy', 'Mild', 'High', 'False', 'P')],\n",
    "               dtype=[('Outlook','U8'), ('Temperature','U4'), ('Humidity','U6'),\n",
    "                      ('Windy','U5'), ('Class','U1')]\n",
    "            )\n",
    "valData = val[['Outlook','Temperature','Humidity','Windy']]\n",
    "valAct = val['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valData['Outlook']=='Rainy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = PredictDTree(testTree, valData, valAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "print( testTree.nCorr )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
