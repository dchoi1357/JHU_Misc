{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseDist(x, y=None):\n",
    "    if y is None:\n",
    "        y = x\n",
    "    return np.sum((x[:,None]-y)**2,axis=2)**0.5\n",
    "\n",
    "def prepData(dataPathDir, fieldNames, featSlices, labelName, \n",
    "             sep=',', transf=None):\n",
    "    raw = pd.read_csv(dataPathDir , sep=sep, names=fieldNames) # read dlm file\n",
    "    if isinstance(featSlices, slice):\n",
    "        dataFeats = fieldNames[featSlices] # list of feature names\n",
    "    else:\n",
    "        dataFeats = [fieldNames[i] for i in featSlices]\n",
    "    if transf is None: # no transformation\n",
    "        dataMat = raw[dataFeats].values # original values\n",
    "    elif transf.lower() == 'std' : # if choose to standardize data\n",
    "        meanVals = raw[dataFeats].mean().values # mean of all features\n",
    "        stdVals = raw[dataFeats].std().values # standard deviations\n",
    "        dataMat = (raw[dataFeats].values - meanVals) / stdVals # [x-E(x)]/S(X)\n",
    "    elif transf.lower() == 'rescale': # rescale to values in [0,1]\n",
    "        mins = raw[dataFeats].min().values # min of feature vals\n",
    "        maxs = raw[dataFeats].max().values # max of feature vals\n",
    "        dataMat = (raw[dataFeats].values-mins) / (maxs-mins) # x-min/range(x)\n",
    "    else: # error out\n",
    "        raise Exception('No such transformation available')\n",
    "    return dataMat,dataFeats,raw[labelName].values\n",
    "\n",
    "def errRate(pred, actual, categorical=True):\n",
    "    if categorical: # if categ., return classification err rate\n",
    "        return sum(pred!=actual) / pred.size\n",
    "    else: # if numeric, return RMSE\n",
    "        return np.linalg.norm(pred-actual)/np.sqrt(pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostCommonElem(elems):\n",
    "    counts = dict() # dict to keep track of counts\n",
    "    for e in elems: # loop over array\n",
    "        counts[e] = counts.get(e,0) + 1 # increase count by 1 (def count of 0)\n",
    "    maxCount = -1\n",
    "    for e,ct in counts.items(): # loop over counts, set maxCount if count larger\n",
    "        maxCount = ct if ct > maxCount else maxCount\n",
    "    # get list of elems which has same count as maxCount (if multiple elems)\n",
    "    mostFreqElem = [e for e,ct in counts.items() if ct==maxCount]\n",
    "    return np.random.choice(mostFreqElem) # randomly choose one elemn from all\n",
    "\n",
    "def kMinValIdx(mat, k):\n",
    "    mat = np.copy(mat) # create copy of variable\n",
    "    if mat.size == 1:\n",
    "        return np.array([[0]]),mat\n",
    "    if mat.ndim == 1:\n",
    "        mat = mat.reshape([1,-1])\n",
    "    idx = np.ones(mat.shape,int).cumsum(axis=1)-1 # rows of idx: 0,1,...,nCol\n",
    "    \n",
    "    for it in range(k): # perform k bubbles to get k smallest\n",
    "        for col in range(mat.shape[1]-it-1):\n",
    "            toSwap = mat[:,col] < mat[:,col+1] # if elem smaller than next elem\n",
    "            # swap cols of data matrix and matrix of indices\n",
    "            mat[np.ix_(toSwap,[col,col+1])] = mat[np.ix_(toSwap,[col+1,col])]\n",
    "            idx[np.ix_(toSwap,[col,col+1])] = idx[np.ix_(toSwap,[col+1,col])]\n",
    "    return idx[:,-k:],mat[:,-k:] # return smallest elemenst per row and the idxs\n",
    "\n",
    "################################################################################\n",
    "def KNN(trainX, trainY, testX, K, categorical):\n",
    "    dists = pairwiseDist(testX, trainX) # all pairwise dist of two datasets\n",
    "    knnIdx,_ = kMinValIdx(dists, K) # idx of K closest data pts in training set\n",
    "    knnLabels = trainY[knnIdx] # labels of these closest data points\n",
    "    \n",
    "    testY = np.empty(testX.shape, trainY.dtype) # pre-allocate test data labels\n",
    "    if not categorical: # regression, calculate mean\n",
    "        testY = knnLabels.mean(axis=1) # mean of k-closest label values\n",
    "    else: # classification, get most common class label\n",
    "        testY = np.array([mostCommonElem(lab) for lab in knnLabels])\n",
    "    return testY # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickAndRemove(arr):\n",
    "    j = np.random.randint(arr.size)\n",
    "    return arr[j], np.delete(arr,j)\n",
    "    \n",
    "def consistentSubset(trainX, trainY, K=1):\n",
    "    dists = pairwiseDist(trainX) # all pairwise dist of two datasets\n",
    "    idx = np.arange(trainX.shape[0]) # construct index of data rows\n",
    "    Z,idx = pickAndRemove(idx) # randomly pick 1st pt of of subset \n",
    "\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        converged = True # stop unless a misclassification\n",
    "        np.random.shuffle(idx) # shuffle sequence of sample to train randomly\n",
    "        \n",
    "        for x in idx: # loop over all samples\n",
    "            nnIdx = kMinValIdx(dists[x,Z], 1)[0] # idx of NN in Z\n",
    "            nnLabel = trainY[nnIdx].flatten() # label of NN of x in Z\n",
    "            if nnLabel!=trainY[x]: # if misclassification\n",
    "                Z = np.hstack([Z,x]) # add to consistent subset\n",
    "                converged = False # continue training\n",
    "        idx = np.setdiff1d(idx, Z) # remove training set from samples\n",
    "        \n",
    "    return Z, idx\n",
    "################################################################################\n",
    "def CNN(trainX, trainY, testX, K):\n",
    "    subset,dataIdx = consistentSubset(trainX, trainY) # find consist. subset\n",
    "    \n",
    "    # use consistent subset as the training set instead of entirety\n",
    "    return KNN(trainX[subset,:], trainY[subset,:], testX, K, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331,)\n",
      "(336, 7)\n"
     ]
    }
   ],
   "source": [
    "z = consistentSubset(ecoliMat, ecoliY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n",
      "['r' 'r' 'r' 'r' 'r' 'g' 'g' 'g' 'g']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([8, 5, 6, 7]), array([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = np.array([[2,1], [1,2], [2,3], [3,2], [4,1],\n",
    "                  [5,1.5], [4,2.5], [6,3], [5,4]])\n",
    "testY = np.array(['r', 'r', 'r', 'r', 'r', 'g', 'g', 'g', 'g'])\n",
    "consistentSubset(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCrossValidFolds(dataMat, classVec, nFolds=5, categorical=False):\n",
    "    ''' Cut N-fold cross validation of the data set\n",
    "    '''\n",
    "    \n",
    "    idx = np.arange(dataMat.shape[0]) # construct index of data rows\n",
    "    if categorical:\n",
    "        unqs = np.unique(classVec)\n",
    "        tmpHold = [None] * len(unqs)\n",
    "        for n,k in enumerate(unqs):\n",
    "            grpIdx = idx[classVec==k] # idx of all elems in current class\n",
    "            np.random.shuffle(grpIdx) # permutate idx for random selection\n",
    "            tmpHold[n] = np.array_split(grpIdx, nFolds) # split: N equals\n",
    "        chunks = [np.hstack(k) for k in zip(*tmpHold)] # concat sub chunks\n",
    "    else:\n",
    "        np.random.shuffle(idx) # random shuffle data\n",
    "        chunks = np.array_split(idx, nFolds) # split into N equal sized chunks\n",
    "\n",
    "    return chunks # return the prediction of the last fold\n",
    "\n",
    "def crossValidate(dataMat, labels, chunks, k, categ):\n",
    "    err = np.empty(len(chunks))\n",
    "    \n",
    "    for ck in range(len(chunks)):\n",
    "        # get index and dataset for current fold of cross-validation\n",
    "        trnIdx = np.hstack([x for n,x in enumerate(chunks) if n != ck])\n",
    "        vldIdx = np.hstack([x for n,x in enumerate(chunks) if n == ck])\n",
    "        dataTrain,labelTrain = dataMat[trnIdx,:],labels[trnIdx] # training\n",
    "        dataTest,labelTest = dataMat[vldIdx,:],labels[vldIdx] # validation\n",
    "        \n",
    "        pred = KNN(dataTrain, labelTrain, dataTest, k, categorical=categ)\n",
    "        err[ck] = errRate(pred, labelTest, categorical=categ)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneK(dataMat, labels, folds, categ):\n",
    "    Ks = np.arange(1,11)\n",
    "    err = np.empty(len(Ks))\n",
    "    \n",
    "    pick = np.random.randint(len(folds)) # randomly pick fold as validation set\n",
    "    trnIdx = np.hstack([x for n,x in enumerate(folds) if n != pick]) # train\n",
    "    vldIdx = np.hstack([x for n,x in enumerate(folds) if n == pick]) # validate\n",
    "    dataTrain,labelTrain = dataMat[trnIdx,:],labels[trnIdx] # training\n",
    "    dataTest,labelTest = dataMat[vldIdx,:],labels[vldIdx] # validation\n",
    "    \n",
    "    for n,k in enumerate(Ks):\n",
    "        pred = KNN(dataTrain, labelTrain, dataTest, k, categorical=categ)\n",
    "        err[n] = errRate(pred, labelTest, categorical=categ)\n",
    "    \n",
    "    return Ks[np.argmin(err)], err # return K with smallest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoliPD = './data/ecoli.data'\n",
    "ecoliVars = ['seq', 'mcg', 'gvh', 'lip', 'chg', 'aac', 'alm1', 'alm2', 'class']\n",
    "################################################################################\n",
    "ecoliMat,ecoliFeat,ecoliY = prepData(ecoliPD, ecoliVars, slice(1,-1), \"class\", r'\\s+')\n",
    "folds = getCrossValidFolds(ecoliMat, ecoliY, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15714286, 0.12857143, 0.15151515, 0.09230769, 0.15384615])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minK,errs = tuneK(ecoliMat, ecoliY, folds, categ=True)\n",
    "crossValidate(ecoliMat, ecoliY, folds, minK, categ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "firePD = './data/forestfires.data'\n",
    "fireVars = ['X', 'Y', 'month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp',\n",
    "           'RH', 'wind', 'rain', 'area']\n",
    "fireIdx = [0,1] + list(range(4,12))\n",
    "fireMat,fireFeats,fireY = prepData(firePD, fireVars, fireIdx, \"area\", transf=\"rescale\")\n",
    "fireY = np.log(fireY+1)\n",
    "################################################################################\n",
    "folds = getCrossValidFolds(fireMat, fireY, categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33034192, 0.91914206, 1.53770281, 1.28881287, 1.29043012])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minK,errs = tuneK(fireMat, fireY, folds, categ=False)\n",
    "np.exp(crossValidate(fireMat, fireY, folds, minK, categ=False))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "machPD = './data/machine.data'\n",
    "machVars = ['vendor', 'model', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', \n",
    "             'CHMAX', 'PRP', 'ERP']\n",
    "################################################################################\n",
    "machMat,machFeat,machY = prepData(machPD, machVars, slice(2,-2), \"PRP\", transf='rescale')\n",
    "folds = getCrossValidFolds(machMat, machY, categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57.7579102 , 85.21778822, 56.77461706, 52.70267003, 39.06155243])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minK,errs = tuneK(machMat, machY, folds, categ=False)\n",
    "crossValidate(machMat, machY, folds, minK, categ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "segPD = './data/segmentation.data'\n",
    "segVars = ['class', 'cent-col', 'cent-row', 'pixel-count', 'sl-density-5', \n",
    "             'sl-density-2', 'vedge-mean', 'vegde-sd', 'hedge-mean', 'hedge-sd',\n",
    "             'intense-m', 'rawred-m', 'rawblue-m', 'rawgreen-m', 'exred-m', \n",
    "             'exblue-m', 'exgreen-m', 'value-m', 'saturate-m', 'hue-m']\n",
    "segIdx = [1,2] + list(range(4,19))\n",
    "################################################################################\n",
    "segMat,segFeat,segY = prepData(segPD, segVars, segIdx, \"class\", transf=None)\n",
    "folds = getCrossValidFolds(segMat, segY, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.16666667, 0.0952381 , 0.28571429, 0.21428571])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minK,errs = tuneK(segMat, segY, folds, categ=True)\n",
    "crossValidate(segMat, segY, folds, minK, categ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15714285714285714"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnIdx = np.hstack([x for n,x in enumerate(folds) if n != 1])\n",
    "vldIdx = np.hstack([x for n,x in enumerate(folds) if n == 1])\n",
    "\n",
    "pred = KNN(ecoliMat[trnIdx], ecoliY[trnIdx], ecoliMat[vldIdx], 3)\n",
    "errRate(pred, ecoliY[vldIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.7531095   1.90570435  2.35356582  2.78923996  2.75831607  5.09819285\n",
      "   2.59454517  4.09085054 15.14762401 16.15038255 17.29086775 15.53368289\n",
      "  15.89654084]\n",
      " [ 2.89632479  2.42758659  1.78430884  3.09164191  3.69661392  4.88415513\n",
      "   2.20077493  2.93689178 16.01803308 16.85705599 18.08449835 16.2482904\n",
      "  16.6680666 ]\n",
      " [ 2.48400306  4.20228236  4.83424079  2.97053469  5.98471444  7.4226921\n",
      "   3.24846557  2.34355008 13.96268961 14.42267718 15.76245646 13.98130953\n",
      "  14.53907182]\n",
      " [ 4.05646107  3.21798525  3.57839308  4.03044589  6.29779001  6.9612301\n",
      "   4.18227002  3.3522941  16.50386363 17.35561302 18.59506191 16.63545198\n",
      "  17.17488197]\n",
      " [ 3.77493685  3.13927818  1.78213933  3.03847036  3.19118653  4.1723466\n",
      "   2.54653494  3.8257698  14.89907238 15.7502842  17.20118056 15.18789626\n",
      "  15.53537594]\n",
      " [15.62919977 14.65630948 16.17242659 14.01604968 14.99672879 17.4843315\n",
      "  15.2171927  15.29248839  2.15042781  2.21585641  4.3617274   1.96923112\n",
      "   2.08483425]\n",
      " [18.12475458 17.07915063 18.83218746 16.54213631 17.71978407 20.33204627\n",
      "  17.82679365 17.72507264  3.9036171   3.50309325  3.95423407  3.38762418\n",
      "   3.53974319]]\n"
     ]
    }
   ],
   "source": [
    "testX = np.vstack([np.random.randn(8,5)+9, np.random.randn(5,5)+2])\n",
    "testY = np.array(['B']*8 + ['S']*5)\n",
    "testPred = np.vstack([np.random.randn(5,5)+9, np.random.randn(2,5)+2])\n",
    "z = pairwiseDist(testPred, testX)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'B', 'B', 'S', 'S'], dtype='<U1')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN(testX, testY, testPred, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
