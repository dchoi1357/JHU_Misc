{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "from utilities import discretizeMean, oneHot, normalizeDF, makeClassMat\n",
    "from crossValidate import getXVFolds\n",
    "from ANNmath import concateBias, sigmoid, softMax, crossEntNK, getRandomSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_0hidd import train_0hidd, pred_0hidd\n",
    "from NN_1hidd import train_1hidd, pred_1hidd\n",
    "from NN_2hidd import train_2hidd, pred_2hidd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_WI_data = os.path.join('./data/', 'breast-cancer-wisconsin.data')\n",
    "bc_WI_names = ['id', 'clumpThick', 'unifSize', 'unifShape', 'margAdhsn', \n",
    "               'epithSize', 'bareNuclei', 'blandChrom', 'normNucleo', \n",
    "               'mitoses', 'class']\n",
    "raw = pd.read_csv(bc_WI_data , names=bc_WI_names)  # read CSV file\n",
    "missRow = (raw=='?').any(axis=1).values # rows with missing data\n",
    "raw = raw[~missRow] # remove rows with missing\n",
    "raw = raw.apply(pd.to_numeric, errors= 'coerce') # conv to numeric data\n",
    "bcFeats = bc_WI_names[1:-1] # list of feature variables\n",
    "classVec = makeClassMat(raw['class']==4)\n",
    "dataMat = raw[bcFeats].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote84Data = os.path.join('./data/', 'house-votes-84.data')\n",
    "vote84Names = ['party', 'infant', 'water', 'budget', 'doctorfee', 'salvador',\n",
    "                'religion', 'satellite', 'contras', 'missile', 'immigration',\n",
    "                'synfuels', 'education', 'superfund', 'crime', 'exports',\n",
    "                'ZAF']\n",
    "raw = pd.read_csv(vote84Data , names=vote84Names ) # read in vote file\n",
    "oneHotCols = oneHot(raw,['water','education','ZAF'])\n",
    "# remove variables with completed one-hot coding from list of variables\n",
    "yesVars = np.setdiff1d(vote84Names[1:],['water','education','ZAF'])\n",
    "yesVote = raw.loc[:,yesVars] == 'y' # boolean for vote='yes' for rest of vars\n",
    "yesVote.columns = [s+'_y' for s in yesVote.columns]\n",
    "voteData = pd.concat([yesVote,oneHotCols], axis=1) # concat two dataframes\n",
    "repub = raw['party']=='republican' # boolean for republicans\n",
    "classVec = makeClassMat(repub)# vector of 0 & 1 for calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soyData = os.path.join('./data/', 'soybean-small.data')\n",
    "# use cardinal number for feature names, like c01 for 1st col, etc\n",
    "soyNames = ['c%02d'%(n+1) for n in range(35)] + ['class'] \n",
    "raw = pd.read_csv(soyData, names=soyNames)\n",
    "feats = np.array(soyNames)[raw.nunique()!=1] # remove feats with only 1 value\n",
    "feats = feats[raw[feats].nunique() == 2] # remove if non-binomial features\n",
    "\n",
    "tmpDF = pd.DataFrame()\n",
    "for f in feats: # loop over features\n",
    "    tmpDF[f] = (raw[f] == raw[f].unique()[0]) # if feature is first uniq val\n",
    "dataMat = tmpDF.values * 1 # change to 1's and 0's\n",
    "classVec = makeClassMat(raw['class']) # all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test %s\"%dataMat.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisFile = os.path.join('./data/', 'iris.data')\n",
    "irisName = ['sepalLen', 'sepalWth', 'petalLen', 'petalWth', 'class']\n",
    "raw = pd.read_csv(irisFile , names=irisName)  # read CSV file\n",
    "irisTypes = makeClassMat(raw['class'])\n",
    "irisMat = normalizeDF(raw[irisName[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = getXVFolds(irisMat, irisTypes, categorical=True)\n",
    "testIdx = folds[0]\n",
    "trainIdx = np.hstack(folds[1:])\n",
    "trainData,trainLabel = irisMat[trainIdx],irisTypes[trainIdx]\n",
    "testData,testLabel = irisMat[testIdx],irisTypes[testIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def train_0hidd(xMat, yMat, eta, eps=1e-7, trace=False, shuffle=True):\n",
    "    def feedForward(xs, ys, wts):\n",
    "        return softMax(xs @ wts)\n",
    "    \n",
    "    def backProp(ys, yfit, xs, wts):\n",
    "        return wts + eta * np.outer(xs, ys-yfit)\n",
    "    \n",
    "    xMat = concateBias(xMat) # add bias terms\n",
    "    (nData,nK),nDim = yMat.shape, xMat.shape[1] # size of data and classes\n",
    "    \n",
    "    wt = np.random.rand(nDim,nK)/50 - 0.01 # init wts to be (-0.01,0.01)\n",
    "    lastErr = np.inf # max error possible\n",
    "    yHats = feedForward(xMat, yMat, wt) # first feedforward calc\n",
    "    meanErr = crossEntNK(yHats, yMat) # error from random weights\n",
    "    \n",
    "    epch = 0\n",
    "    while (abs(meanErr-lastErr) > eps) and epch < 1e6: # while not converged\n",
    "        if epch%1000==0 and trace:\n",
    "            print('Iter #%u, error: %f'%(epch,meanErr))\n",
    "        \n",
    "        if shuffle: # shuffle sequence of gradient descent\n",
    "            seq = getRandomSeq(nData) # random seq for stoch. gradient descent\n",
    "        else:\n",
    "            seq = np.arange(nData)\n",
    "        for n in seq: # loop over data set\n",
    "            x,y = xMat[n],yMat[n] # index x and y for curr data point\n",
    "            yHat = feedForward(x, y, wt) # feedforward\n",
    "            wt = backProp(y, yHat, x, wt) # update weight\n",
    "        \n",
    "        lastErr = meanErr\n",
    "        yHats = feedForward(xMat, yMat, wt) # fitted Y for this epoch\n",
    "        meanErr = crossEntNK(yHats, yMat) # err for this epoch\n",
    "        \n",
    "        if meanErr > lastErr:  # slow learning rate if error increase\n",
    "            eta /= 5\n",
    "        epch += 1\n",
    "\n",
    "    if trace: # print final error\n",
    "        print('Final iteration #%u, error: %f' % (epch-1,meanErr) )\n",
    "    return wt,epch\n",
    "\n",
    "def pred_0hidd(xMat, wts):\n",
    "    yHat = softMax(concateBias(testData) @ wts)\n",
    "    return yHat.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.rand(4,6)/10\n",
    "concateBias(testData[0] @ v) @ np.random.rand(6+1, 3)\n",
    "print(v)\n",
    "v[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt,nn = train_1hidd(trainData, trainLabel, 3, 8, eps=1e-6, trace=True, shuffle=True)\n",
    "pred_1hidd(testData, *wt) == testLabel.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def train_1hidd(xMat, yMat, eta, nNodes, eps=1e-7, trace=False, shuffle=True):\n",
    "    def feedForward(xs, ys, wtsOut, wtsHidd):\n",
    "        zs = concateBias( sigmoid(xs@wtsHidd) )\n",
    "        return zs, softMax(zs @ wtsOut)\n",
    "    \n",
    "    def backProp(ys, yfit, xs, zs, wtsOut, wtsHidd):\n",
    "        d_Out = eta * np.outer(zs, ys-yfit)\n",
    "        d_hidd = eta * np.outer(xs, wtsOut@(ys-yfit) * (zs*(1-zs)))[:,:-1]\n",
    "        return wtsOut + d_Out, wtsHidd + d_hidd\n",
    "    \n",
    "    xMat = concateBias(xMat)\n",
    "    (nData,nK),nDim = yMat.shape, xMat.shape[1]\n",
    "    \n",
    "    wtOut = np.random.rand(nNodes+1,nK)/50 - 0.01 # init wts to be (-0.01,0.01)\n",
    "    wtHidd = np.random.rand(nDim,nNodes)/50 - 0.01\n",
    "    \n",
    "    lastErr = np.inf # max error possible\n",
    "    zs,yHats = feedForward(xMat, yMat, wtOut, wtHidd)\n",
    "    meanErr = crossEntNK(yHats, yMat)\n",
    "    \n",
    "    epch = 0\n",
    "    while (abs(meanErr-lastErr) > eps) and epch < 1e6: # while not converged\n",
    "        if epch%1000==0 and trace:\n",
    "            print('Iter #%u, error: %f'%(epch,meanErr))\n",
    "        \n",
    "        if shuffle:\n",
    "            seq = getRandomSeq(nData) # random seq for stoch. gradient descent\n",
    "        else:\n",
    "            seq = np.arange(nData)\n",
    "        for n in seq: # loop over data set\n",
    "            x,y = xMat[n],yMat[n] # index x and y for curr data point\n",
    "            z,yHat = feedForward(x, y, wtOut, wtHidd) # feedforward\n",
    "            wtOut,wtHidd = backProp(y, yHat, x, z, wtOut, wtHidd) # update weight\n",
    "################################################################################\n",
    "        lastErr = meanErr\n",
    "        zs,yHats = feedForward(xMat, yMat, wtOut, wtHidd) # fitted Y for this epoch\n",
    "        meanErr = crossEntNK(yHats, yMat) # err for this epoch\n",
    "        \n",
    "        if meanErr > lastErr:  # slow learning rate if error increase\n",
    "            eta /= 2\n",
    "        epch += 1\n",
    "\n",
    "    if trace: # print final error\n",
    "        print('Final iteration #%u, error: %f' % (epch-1,meanErr) )\n",
    "    return (wtOut,wtHidd),epch\n",
    "\n",
    "def pred_1hidd(xMat, wtsOut, wtsHidd):\n",
    "    z = sigmoid(concateBias(xMat) @ wtsHidd)\n",
    "    yHat = softMax(concateBias(z) @ wtsOut)\n",
    "    return yHat.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #0, error: 1.098633\n",
      "Iter #1000, error: 0.049496\n",
      "Iter #2000, error: 0.047250\n",
      "Iter #3000, error: 0.029844\n",
      "Iter #4000, error: 0.004723\n",
      "Iter #5000, error: 0.001255\n",
      "Iter #6000, error: 0.000737\n",
      "Iter #7000, error: 0.000522\n",
      "Final iteration #7783, error: 0.000426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt,nn,err = train_2hidd(trainData, trainLabel, 3, 6, eps=1e-7, trace=True, shuffle=False)\n",
    "pred_2hidd(testData, *wt) == testLabel.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 10.50657934,   1.26281465, -11.77279206],\n",
       "        [  8.37251125,   0.88914978,  -9.25885993],\n",
       "        [  6.52099472,   7.77065498, -14.28641747],\n",
       "        [  9.56421464,   1.66261931, -11.2394224 ],\n",
       "        [  8.24618486,   1.26049761,  -9.50810299],\n",
       "        [  8.43256651,   1.81869959, -10.25579956],\n",
       "        [-19.63495177,   2.41395448,  17.2069027 ]]),\n",
       " array([[ -3.69141031,  -1.79395101,  -3.56194723,  -3.67133325,\n",
       "          -2.04963434,  -3.1550329 ],\n",
       "        [ -2.90488223,  -1.44300358,  -3.81340717,  -2.91609953,\n",
       "          -1.57952137,  -2.51493279],\n",
       "        [  4.96434189,  -0.24250175, -10.28926198,   4.91256327,\n",
       "           2.20025144,   4.12893296],\n",
       "        [ -4.39035533,  -2.44868414,  -3.45874531,  -4.30472343,\n",
       "          -2.71326405,  -3.7330607 ],\n",
       "        [ -6.65454672,  -5.53869992,  -1.50132228,  -6.57788544,\n",
       "          -5.47474315,  -6.24499868],\n",
       "        [  4.44398362,  -0.32617749, -10.04452587,   4.39324293,\n",
       "           1.90894437,   3.66804174],\n",
       "        [  1.64150834,   2.38361557,   8.40344454,   1.62297965,\n",
       "           2.4761062 ,   1.89952085]]),\n",
       " array([[ -7.4800396 ,  -7.17202738, -13.31718472,  -5.18031807,\n",
       "           3.44529013, -12.23852341],\n",
       "        [ -2.56015036,  -2.45187917,   1.49919408,  -1.2629726 ,\n",
       "         -12.38168987,   1.38374636],\n",
       "        [ 12.82547563,  13.11938434,  22.05698929,  13.21433582,\n",
       "          13.83870003,  21.51939116],\n",
       "        [ 14.86819002,  13.1220384 ,   6.0606832 ,  16.82738843,\n",
       "          -0.59687823,   6.09545306],\n",
       "        [-15.51146902, -14.65119136, -12.28380735, -18.34545969,\n",
       "          -1.66058831, -12.40080225]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def train_2hidd(xMat, yMat, eta, nNodes, eps=1e-7, trace=False, shuffle=True):\n",
    "    def feedForward(xs, ys, wtsOut, wtsHidd2, wtsHidd1):\n",
    "        z1s = concateBias( sigmoid(xs@wtsHidd1) )\n",
    "        z2s = concateBias( sigmoid(z1s@wtsHidd2) )\n",
    "        return (z1s,z2s), softMax(z2s @ wtsOut)\n",
    "    \n",
    "    def backProp(ys, yfit, xs, zs, wtsOut, wtsHidd2, wtsHidd1):\n",
    "        z1s,z2s = zs\n",
    "        errO = ys-yfit\n",
    "        d_Out = eta * np.outer(z2s, errO)\n",
    "        \n",
    "        err2 = (wtsOut@errO) * (z2s*(1-z2s))\n",
    "        d_hidd2 = eta * np.outer(z1s,err2)[:,:-1]\n",
    "        \n",
    "        err1 = (wtsHidd2@err2[:-1]) * (z1s*(1-z1s))\n",
    "        d_hidd1 = eta * np.outer(xs,err1)[:,:-1]\n",
    "        return wtsOut + d_Out, wtsHidd2 + d_hidd2, wtsHidd1 + d_hidd1\n",
    "    \n",
    "    xMat = concateBias(xMat)\n",
    "    (nData,nK),nDim = yMat.shape, xMat.shape[1]\n",
    "    \n",
    "    wtOut = np.random.rand(nNodes+1,nK)/50 - 0.01 # init wts to be (-0.01,0.01)\n",
    "    wtHidd2 = np.random.rand(nNodes+1,nNodes)/50 - 0.01\n",
    "    wtHidd1 = np.random.rand(nDim,nNodes)/50 - 0.01\n",
    "    \n",
    "    lastErr = np.inf # max error possible\n",
    "    zs,yHats = feedForward(xMat, yMat, wtOut, wtHidd2, wtHidd1)\n",
    "    meanErr = crossEntNK(yHats, yMat)\n",
    "    \n",
    "    epch = 0\n",
    "    while (abs(meanErr-lastErr) > eps) and epch < 1e6: # while not converged\n",
    "        if epch%1000==0 and trace:\n",
    "            print('Iter #%u, error: %f'%(epch,meanErr))\n",
    "        \n",
    "        if shuffle:\n",
    "            seq = getRandomSeq(nData) # random seq for stoch. gradient descent\n",
    "        else:\n",
    "            seq = np.arange(nData)\n",
    "        for n in seq: # loop over data set\n",
    "            x,y = xMat[n],yMat[n] # index x and y for curr data point\n",
    "            z12,yHat = feedForward(x, y, wtOut, wtHidd2, wtHidd1) # feedforward\n",
    "            wtOut,wtHidd2,wtHidd1 = backProp(y, yHat, x, z12, # update wts\n",
    "                                             wtOut, wtHidd2, wtHidd1) \n",
    "################################################################################\n",
    "        lastErr = meanErr        # fitted Y for this epoch\n",
    "        zs,yHats = feedForward(xMat, yMat, wtOut, wtHidd2, wtHidd1) \n",
    "        meanErr = crossEntNK(yHats, yMat) # err for this epoch\n",
    "        \n",
    "        if meanErr > lastErr:  # slow learning rate if error increase\n",
    "            eta /= 2\n",
    "        epch += 1\n",
    "\n",
    "    if trace: # print final error\n",
    "        print('Final iteration #%u, error: %f' % (epch-1,meanErr) )\n",
    "    return (wtOut,wtHidd2,wtHidd1),epch\n",
    "\n",
    "def pred_2hidd(xMat, wtsOut, wtsHidd2, wtsHidd1):\n",
    "    z1 = sigmoid(concateBias(xMat) @ wtsHidd1)\n",
    "    z2 = sigmoid( concateBias(z1) @ wtsHidd2 )\n",
    "    yHat = softMax(concateBias(z2) @ wtsOut)\n",
    "    return yHat.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(3, int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
