{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04\n",
    "\n",
    "student: John Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, sys, csv, string, re, sklearn.preprocessing, sklearn.metrics\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn import naive_bayes as NB, svm as SVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import IPython.display as disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file names\n",
    "trainFile = './data/train.tsv'\n",
    "testFile = './data/test.tsv'\n",
    "devFile = './data/dev.tsv'\n",
    "varNames = ['stars','docID','text']\n",
    "\n",
    "# read in files\n",
    "train = pd.read_csv(trainFile, sep='\\t', header=None, names=varNames)\n",
    "dev = pd.read_csv(devFile, sep='\\t', header=None, names=varNames)\n",
    "test = pd.read_csv(testFile, sep='\\t', header=None, names=varNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Study the training data\n",
    "\n",
    "This section explores the training data set to allow a better understanding of the data. To start with, we look at whether the classes are balanced. If the mean rating of the data is 3, it would mean the data is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['stars'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get some idea of useful features for the data, we use `CountVectorizer` to count the number of term frequencies of terms appearing in each document. We set the CountVectorizer to only return binary counts (i.e. value=1 if term is in the document at least once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binVec = CountVectorizer(tokenizer=nltk.word_tokenize, binary=True)\n",
    "binTF = binVec.fit_transform(train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative word frequency\n",
    "In the following section, we find the top terms with the biggest difference of appearences between two and four-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great: 39.60% (pos), 17.80% (neg)\n",
      "was: 54.90% (pos), 75.60% (neg)\n",
      "not: 42.40% (pos), 62.00% (neg)\n",
      "!: 47.90% (pos), 28.40% (neg)\n",
      "were: 27.60% (pos), 41.60% (neg)\n",
      "n't: 45.30% (pos), 59.10% (neg)\n",
      "always: 22.70% (pos), 9.80% (neg)\n",
      "good: 55.70% (pos), 42.90% (neg)\n",
      "did: 14.40% (pos), 27.10% (neg)\n",
      "be: 32.60% (pos), 44.20% (neg)\n",
      "just: 26.70% (pos), 38.10% (neg)\n",
      "better: 11.70% (pos), 22.80% (neg)\n",
      "delicious: 14.40% (pos), 3.30% (neg)\n",
      "friendly: 17.50% (pos), 6.60% (neg)\n",
      "are: 45.00% (pos), 34.20% (neg)\n",
      "because: 13.80% (pos), 24.10% (neg)\n",
      "ordered: 13.90% (pos), 24.10% (neg)\n",
      "no: 15.50% (pos), 25.50% (neg)\n",
      "bad: 7.20% (pos), 17.00% (neg)\n",
      "at: 38.60% (pos), 47.10% (neg)\n"
     ]
    }
   ],
   "source": [
    "twoSt = (train['stars']==2).to_numpy() # idx for 2-star reviews\n",
    "tfDiff = np.abs(binTF[twoSt].mean(axis=0) - binTF[~twoSt].mean(axis=0))\n",
    "top20idx = tfDiff.A1.argsort()[-20:][::-1] # get last 20, descending\n",
    "terms = binVec.get_feature_names() # get actual terms of doc matrix\n",
    "for x in top20idx: # loop over all terms in top 20 difference\n",
    "    a,b = binTF[~twoSt,x].mean()*100, binTF[twoSt,x].mean()*100\n",
    "    print('%s: %.2f%% (pos), %.2f%% (neg)'%(terms[x],a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms are listed in order of disparity. As expected, words like \"great\", \"always\", \"good\", \"delicious\", and \"friendly\" are expected to have a high presence in positive reviews, while terms like \"not\" and \"bad\" has a high presence in negative reviews. However, there are also some counter-intuitive examples. The term \"better\" is more frequently seen in negative reviews due to expressions like \"maybe the next time I come in the food will be better\". While the term \"like\" can connotate a favorable feeling, it is also used in simile, which are present in negative reviews such as \"it tastes like a combo of cream cheese, american cheese and sour cream\". \n",
    "\n",
    "Terms like \"was\", \"were\", and \"did\" also had a higher presence in negative reviews. These words are combined with others to form negative phrases like \"was not\" and \"weren't\". One unexpected result is that people are much more likely to use exclamation marks in postive reviews. The word \"ordered\" appear to be used more frequent in negative reviews. After looking through negative reviews, they often contain details which list the items ordered and how they are bad, such as \"my friend ordered a virgin strawberry daiquiri and instead she got some weird smoothie with whip cream on top\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other useful characteristics\n",
    "\n",
    "In this section, we explore a few characteristics that are different between the two types of reviews. Each cell we break down the characteristic by star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "2    720.375\n",
       "4    631.283\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textLen = train['text'].str.len() # length of text\n",
    "textLen.groupby(train['stars']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative reviews are 90 characters longer on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "2    0.025294\n",
       "4    0.027273\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capPct = train['text'].str.count(r'[A-Z]')/textLen # % of chars upper case\n",
    "capPct.groupby(train['stars']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive reviews tend to have a slightly larger proportion of upper case letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "2    0.000543\n",
       "4    0.000399\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nPunct = train['text'].str.count('2') # number of apperences of number 2\n",
    "(nPunct/textLen).groupby(train['stars']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-star reviews tend to have more mentions of the number \"2\", likely from the reviews explicitly enumerating the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Train a classifier\n",
    "\n",
    "In this section, we build a pipeline for a naive Bayes classifier. The pipeline includes two pars:\n",
    "1. **TF-IDF vectorizer**, which extracts features from input text and builds a document-term matrix based on TF-IDF values. \n",
    "  * The text is tokenized via NLTK `word_tokenize` function.\n",
    "    * It is based on [Treebank tokenization](ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html) developed at UPenn.\n",
    "    * It splits on all whitespaces as well as contractions i.e. \"can't\" -> \"ca\", \"n't\"\n",
    "    * It tokenizes any consecutive number of punctuations, such as “,”, “?”, “—“, or “…”\n",
    "    * Punctuations inmixed with letters, such as “03/20/2018” would be tokenized as one word, as well as things like URL or hyphenated words like “open-faced”\n",
    "  * Stop words are not removed, as even simple terms like \"was\" and \"not\" appear at significantly different rates in positive and negative reviews.\n",
    "  * Only the top 5K terms by document frequency is retained. Terms with df less than 5 are also removed.\n",
    "  * TF-IDF weights are used for document-term matrix.\n",
    "1. **Multinomial naive Bayes** model is chosen\n",
    "  * Multinomial NB is chosen due to the training data being based on term counts, where the frequency of term matters as much as just apperence (the basis of Bernoulli naive Bayes model). \n",
    "  * Laplace smoothing is used with $\\alpha=1$, due to the large number of features and possibility of a term not appearing in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_tfidf = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=nltk.word_tokenize, # vectorize\n",
    "                             max_features=5000, min_df=5)),\n",
    "    ('clf', NB.MultinomialNB(alpha=1)) # classify\n",
    "])\n",
    "\n",
    "NB_tfidf.fit(train['text'], train['stars']) # fit model on training set\n",
    "pred_dev = NB_tfidf.predict(dev['text']) # pred based on dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a view of the underlying data, we pull the underlying TF-IDF document matrix and the terms. Since the TF-IDF document matrix is sparse, we only present the elements for which there is a value. The below section prints the text of the first review as well as the document matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So let me set the scene first, My church social group took a trip here last saturday. We are not your mothers church. The churhc is Community Church of Hope, We are the valleys largest GLBT church so when we desended upon Organ stop Pizza, in LDS land you know we look a little out of place. We had about 50 people from our church come and boy did we have fun.  There was a baptist church a couple rows down from us who didn't see it coming. Now we aren't a bunch of flamers frolicking around or anything but we do tend to get a little loud and generally have a great time. I did recognized some of the music  so I was able to sing along with those.  This is a great place to take anyone over 50.  I do think they might be washing dirtymob money or something since the business is cash only.........which I think caught a lot of people off guard including me.  The show starts at 530  so dont be late !!!!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>a</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>along</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181439</td>\n",
       "      <td>0.052572</td>\n",
       "      <td>0.124862</td>\n",
       "      <td>0.112978</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.156293</td>\n",
       "      <td>0.07353</td>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>0.0328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyone</th>\n",
       "      <th>anything</th>\n",
       "      <th>are</th>\n",
       "      <th>around</th>\n",
       "      <th>at</th>\n",
       "      <th>be</th>\n",
       "      <th>boy</th>\n",
       "      <th>bunch</th>\n",
       "      <th>business</th>\n",
       "      <th>but</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071641</td>\n",
       "      <td>0.055843</td>\n",
       "      <td>0.088998</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.060279</td>\n",
       "      <td>0.092999</td>\n",
       "      <td>0.091857</td>\n",
       "      <td>0.068932</td>\n",
       "      <td>0.021933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cash</th>\n",
       "      <th>caught</th>\n",
       "      <th>church</th>\n",
       "      <th>come</th>\n",
       "      <th>coming</th>\n",
       "      <th>community</th>\n",
       "      <th>couple</th>\n",
       "      <th>did</th>\n",
       "      <th>do</th>\n",
       "      <th>dont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.104911</td>\n",
       "      <td>0.629466</td>\n",
       "      <td>0.051043</td>\n",
       "      <td>0.065795</td>\n",
       "      <td>0.104911</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.118815</td>\n",
       "      <td>0.066965</td>\n",
       "      <td>0.084209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>down</th>\n",
       "      <th>first</th>\n",
       "      <th>from</th>\n",
       "      <th>fun</th>\n",
       "      <th>generally</th>\n",
       "      <th>get</th>\n",
       "      <th>great</th>\n",
       "      <th>group</th>\n",
       "      <th>had</th>\n",
       "      <th>have</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050583</td>\n",
       "      <td>0.047145</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.065199</td>\n",
       "      <td>0.08232</td>\n",
       "      <td>0.034248</td>\n",
       "      <td>0.069237</td>\n",
       "      <td>0.071641</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>0.052001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>here</th>\n",
       "      <th>hope</th>\n",
       "      <th>i</th>\n",
       "      <th>in</th>\n",
       "      <th>including</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>know</th>\n",
       "      <th>land</th>\n",
       "      <th>largest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032635</td>\n",
       "      <td>0.076074</td>\n",
       "      <td>0.069533</td>\n",
       "      <td>0.022206</td>\n",
       "      <td>0.075684</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.046379</td>\n",
       "      <td>0.104911</td>\n",
       "      <td>0.102536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last</th>\n",
       "      <th>late</th>\n",
       "      <th>let</th>\n",
       "      <th>little</th>\n",
       "      <th>look</th>\n",
       "      <th>lot</th>\n",
       "      <th>loud</th>\n",
       "      <th>me</th>\n",
       "      <th>might</th>\n",
       "      <th>money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052683</td>\n",
       "      <td>0.067284</td>\n",
       "      <td>0.060381</td>\n",
       "      <td>0.085246</td>\n",
       "      <td>0.063712</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>0.073869</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.062196</td>\n",
       "      <td>0.070227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music</th>\n",
       "      <th>my</th>\n",
       "      <th>n't</th>\n",
       "      <th>not</th>\n",
       "      <th>now</th>\n",
       "      <th>of</th>\n",
       "      <th>off</th>\n",
       "      <th>only</th>\n",
       "      <th>or</th>\n",
       "      <th>our</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072875</td>\n",
       "      <td>0.025224</td>\n",
       "      <td>0.050829</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.050358</td>\n",
       "      <td>0.100891</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.04104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out</th>\n",
       "      <th>over</th>\n",
       "      <th>people</th>\n",
       "      <th>pizza</th>\n",
       "      <th>place</th>\n",
       "      <th>saturday</th>\n",
       "      <th>scene</th>\n",
       "      <th>see</th>\n",
       "      <th>set</th>\n",
       "      <th>show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034066</td>\n",
       "      <td>0.046905</td>\n",
       "      <td>0.093811</td>\n",
       "      <td>0.051199</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.100479</td>\n",
       "      <td>0.056056</td>\n",
       "      <td>0.07961</td>\n",
       "      <td>0.07961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>since</th>\n",
       "      <th>so</th>\n",
       "      <th>social</th>\n",
       "      <th>some</th>\n",
       "      <th>something</th>\n",
       "      <th>starts</th>\n",
       "      <th>stop</th>\n",
       "      <th>take</th>\n",
       "      <th>tend</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.115262</td>\n",
       "      <td>0.104911</td>\n",
       "      <td>0.038056</td>\n",
       "      <td>0.04949</td>\n",
       "      <td>0.095573</td>\n",
       "      <td>0.065795</td>\n",
       "      <td>0.052341</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>0.095061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>there</th>\n",
       "      <th>they</th>\n",
       "      <th>think</th>\n",
       "      <th>this</th>\n",
       "      <th>those</th>\n",
       "      <th>time</th>\n",
       "      <th>to</th>\n",
       "      <th>took</th>\n",
       "      <th>trip</th>\n",
       "      <th>upon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>0.093456</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.060815</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.05423</td>\n",
       "      <td>0.073869</td>\n",
       "      <td>0.082924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>us</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>when</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047888</td>\n",
       "      <td>0.043959</td>\n",
       "      <td>0.253231</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.038741</td>\n",
       "      <td>0.052683</td>\n",
       "      <td>0.025123</td>\n",
       "      <td>0.02801</td>\n",
       "      <td>0.043173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docMat = NB_tfidf.named_steps['vect'].transform(train['text'])\n",
    "tfidfTerms = NB_tfidf.named_steps['vect'].get_feature_names()\n",
    "\n",
    "print(train['text'][0]) # print text of first review\n",
    "nonZero = docMat[0,]!=0 # idx for terms that are in first document\n",
    "names = [tfidfTerms[x] for x in np.where(nonZero.todense().A1)[0]] # actual terms\n",
    "firstDoc = pd.DataFrame(docMat[0,][nonZero], columns=names) # get first Doc\n",
    "for n in range(0, firstDoc.shape[1], 10): # loop to print document\n",
    "    disp.display(disp.HTML(firstDoc.iloc[:,n:n+10].to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the prediction of the first 10 document in the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZSJnW6faaNFQoqq4ALqYg\t4\n",
      "Rcbv11hm5AYEwZyqYwAvg\t2\n",
      "rkRTjhu5szaBggeFVcVJlA\t4\n",
      "dhmeDsQGUS1FXMLs49SWjQ\t4\n",
      "z9zfIMYmRRCE4ggfOIieEw\t4\n",
      "Xtb3pGSh39bqcozkBECw\t2\n",
      "DOUflAGzxLsXG6xOmR1w\t2\n",
      "0RxCEWURe08CTcZt95F4AQ\t2\n",
      "MzUg5twEcCyd0X6lBMP2Lg\t2\n",
      "uNlw2D5CYKk0wjNxLtYw\t4\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    print('%s\\t%d'%(dev['docID'][n],pred_dev[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Evaluate your predictions\n",
    "\n",
    "To evaluate the effectiveness of the classifier built in (b), the following function displays precision, recall, F1 score, and accuracy, as well as their constituent parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates various stats related to validation\n",
    "def validationStats(y_Prd, y_Act, msg='', algo='naive Bayes'):\n",
    "    # confusion matrix, T=true, F=false, N=negative, P=positive\n",
    "    TN, FP, FN, TP = sklearn.metrics.confusion_matrix(y_Act, y_Prd).ravel()\n",
    "    precision,recall = TP/(TP+FP) , TP/(TP+FN) # precision and recall\n",
    "    corr,tot = TN+TP , TN+TP+FN+FP # used for accuracy calculation\n",
    "    print(\"Using %s, %s\"%(algo,msg))\n",
    "    print(\"\\tTP=%d, TN=%d, FP=%d, FN=%d\"%(TP,TN,FP,FN))\n",
    "    print(\"\\tRecall: %u/%u = %.1f%%\" % (TP, TP+FN, recall*100) )\n",
    "    print(\"\\tPrecision: %u/%u = %.1f%%\" % (TP, TP+FP, precision*100) )\n",
    "    print(\"\\tF1 score: %.3f\" % (2*precision*recall / (precision+recall)) )\n",
    "    print(\"\\tAccuracy: %u/%u = %.1f%%\" % (corr,tot,corr/tot*100) )\n",
    "    return (TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using naive Bayes, TF-IDF doc vectors\n",
      "\tTP=835, TN=838, FP=162, FN=165\n",
      "\tRecall: 835/1000 = 83.5%\n",
      "\tPrecision: 835/997 = 83.8%\n",
      "\tF1 score: 0.836\n",
      "\tAccuracy: 1673/2000 = 83.7%\n"
     ]
    }
   ],
   "source": [
    "validationStats(pred_dev, dev['stars'], 'TF-IDF doc vectors');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of classification mistakes\n",
    "\n",
    "Below we present a few documents in the dev set that were classified incorrectly. The text of the document is first displayed, and the mean TF-IDF value of a few select terms by review type is also shown to assess why the review was misclassified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTermCompByClass(termList):\n",
    "    ''' The function concatenate tf-idf values of all the terms in the parameter\n",
    "    by review type, and display the resulting table '''\n",
    "    idx = [tfidfTerms.index(x) for x in termList]\n",
    "    df = pd.DataFrame(docMat[:,idx].todense()).groupby(train['stars']).mean()\n",
    "    df.columns = termList\n",
    "    disp.display(disp.HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok, I am not sure why people put down the Stratosphere, yea...yea the casino action kind of sucks....but don't go there to gamble, go there for Lucky's and Fat Tuesday's....But let's get back to Lucky's....we were here with a couple that had never been to the Strat, so we decided to go before having dinner, my honey and I decided to play some penny slot to kill time, and LO and BEHOLD...I saw a sign advertising steak and crab legs for 9.99, well, most people (NOT ME) would be scared off by that, but hell it was a hard night, I lost some moola and was looking for some cheap (but good) grub....I am after all a foodie...haha, only if you count greasy spoons. Anyways, back to Lucky's the dinner was really good, the steak was juicy, the crab legs meaty, tender and were already cut in half for you....shoot people, what more do you want, what more do you need.....Oh, but wait there's a catch, you can only order that between 7p-10p or 6-10, I forgot, but I do know it ends at 10p. Try to catch it, if you are cheap like me. A damn good, dinner, though, damn!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not</th>\n",
       "      <th>sucks</th>\n",
       "      <th>but</th>\n",
       "      <th>n't</th>\n",
       "      <th>though</th>\n",
       "      <th>greasy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041488</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.042361</td>\n",
       "      <td>0.042388</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.019250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.027497</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0.017394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dev['text'][57])\n",
    "getTermCompByClass(['not', 'sucks', 'but', \"n't\", 'though', 'greasy', 'time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review was classified as a 4, but was actually a 2. The review starts out negatively, using words like \"not\", \"sucks\", \"but\", and \"don't\". However, the initial part of the review was describing the casino, not the restaurant itself. Depiste being a positive review, it's interspersed with words frequently found in negative reviews like \"though\", \"greasy\", and \"time\" (probably from people who waited a long time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has been about a month since we last visited this place.  I recommend going to the pub and not the restaraunt side.  Service was great.  We got a couple of pints and some wings.  Wings were overdone although the sauces were good.  Love the garlic parmesan wings, even though overdone.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommend</th>\n",
       "      <th>great</th>\n",
       "      <th>good</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.006714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.033682</td>\n",
       "      <td>0.041305</td>\n",
       "      <td>0.014412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dev['text'][974])\n",
    "getTermCompByClass(['recommend', 'great', 'good', 'love'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review was misclassified as a 4, but is actually a 2. Depiste the overall review being negative, it talks about positive aspects of the visit. The review contains words typically associated with positive reviews like \"recommend\", \"great\", \"good\", and \"love\". Therefore, it's easy to see what this was misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want atmosphere, it's a great, great, great coffee shop.  If you want espresso, food, or fast service, unfortunately, look elsewhere.    Every visit here has had me run into friendly, talkative, awesome people, but I go to a coffee shop wanting coffee, honestly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>friendly</th>\n",
       "      <th>awesome</th>\n",
       "      <th>fast</th>\n",
       "      <th>unfortunately</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.005428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033682</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.000644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dev['text'][1437])\n",
    "getTermCompByClass(['great', 'friendly', 'awesome', 'fast', 'unfortunately'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review was misclassified as a 4. It is easy to see why this happened, as the reviewer used \"great\" three times as well as other words like \"good\", \"friendly\", and \"awesome\". The positive aspects of this review overwhelmed the use of negative words like \"unfortunately\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Build a second classifier\n",
    "\n",
    "For the second classifier, we build a support vector machine (SVM) pipeline is explored to test whether it can provide a better performance than naive Bayes. The pipeline contains:\n",
    "\n",
    "1. **TF-IDF vectorizer**, using the same setup as was used in **(b)**, with 5000 features and min(df)=2\n",
    "1. **Standard Scaler**, where document vector are scaled by mean and standard deviation to be between 0 and 1. This improves separability of the data by SVM\n",
    "1. **Support Vector Machines** as the classifier\n",
    "  * SVC is chosen to try to get a better separation of the two classes. \n",
    "  * Radial basis function, $\\exp(-\\gamma||x-x'||^2)$, is used as the kernel, where $\\gamma$ is inversely proportional to the number of features\n",
    "  * To ensure repeatability, the same random state is seeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVM, 5000 features\n",
      "\tTP=812, TN=825, FP=175, FN=188\n",
      "\tRecall: 812/1000 = 81.2%\n",
      "\tPrecision: 812/987 = 82.3%\n",
      "\tF1 score: 0.817\n",
      "\tAccuracy: 1637/2000 = 81.8%\n"
     ]
    }
   ],
   "source": [
    "SVM_tfidf = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=nltk.word_tokenize, \n",
    "                             max_features=5000, min_df=2) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(gamma='auto', max_iter=-1, random_state=1, kernel='rbf'))\n",
    "])\n",
    "\n",
    "pred_dev2 = SVM_tfidf.fit(train['text'], train['stars']).predict(dev['text'])\n",
    "validationStats(pred_dev2, dev['stars'], '5000 features', 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of SVM model results in a very small degredation of the result, but not very much so.\n",
    "\n",
    "With SVM focused on separability, we also evaluate an alternative setup, where only 2000 most important features are used. Wtih this setup, we hope to improve the performance as separability can be achieved better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVM, 2000 features\n",
      "\tTP=825, TN=865, FP=135, FN=175\n",
      "\tRecall: 825/1000 = 82.5%\n",
      "\tPrecision: 825/960 = 85.9%\n",
      "\tF1 score: 0.842\n",
      "\tAccuracy: 1690/2000 = 84.5%\n"
     ]
    }
   ],
   "source": [
    "SVM_tfidf_2k = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=nltk.word_tokenize, \n",
    "                             max_features=2000, min_df=2) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(gamma='auto', max_iter=-1, random_state=1, kernel='rbf'))\n",
    "])\n",
    "\n",
    "pred_dev3 = SVM_tfidf_2k.fit(train['text'], train['stars']).predict(dev['text'])\n",
    "validationStats(pred_dev3, dev['stars'], '2000 features', 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fewer features improves performance compared to the first SVM setup, about equivalent to the performance of the naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Feature engineering\n",
    "\n",
    "For this section, in addition to the bag-of-words model, we add the use of longer token sets. In the first instance, we try bigrams in addition to unigram using SVM. The setup is similar to those attempted in (d), but we increase the maximum feature counts to 5000, since with the additional of bigrams there would be more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVM, uni & bigram\n",
      "\tTP=853, TN=877, FP=123, FN=147\n",
      "\tRecall: 853/1000 = 85.3%\n",
      "\tPrecision: 853/976 = 87.4%\n",
      "\tF1 score: 0.863\n",
      "\tAccuracy: 1730/2000 = 86.5%\n"
     ]
    }
   ],
   "source": [
    "SVM_tfidf_bg = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=nltk.word_tokenize, ngram_range=(1,2),\n",
    "                             max_features=5000, min_df=2) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(gamma='auto', max_iter=-1, random_state=1, kernel='rbf'))\n",
    "])\n",
    "\n",
    "pred_dev4 = SVM_tfidf_bg.fit(train['text'], train['stars']).predict(dev['text'])\n",
    "validationStats(pred_dev4, dev['stars'], 'uni & bigram', 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using bigrams in addition to unigram increased the performance above all the classifiers we have used so far, where we are getting better precision and recall at the same time.\n",
    "\n",
    "To consider another setup, we increase the order of the model to trigrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVM, bi & trigram\n",
      "\tTP=841, TN=874, FP=126, FN=159\n",
      "\tRecall: 841/1000 = 84.1%\n",
      "\tPrecision: 841/967 = 87.0%\n",
      "\tF1 score: 0.855\n",
      "\tAccuracy: 1715/2000 = 85.8%\n"
     ]
    }
   ],
   "source": [
    "SVM_tfidf_bitri = Pipeline([ # establish pipeline\n",
    "    ('vect', TfidfVectorizer(tokenizer=nltk.word_tokenize, ngram_range=(1,3),\n",
    "                             max_features=7000, min_df=2) ),\n",
    "    ('scl', sklearn.preprocessing.StandardScaler(copy=False, with_mean=False)),\n",
    "    ('clf', SVM.SVC(gamma='auto', max_iter=-1, random_state=1, kernel='rbf'))\n",
    "])\n",
    "\n",
    "pred_dev5 = SVM_tfidf_bitri.fit(train['text'], train['stars']).predict(dev['text'])\n",
    "validationStats(pred_dev5, dev['stars'], 'bi & trigram', 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extending the feature set to trigrams does not result in as good of a performance as unigram and bigrams, especially considering recall.\n",
    "\n",
    "### Outputting predictions\n",
    "\n",
    "So far, the classifier with the best performance is the SVM model based on unigram and trigrams. As a result, we output the prediction based on this model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = SVM_tfidf_bg.predict(test['text'])\n",
    "with open('jwu74.tsv', 'w') as fh:\n",
    "    for ID,star in zip(test['docID'], pred_test):\n",
    "        fh.write('%s\\t%d\\n'%(ID,star))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jwu)",
   "language": "python",
   "name": "conda_jwu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
