{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Information Retrieval\n",
    "\n",
    "Student: John Wu\n",
    "\n",
    "__Summary__\n",
    "\n",
    "For the input file, each document is processed and an inverted file of the corpus is built. Each document is first converted to lower case and tokenized by NLTK. From these tokens an inverted file is built. The program then calculates the IDFs of each term as well as the vector document lengths of each document in the corpus. \n",
    "\n",
    "For the queries, they are processed the same way. Each query is then scored against all documents for which its term appear in. A cosine similarity score is calculated for every document and the top 50 most similar document is then chosen and written out. \n",
    "\n",
    "Generally, the inverted file is about 1/3 to 1/2 of the size of the original corpus. The time it takes to build the corpus takes much longer than the querying. Therefore, once a corpus is built, queries can be done very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re, nltk, time, math\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Build in-memory inverted file\n",
    "\n",
    "First, we must build a tokenizer that can split text into tokens to be processed by the program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt): # return lowe cased txt as tokenized by NLTK\n",
    "    ''' Tokenize a string of text and return a list of string tokens.\n",
    "    - The tokenizer is an extension on Treebank tokenization\n",
    "    - The tokenizer splits on all whitespaces as well as contractions \n",
    "      where “can’t” -> “ca”, “n’t” etc.\n",
    "    - It tokenizes any consecutive number of punctuations, such as \n",
    "      “,”, “?”, “—“, or “…”\n",
    "    - Punctuations inmixed with letters, such as “03/20/2018” would be tokenized \n",
    "      as one word, as well as things like URL or hyphenated words \n",
    "      like “open-faced”\n",
    "    '''\n",
    "    return nltk.word_tokenize(txt.casefold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input document will be processed one by one, with the result being arranged into a inverted file. The inverted file will be implemented as a python dict, a hash table with the keys being the terms themselves. These will be performed by 2 utilty functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDoc(txt, docID, vocab):\n",
    "    '''Process a string of text, and takes an inverted file as a parameter and\n",
    "    adds to the inverted file. The output is an inverted file with a new document\n",
    "    added.\n",
    "    '''\n",
    "    d = Counter( tokenize(txt) ) # count of each token\n",
    "    for tk in d: # merge dict of this doc with the bigger vocab dict\n",
    "        if tk not in vocab: # if not in vocab\n",
    "            vocab[tk] = [(docID, d[tk])] # first posting for token: (docID, DF)\n",
    "        else: # if already in vocab\n",
    "            vocab[tk].append( (docID, d[tk]) ) # append to posting list\n",
    "    return vocab, d\n",
    "\n",
    "def processDocsFile(docFile):\n",
    "    ''' Read in a text file, where each line is a document. The function \n",
    "    calls `processDoc()` function for each document, and returns an inverted\n",
    "    file as a dict as well as the total number of document processed.\n",
    "    '''\n",
    "    nDocs = 0 # count number of total docs processed\n",
    "    vcb = dict() # dict for inverted file\n",
    "\n",
    "    with open(docFile, 'r') as f:\n",
    "        for line in f: # NOTE: read line by line due to possibly large size\n",
    "            docID,txt = line.split('\\t')\n",
    "            docID = int(docID) # parse into int\n",
    "            vcb, tmpDict = processDoc(txt, docID, vcb) # process single doc\n",
    "            nDocs += 1\n",
    "\n",
    "        for term in vcb:  # go through dict and sort the posting lists\n",
    "            vcb[term].sort(key=itemgetter(0)) # sort by first elem, or docID\n",
    "            \n",
    "    return vcb, nDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the parsing of TIME dataset and building of inverted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = './data/time-documents.txt'\n",
    "t0 = time.perf_counter()\n",
    "timeInv, timeNdocs = processDocsFile(fName)\n",
    "tt = time.perf_counter() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Posting List Tuples for Terms__\n",
    "\n",
    "Since the tokenization folds the case of all terms, the terms need to be inputted as low cased. Only the first 10 entries of the posting lists are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer -> [(308, 1)]\n",
      "thailand -> [(203, 1), (243, 5), (280, 14), (396, 1), (449, 1), (498, 1), (516, 1), (534, 5), (543, 12), (544, 2)]\n",
      "rockets -> [(27, 1), (117, 1), (186, 1), (313, 6), (404, 1), (464, 2), (495, 1), (509, 2), (545, 2)]\n"
     ]
    }
   ],
   "source": [
    "terms = ['computer', 'thailand', 'rockets']\n",
    "for t in terms:\n",
    "    posts = timeInv[t][:10]\n",
    "    print('%s -> %s'%(t,posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print DF and IDF__\n",
    "\n",
    "For the three terms above, prints the document frequency and the inverse document frequency. Note that the IDF here has a one added to `N/DF` inside the log so as to prevent terms which is in every document to have an IDF of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer: DF=1, IDF=8.727920\n",
      "thailand: DF=11, IDF=5.302120\n",
      "rockets: DF=9, IDF=5.584963\n"
     ]
    }
   ],
   "source": [
    "for t in terms:\n",
    "    df = len(timeInv[t])\n",
    "    print('%s: DF=%d, IDF=%f'%(t,df,math.log2(1.0 + timeNdocs/df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Timing of Processing Documents__\n",
    "\n",
    "The time is measured as CPU process time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed in 0 minutes and 1.821 seconds.\n"
     ]
    }
   ],
   "source": [
    "print('Processed in %d minutes and %.3f seconds.'%(tt//60,tt%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Document vector length\n",
    "\n",
    "The function below implement the algorithm provided in the assignment. Note that +1.0 is added to raw IDF so to not end up with 0 if a term appears in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDocLens(vcb, nDocs):\n",
    "    '''Given an inverted file and total number of documents in corpus, \n",
    "    return a dict containing vector length of each document and another dict\n",
    "    containing the IDF value of each term.\n",
    "    '''\n",
    "    docLens = Counter() # use dict since docID may not be contiguous\n",
    "    idfs = dict() # dict storing IDF values for each term\n",
    "    \n",
    "    for term,posts in vcb.items(): # loop over all terms in collection\n",
    "        idf = math.log2(1.0 + nDocs/len(posts)) # +1.0 for term in all docs\n",
    "        idfs[term] = (len(posts), idf) # also store the DF as well\n",
    "        for docID,tf in posts: # loop over docID and tf(term,docid)\n",
    "            docLens[docID] += (tf*idf)**2 # accumulate doc vector length\n",
    "            \n",
    "    for docID,accum in docLens.items(): # loop calculate proper doc vec length\n",
    "        docLens[docID] = math.sqrt(accum) # sqrt of sum of squared terms\n",
    "    \n",
    "    return docLens,idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Document Vector Lengths__\n",
    "\n",
    "Since we do not know a priori the documents are sorted by docID, we must sort all the document IDs and get the 10 documents with the lowest IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocID=17, length=187.113691\n",
      "DocID=18, length=71.207738\n",
      "DocID=19, length=155.399087\n",
      "DocID=20, length=75.472602\n",
      "DocID=21, length=185.960262\n",
      "DocID=23, length=145.982647\n",
      "DocID=24, length=243.984066\n",
      "DocID=25, length=73.511986\n",
      "DocID=26, length=135.834693\n",
      "DocID=27, length=84.271118\n"
     ]
    }
   ],
   "source": [
    "timeDocLens,timeIDFs = calcDocLens(timeInv, timeNdocs)\n",
    "tmp = sorted(timeDocLens.items(), key=itemgetter(0))[:10] # sorted by docID\n",
    "for docID,docLen in tmp: # print 10 lowest by numerical docID\n",
    "    print('DocID=%d, length=%f'%(docID,docLen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Query representation\n",
    "\n",
    "The query files are read in and for each query (separated by line), it will be processed in the same way as the source corpus, where each query will be represented as a dict of term frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processQueryFile(queryFile):\n",
    "    ''' Read a query file and process each query. Returns a list of tuples, \n",
    "    where each tuple contains a query ID and a dict with keys being the term \n",
    "    and the item being the term frequency in the query.\n",
    "    '''\n",
    "    with open(queryFile, 'r') as f: # read the query file\n",
    "        txts = f.read().splitlines() # split by line, list of text strings\n",
    "    qs = [None for x in range(len(txts))] # pre-allocate list of query dicts\n",
    "    qIDs = [0 for x in range(len(txts))] # pre-allocate list of ints (for qID)\n",
    "    for n,line in enumerate(txts): # loop over lines (or individual queries)\n",
    "        qID,qTxt = line.split('\\t') # split queryID from query text\n",
    "        qIDs[n] = int(qID)\n",
    "        qs[n] = Counter(tokenize(qTxt)) # tokenize and count terms in query\n",
    "\n",
    "    return list(zip(qIDs, qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = './data/time-queries.txt'\n",
    "timeQs = processQueryFile(fName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TF/IDF and query vector length for 1st query__\n",
    "\n",
    "The code below goes through each term in the first query, looks up the TF and IDF of the terms, and then calculate the vector length of each term in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kennedy: tf=1, idf=3.321928\n",
      "administration: tf=1, idf=4.539975\n",
      "pressure: tf=1, idf=3.829723\n",
      "on: tf=1, idf=1.071462\n",
      "ngo: tf=1, idf=4.469235\n",
      "dinh: tf=1, idf=4.469235\n",
      "diem: tf=1, idf=4.277338\n",
      "to: tf=1, idf=1.001708\n",
      "stop: tf=1, idf=3.872352\n",
      "suppressing: not found in Corpus\n",
      "the: tf=1, idf=1.000000\n",
      "buddhists: tf=1, idf=5.179909\n",
      ".: tf=1, idf=1.000000\n",
      "\n",
      "Query Vector Length: 12.269275\n"
     ]
    }
   ],
   "source": [
    "qLen = 0\n",
    "for term,tf in timeQs[0][1].items():\n",
    "    if term in timeIDFs:\n",
    "        df,idf = timeIDFs[term]\n",
    "        print('%s: tf=%d, idf=%f'%(term,tf,idf))\n",
    "        qLen += (tf*idf) ** 2\n",
    "    else:\n",
    "        print('%s: not found in Corpus'%term)\n",
    "qLen = math.sqrt(qLen)\n",
    "    \n",
    "print('\\nQuery Vector Length: %f'%qLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Score Documents\n",
    "\n",
    "To score the queries against the corpus, we use two of the utility functions below. The first function will calculate cosine similarity for a given query against the corpus (represented by an inverted file, the IDFs of all terms, and dict of document lengths). The second function repeatedly calls the first function for every query in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSim(qDict, invFile, idfs, docLens):\n",
    "    ''' Given a query (represented as a dict) and a corpus (represented by an\n",
    "    inverted file, idfs, and document vector lengths of all documents), the \n",
    "    function calculate a similarity score of the query against all documents\n",
    "    for which any query terms appear in. It returns this score as a dict, where\n",
    "    the keys are the document IDs and the items are cosine similarity scores.\n",
    "    '''\n",
    "    sims = Counter()  # counter for storing simularity scores\n",
    "    qLen = 0 # vector length of query\n",
    "    for tk,quTF in qDict.items(): # loop over terms in a query\n",
    "        if tk not in invFile: # skip query term if not in corpus\n",
    "            continue\n",
    "        df,idf = idfs[tk] # document freq and IDF value for each token\n",
    "        qLen += (quTF*idf) ** 2\n",
    "        for docID,corpTF in invFile[tk]: # iterate through posting list\n",
    "            sims[docID] += corpTF*idf * quTF*idf \n",
    "    \n",
    "    qLen = math.sqrt(qLen) # take sqrt of query raw document length\n",
    "    for docID in sims: # has to iterate through all docs for proper score\n",
    "        sims[docID] /= (docLens[docID] * qLen) \n",
    "    return sims # return simularity scores of each document (most are 0)\n",
    "\n",
    "def processQueries(qs, invFile, idfs, docLens):\n",
    "    scores = [None for x in range(len(qs))] # score dict\n",
    "    for n,(qID,qDict) in enumerate(qs): # iterate through all queries\n",
    "        scores[n] = (qID,cosineSim(qDict, invFile, idfs, docLens))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Processing Queries and Timing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed in 0 minutes and 0.150 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "timeQscores = processQueries(timeQs, timeInv, timeIDFs, timeDocLens)\n",
    "tt = time.perf_counter() - t0\n",
    "print('Processed in %d minutes and %.3f seconds.'%(tt/60,tt%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sample of Cosine Similarity Scores__\n",
    "\n",
    "This shows the cosine similarity scores of the first query for 20 arbitrary document IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryID: 17, similarity score = 0.078330\n",
      "QueryID: 21, similarity score = 0.061475\n",
      "QueryID: 28, similarity score = 0.065611\n",
      "QueryID: 29, similarity score = 0.071129\n",
      "QueryID: 43, similarity score = 0.067917\n",
      "QueryID: 45, similarity score = 0.067563\n",
      "QueryID: 57, similarity score = 0.047027\n",
      "QueryID: 62, similarity score = 0.088439\n",
      "QueryID: 67, similarity score = 0.052006\n",
      "QueryID: 70, similarity score = 0.055056\n",
      "QueryID: 71, similarity score = 0.087181\n",
      "QueryID: 105, similarity score = 0.057303\n",
      "QueryID: 126, similarity score = 0.068932\n",
      "QueryID: 163, similarity score = 0.083421\n",
      "QueryID: 183, similarity score = 0.120371\n",
      "QueryID: 188, similarity score = 0.075367\n",
      "QueryID: 196, similarity score = 0.095311\n",
      "QueryID: 204, similarity score = 0.068869\n",
      "QueryID: 217, similarity score = 0.050837\n",
      "QueryID: 221, similarity score = 0.075565\n"
     ]
    }
   ],
   "source": [
    "for n,(qID,s) in enumerate(timeQscores[0][1].items()):\n",
    "    if n>=20:\n",
    "        break\n",
    "    print('QueryID: %d, similarity score = %f'%(qID,s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Ranked List\n",
    "Since we're using `Counter` to store similarity scores, we can use the built-in `most_common()` function, which implements a binary heap for extracting the top N items with highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopNSimDocs(qID, simScore, N=50): # return top N document for a query\n",
    "    topN = simScore.most_common(N) # use binary heap for extracting top N\n",
    "    fmt = '%d Q0 %d %d %.6f jwu74\\n' # format for output file lines\n",
    "    return [fmt % (qID,docID,n+1,score) for n,(docID,score) in enumerate(topN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting query results to `time-jwu74.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeQueryResult(outName, qScores, N=50):\n",
    "    with open(outName, 'w') as fh: \n",
    "        for qInd,score in qScores: # loop over query results\n",
    "            out = getTopNSimDocs(qInd,score) # get top N docs based on sim\n",
    "            fh.writelines(out) # write out lines for output\n",
    "\n",
    "writeQueryResult('time-jwu74.txt', timeQscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f) Efficiency\n",
    "\n",
    "In this section, we build another function which performs the entire pipeline of building the inverted file, calculating document vector lengths, processing a query file, and writing the output of top 50 similar documents in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryCorpus(corpusFile, queryFile, outFile):\n",
    "    ''' The function reads in a corpus, build the inverted file, and \n",
    "    calculate document vector lengths for the corpus. It then reads in a \n",
    "    query file, process and score the queries, and write the output of top\n",
    "    50 similar documents to an output file.\n",
    "    \n",
    "    The function returns two floats, representing the seconds it took to \n",
    "    build a corpus, and to query against this corpus.\n",
    "    '''\n",
    "    t0 = time.perf_counter() # time building process\n",
    "    invFile, nDocs = processDocsFile(corpusFile) # build inverted file\n",
    "    docLens, idfs = calcDocLens(invFile, nDocs) # calc vector doc lengths\n",
    "    buildTime = time.perf_counter() - t0 # end time\n",
    "    \n",
    "    t0 = time.perf_counter() # time querying process\n",
    "    qTxts = processQueryFile(queryFile) # read in query file\n",
    "    qryScores = processQueries(qTxts, invFile, idfs, docLens) # queries\n",
    "    queryTime = time.perf_counter() - t0 # end time\n",
    "    \n",
    "    writeQueryResult(outFile, qryScores) # output query results\n",
    "    \n",
    "    return buildTime, queryTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this pipeline on the fire10 data set takes significantly longer than the previous Reuters headlines file. The result is written to `fire10-jwu74.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build time for fire10: 5 minutes 36.826 seconds\n",
      "Query time for fire10: 0 minutes 18.169 seconds\n"
     ]
    }
   ],
   "source": [
    "bt, qt = queryCorpus('./data/fire10-documents.txt', \n",
    "                     './data/fire10-queries.txt', 'fire10-jwu74.txt' )\n",
    "\n",
    "print('Build time for fire10: %d minutes %.3f seconds'%(bt//60,bt%60))\n",
    "print('Query time for fire10: %d minutes %.3f seconds'%(qt//60,qt%60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jwu)",
   "language": "python",
   "name": "conda_jwu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
