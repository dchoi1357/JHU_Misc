{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Information Retrieval\n",
    "\n",
    "Student: John Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, re, nltk, time\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Build in-memory inverted file\n",
    "\n",
    "The input document will be processed one by one, with the result being appended into a inverted file, which is a dictionary. These will be performed by 2 utilty functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDoc(txt, docID, vocab):\n",
    "    d = Counter( nltk.word_tokenize(txt) ) # count of each token (as by NLTK)\n",
    "    for tk in d: # merge dict of this doc with the bigger vocab dict\n",
    "        if tk not in vocab: # if not in vocab\n",
    "            vocab[tk] = [(docID, d[tk])] # first posting for token: (docID, DF)\n",
    "        else: # if already in vocab\n",
    "            vocab[tk].append( (docID, d[tk]) ) # append to posting list\n",
    "    return vocab, d\n",
    "\n",
    "def processDocsFile(docFile):\n",
    "    nDocs = 0 # count number of total docs processed\n",
    "    vcb = dict() # dict for inverted file\n",
    "\n",
    "    with open(docFile, 'r') as f:\n",
    "        for line in f: # NOTE: read line by line due to possibly large size\n",
    "            docID,txt = line.split('\\t')\n",
    "            docID = int(docID) # parse into int\n",
    "            vcb, tmpDict = processDoc(txt, docID, vcb) # process single doc\n",
    "            nDocs += 1\n",
    "\n",
    "        for term in vcb:  # go through dict and sort the posting lists\n",
    "            vcb[term].sort(key=itemgetter(0)) # sort by first elem, or docID\n",
    "            \n",
    "    return vcb, nDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the parsing of TIME dataset and building of inverted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "fName = './data/time-documents.txt'\n",
    "t0 = time.process_time()\n",
    "timeVcb, timeDocs = processDocsFile(fName)\n",
    "t1 = time.process_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Posting List Tuples for Terms__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTER -> [(308, 1)]\n",
      "THAILAND -> [(203, 1), (243, 5), (280, 14), (396, 1), (449, 1), (498, 1), (516, 1), (534, 5), (543, 12), (544, 2)]\n",
      "ROCKETS -> [(27, 1), (117, 1), (186, 1), (313, 6), (404, 1), (464, 2), (495, 1), (509, 2), (545, 2)]\n"
     ]
    }
   ],
   "source": [
    "terms = ['COMPUTER', 'THAILAND', 'ROCKETS']\n",
    "for t in terms:\n",
    "    posts = timeVcb[t][:10]\n",
    "    print('%s -> %s'%(t,posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print DF and IDF__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTER: DF=1, IDF=1.000000\n",
      "THAILAND: DF=11, IDF=0.090909\n",
      "ROCKETS: DF=9, IDF=0.111111\n"
     ]
    }
   ],
   "source": [
    "for t in terms:\n",
    "    df = len(timeVcb[t])\n",
    "    print('%s: DF=%d, IDF=%f'%(t,df,1/df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Timing of Processing Documents__\n",
    "\n",
    "The time is measured as CPU process time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed in 0 minutes and 1.823 seconds.\n"
     ]
    }
   ],
   "source": [
    "t = t1-t0\n",
    "print('Processed in %d minutes and %.3f seconds.'%(np.floor(t/60),t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Document vector length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jwu)",
   "language": "python",
   "name": "conda_jwu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
