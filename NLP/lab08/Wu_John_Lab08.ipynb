{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np, pandas as pd\n",
    "from IPython.display import HTML\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import regex\n",
    "# def correctSpacing(inFile, outFile):\n",
    "#     with open(inFile, 'r', encoding='utf-8') as fh:\n",
    "#         raw = fh.read()\n",
    "#     raw1 = regex.sub(r'(\\p{Ll})\\.(\\p{Lu})', '\\g<1>. \\g<2>', raw)\n",
    "#     raw2 = regex.sub(r'(\\/\\d\\d\\d\\d)(\\p{Lu})', '\\g<1> \\g<2>', raw1)\n",
    "#     raw3 = regex.sub(r'(\\/\\d\\d)(\\p{Lu})', '\\g<1> \\g<2>', raw2)\n",
    "#     with open(outFile, 'w', encoding='utf-8') as fh:\n",
    "#         fh.write(raw3)\n",
    "\n",
    "# correctSpacing('./data/greek.txt', './data/greek.new.txt')\n",
    "# correctSpacing('./data/english.txt', './data/english.new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputList(inFile):\n",
    "    with open(inFile, 'r', encoding='utf-8') as fh:\n",
    "        raw = fh.read().split('\\n')\n",
    "    return [x for x in raw if x] # strip empty lines\n",
    "\n",
    "greeks = getInputList('./data/greek.new.txt')\n",
    "engs = getInputList('./data/english.new.txt')\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Translating Words from Aligned Parallel Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tranlation of Washington__\n",
    "\n",
    "From looking at the English file with lines containing \"Washington\", the Greek translation seems to be \"Ουάσιγκτον\", which checked to be correct from Google translate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Functions to calculate A, B, and C__\n",
    "\n",
    "First, we need to process the document. We could leverage the `CountVectorizer` of `sklearn` to produce a term-document matrix of binary counts. From these matrices, we could do the calculation we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engVec = CountVectorizer(binary=True)\n",
    "engMat = engVec.fit_transform(engs)\n",
    "engTerms = engVec.get_feature_names()\n",
    "engVcb = {k: v for v, k in enumerate(engTerms)}\n",
    "\n",
    "ellVec = CountVectorizer(binary=True)\n",
    "ellMat = ellVec.fit_transform(greeks)\n",
    "ellTerms = ellVec.get_feature_names()\n",
    "ellVcb = {k: v for v, k in enumerate(ellTerms)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, a function is written to get the term vector and another function is written to calculate the PMI and the underlying components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVec(term, english=True):\n",
    "    if english:\n",
    "        return engMat[:, engVcb[term]]\n",
    "    else: # Greek\n",
    "        return ellMat[:, ellVcb[term]]\n",
    "\n",
    "def getPMIinfo(vec1, vec2):\n",
    "    A = (vec1.transpose() * vec2).sum()\n",
    "    B = vec1.sum() - A\n",
    "    C = vec2.sum() - A\n",
    "    PMI = np.log2(vec1.shape[0]*A / (A+B) / (A+C))\n",
    "    return A, B, C, PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PMI and the components between \"motorcycle\", \"μοτοσικλέτα\" are as follows. Since it has a high PMI, it is likely the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=4, B=1, C=0, PMI=11.550747\n"
     ]
    }
   ],
   "source": [
    "x = getVec('motorcycle', True)\n",
    "y = getVec('μοτοσικλέτα', False)\n",
    "print('A=%d, B=%d, C=%d, PMI=%f'%getPMIinfo(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Top-5 ranked Greek Candidates__\n",
    "\n",
    "Since the data is stored term-document matrices, the calculation of the PMI can be done with linear algebra. The following function calculates the components of PMI (only for candidates with intersection of larger than 5), find the candidates with the highest 5 PMI scores, and output a table of them with the corresponding Greek terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopGreekTerms(engTerm, N=5, getTable=False):\n",
    "    vec = engMat[:, engVcb[engTerm]]\n",
    "    nSentEng = vec.sum()\n",
    "    nsSentEll = ellMat.sum(axis=0).A1\n",
    "    \n",
    "    As = (vec.transpose() * ellMat).todense().A1\n",
    "    idx = (As > 5).nonzero()[0]\n",
    "    As = As[idx]\n",
    "    \n",
    "    Bs = nSentEng - As\n",
    "    Cs = nsSentEll[idx] - As\n",
    "    PMI = np.log2(vec.shape[0]*As / (As+Bs) / (As+Cs))\n",
    "    \n",
    "    topN = PMI.argpartition(-N)[-N:]\n",
    "    topN = topN[PMI[topN].argsort()[::-1]]\n",
    "    outTerms = [ellTerms[x] for x in idx[topN]]\n",
    "    \n",
    "    if getTable:\n",
    "        data = zip(outTerms,As[topN],Bs[topN],Cs[topN],PMI[topN])\n",
    "        return pd.DataFrame(data, columns=['Greek Terms','A','B','C','PMI'])\n",
    "    else:\n",
    "        return outTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Greek Terms</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>συνομιλία</td>\n",
       "      <td>17</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>7.078259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>τηλεφώνου</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>7.078259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>τηλεφωνικής</td>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>6.908334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>τηλεφωνική</td>\n",
       "      <td>27</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>6.878950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>συνομιλίας</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>6.663222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = getTopGreekTerms('telephone', getTable=True)\n",
    "HTML(tmp.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Greek Terms</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>κολύμβησης</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>8.318086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>κολύμβηση</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>8.211171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>σκοποβολή</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>7.903049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>μετάλλια</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>6.318086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>αθλητές</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>6.202609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = getTopGreekTerms('swimming', getTable=True)\n",
    "HTML(tmp.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Greek Terms</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ελικοπτέρου</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>9.228819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ελικόπτερο</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9.228819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>συνετρίβη</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7.813781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>συντριβή</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>7.565854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>θάλασσα</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>160</td>\n",
       "      <td>4.438742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = getTopGreekTerms('helicopter', getTable=True)\n",
    "HTML(tmp.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Greek Terms</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ουασιγκτον</td>\n",
       "      <td>47</td>\n",
       "      <td>1239</td>\n",
       "      <td>0</td>\n",
       "      <td>3.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>πεντάγωνο</td>\n",
       "      <td>9</td>\n",
       "      <td>1277</td>\n",
       "      <td>0</td>\n",
       "      <td>3.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>μπούς</td>\n",
       "      <td>8</td>\n",
       "      <td>1278</td>\n",
       "      <td>0</td>\n",
       "      <td>3.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>file</td>\n",
       "      <td>31</td>\n",
       "      <td>1255</td>\n",
       "      <td>0</td>\n",
       "      <td>3.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ουασινγκτον</td>\n",
       "      <td>213</td>\n",
       "      <td>1073</td>\n",
       "      <td>1</td>\n",
       "      <td>3.537243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = getTopGreekTerms('washington', getTable=True)\n",
    "HTML(tmp.to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PMI Table for Select Terms__\n",
    "\n",
    "In order to keep the formatting of this workbook reasonable, the output of this section is in a separate `translation.txt` printout as there are more than 900 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all English terms appearing between 70 and 80 lines (inclusive)\n",
    "idx = np.logical_and(70 <= engMat.sum(axis=0), engMat.sum(axis=0) <= 80).A1\n",
    "selectTerms = [engTerms[x] for x in idx.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('translations.txt', 'w', encoding='utf-8') as fh:\n",
    "    for t in selectTerms: # loop over selected terms\n",
    "        fh.write('English term: [%s]\\n'%t)\n",
    "        tmp = getTopGreekTerms(t, getTable=True)\n",
    "        fh.write(tmp.to_string(index=False)+'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating MT Quality with BLEU ##\n",
    "\n",
    "In addition to the information in the lectures, we also leveraged [this](https://en.wikipedia.org/wiki/BLEU) Wikipedia article. There are three steps in calculating BLEU score:\n",
    "\n",
    "1. Generate all n-grams, 1 ≤ n ≤ 4\n",
    "1. Calculate precision for each n-gram level, clipped at the min of the reference set\n",
    "1. Find geometric mean of the four n-gram levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'to': 2, 'be': 2, 'or': 1, 'not': 1}),\n",
       " Counter({'to be': 2, 'be or': 1, 'or not': 1, 'not to': 1}),\n",
       " Counter({'to be or': 1, 'be or not': 1, 'or not to': 1, 'not to be': 1}),\n",
       " Counter({'to be or not': 1, 'be or not to': 1, 'or not to be': 1})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to generate all n-grams between two n's\n",
    "def nGramize(toks, minN=1, maxN=4):\n",
    "    outGrams = [Counter() for x in range(minN,maxN+1)]\n",
    "    nToks = len(toks)\n",
    "    for x in range(nToks):\n",
    "        for y in range(x+minN, min(nToks,x+maxN)+1):\n",
    "            outGrams[y-x-1][' '.join(toks[x:y])] += 1\n",
    "    return outGrams\n",
    "\n",
    "nGramize(['to','be','or','not','to','be']) # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "toktok = nltk.tokenize.toktok.ToktokTokenizer() # use TokTok for simplicity\n",
    "\n",
    "def calcBLEU(ref, candidate, debug=False):\n",
    "    refSet = nGramize(toktok.tokenize(ref)) # tokenize and gen all n-grams\n",
    "    candSet = nGramize(toktok.tokenize(candidate)) # same for candidate\n",
    "    score = 1\n",
    "    for n in range(4):\n",
    "        inter = refSet[n] & candSet[n] # intersection, clipped at min of either\n",
    "        prec = sum(inter.values()) / sum(candSet[n].values()) # out of all ngrams\n",
    "        score *= prec**(1/4)\n",
    "        if debug:\n",
    "            print('Precision for %d-gram is: %f'%(n+1,prec))\n",
    "        \n",
    "    # adjust by preveity penalty\n",
    "    bleu = min(1, sum(candSet[0].values())/sum(refSet[0].values())) * score\n",
    "    if debug:\n",
    "        print('Overall BLEU is: %f'%bleu)\n",
    "    return bleu\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__N-gram precisions and BLEU score__\n",
    "\n",
    "Scores for both system are reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== BLEU for System A ==\n",
      "Precision for 1-gram is: 0.769231\n",
      "Precision for 2-gram is: 0.583333\n",
      "Precision for 3-gram is: 0.545455\n",
      "Precision for 4-gram is: 0.500000\n",
      "Overall BLEU is: 0.549213\n",
      "\n",
      "== BLEU for System B ==\n",
      "Precision for 1-gram is: 0.666667\n",
      "Precision for 2-gram is: 0.454545\n",
      "Precision for 3-gram is: 0.300000\n",
      "Precision for 4-gram is: 0.111111\n",
      "Overall BLEU is: 0.271734\n"
     ]
    }
   ],
   "source": [
    "ref = 'we are very clear on this : illegal border crossing is a crime .'\n",
    "sysA = 'we say it very clearly : illegal border crossing is a crime .'\n",
    "sysB = 'we want is important : illegal border concerns is a crime .'\n",
    "\n",
    "\n",
    "print('== BLEU for System A ==')\n",
    "calcBLEU(ref, sysA, True);\n",
    "\n",
    "print('\\n== BLEU for System B ==')\n",
    "calcBLEU(ref, sysB, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BLEU metrics imperfection__\n",
    "\n",
    "BLEU metrics compares a candidate trnaslation with a reference one. Therefore, the metric is only as good as the reference. For a given sentence, there can be many different ways of writing a translation, depending on word choices and writing style. If a translation uses unconventional word choice, it could be scored not as well. For example, in Indian English, the expression \"do the needful\" is common, but it is considered archaic in American English.\n",
    "\n",
    "Secondly, BLEU ignores word meaning. Some translations may be preferred by a human if it captures the general meaning of the original sentence even if it does not read fluently. For example, consider the following translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== BLEU for 1st Sentence ==\n",
      "Precision for 1-gram is: 0.571429\n",
      "Precision for 2-gram is: 0.166667\n",
      "Precision for 3-gram is: 0.000000\n",
      "Precision for 4-gram is: 0.000000\n",
      "Overall BLEU is: 0.000000\n",
      "\n",
      "== BLEU for 2nd Sentence==\n",
      "Precision for 1-gram is: 0.666667\n",
      "Precision for 2-gram is: 0.400000\n",
      "Precision for 3-gram is: 0.250000\n",
      "Precision for 4-gram is: 0.000000\n",
      "Overall BLEU is: 0.000000\n"
     ]
    }
   ],
   "source": [
    "ref = 'I read through the instructions.'\n",
    "sys1 = 'I parsed through the instructional manual.'\n",
    "sys2 = 'I ripped up the instructions.'\n",
    "\n",
    "print('== BLEU for 1st Sentence ==')\n",
    "calcBLEU(ref, sys1, True);\n",
    "\n",
    "print('\\n== BLEU for 2nd Sentence==')\n",
    "calcBLEU(ref, sys2, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BLEU score of the second sentence is higher, even though it is opposite in meaning of the original sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
