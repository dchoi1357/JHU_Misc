{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os, torch, subprocess, csv, re\ntorch.cuda.is_available()","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Files needed for this lab\n\nCopy code files from tagger by Liu et et al from input directory to working. Create directories for outputs and input files."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy over code files from github repository \n!cp -r /kaggle/input/liutagger/* ./\n!mkdir -p checkpoint\n!cp /kaggle/input/trainedtaggermodel/* ./checkpoint/\n!mkdir ./inputs\n!cp /kaggle/input/my-tagger-test/my_test.txt ./inputs/my_test.txt\n!mkdir ./outputs\n!ls ","execution_count":2,"outputs":[{"output_type":"stream","text":"LICENSE\t\t\t   docs        model\t\t seq_wc.py\r\nREADME.md\t\t   eval_w.py   outputs\t\t train_w.py\r\n__notebook_source__.ipynb  eval_wc.py  requirements.txt  train_wc.py\r\ncheckpoint\t\t   inputs      seq_w.py\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Function for writing the system output one gets from running the tagger program."},{"metadata":{"trusted":true},"cell_type":"code","source":"def writeLogOut(logTxt, filePath):\n    if type(logTxt) is bytes: # convert to utf-8 if log is in byte chars\n        logTxt = logTxt.decode()\n    with open(filePath, 'w') as f:\n        f.write(logTxt)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################################################################################\ntemplate = ['python -W ignore train_wc.py',\n            '--emb_file /kaggle/input/glove6b100dtxt/glove.6B.100d.txt', \n            '--train_file {0}/{1}', \n            '--dev_file {0}/valid.txt', \n            '--test_file {0}/test.txt', \n            '--checkpoint checkpoint/ner_ --epoch {2}', \n            '--caseless --fine_tune --high_way --co_train --least_iters 100']\ninPath = '/kaggle/input/conll003-englishversion'\ninfile = 'train.txt'\ncmd = ' '.join(template).format(inPath,'train.txt',30)\nprint(cmd)","execution_count":4,"outputs":[{"output_type":"stream","text":"python -W ignore train_wc.py --emb_file /kaggle/input/glove6b100dtxt/glove.6B.100d.txt --train_file /kaggle/input/conll003-englishversion/train.txt --dev_file /kaggle/input/conll003-englishversion/valid.txt --test_file /kaggle/input/conll003-englishversion/test.txt --checkpoint checkpoint/ner_ --epoch 30 --caseless --fine_tune --high_way --co_train --least_iters 100\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Running the baseline run  \n\nNote: this is done twice to get some range of performance numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for n in range(3):\n    print('=== Run %d ==='%n)\n    #baseline = subprocess.check_output(cmd, shell=True)\n    #writeLogOut(baseline, './outputs/baseline_%d.log'%n)","execution_count":5,"outputs":[{"output_type":"stream","text":"=== Run 0 ===\n=== Run 1 ===\n=== Run 2 ===\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"outputs/baseline_0.log\">baseline_0.log</a>, \n<a href=\"outputs/baseline_1.log\">baseline_1.log</a>,\n<a href=\"outputs/baseline_2.log\">baseline_2.log</a>  \n\n<a href=\"checkpoint/ner_cwlm_lstm_crf.json\">ner_cwlm_lstm_crf.json</a>,\n<a href=\"checkpoint/ner_cwlm_lstm_crf.model\">ner_cwlm_lstm_crf.model</a>"},{"metadata":{},"cell_type":"markdown","source":"## Runs of partial files\n\n### Splitting of Input Files\nRead in the training file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get split points for each chunks of the file\nwith open('/kaggle/input/conll003-englishversion/train.txt', 'r') as f:\n    raw = np.array(f.read().split('\\n'))","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Produce the split file, where first file has first 1/10, second file has first 2/10, and so on, until the last file having the entirety of the content."},{"metadata":{"trusted":true},"cell_type":"code","source":"docStarts = np.where(raw=='-DOCSTART- -X- -X- O')[0] # document start points\ndocEnds = np.hstack([docStarts[1:],raw.size]) # document end points\nnDocs = docStarts.size # num of total documents in training file\nnFiles = 10\n\ndocsPerFile = np.rint(np.arange(1,nFiles+1)/nFiles*nDocs).astype(int)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n,ds in enumerate(docsPerFile):\n    blob = raw[:docEnds[:ds][-1]]  # concat all lines in this file\n    with open(os.path.join('inputs','train%02d.txt'%n), 'w') as f:\n        f.write('\\n'.join(blob))\n\n################################################################################","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look at the number of lines in each of the input files"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wc -l inputs/train*.txt","execution_count":9,"outputs":[{"output_type":"stream","text":"   20342 inputs/train00.txt\r\n   42425 inputs/train01.txt\r\n   62177 inputs/train02.txt\r\n   84506 inputs/train03.txt\r\n  108704 inputs/train04.txt\r\n  133690 inputs/train05.txt\r\n  155268 inputs/train06.txt\r\n  178879 inputs/train07.txt\r\n  198281 inputs/train08.txt\r\n  219554 inputs/train09.txt\r\n 1203826 total\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Running Partially Split Files\n\nRun training on the split files as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"inPath = './inputs'\nlog = [''for x in range(10)]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfor n in range(5,9):\n    inFile = 'train%02d.txt'%n\n    cmd = ' '.join(template).format(inPath,inFile,30)\n    print('==== Running File %d of %d ===='%(n,len(log)))\n    print(cmd)\n    log[n] = subprocess.check_output(cmd, shell=True)\n    \n    writeLogOut(log[n], './outputs/part%02d.log'%n)\nprint(\"==== Done ====\")\n'''","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"'\\nfor n in range(5,9):\\n    inFile = \\'train%02d.txt\\'%n\\n    cmd = \\' \\'.join(template).format(inPath,inFile,30)\\n    print(\\'==== Running File %d of %d ====\\'%(n,len(log)))\\n    print(cmd)\\n    log[n] = subprocess.check_output(cmd, shell=True)\\n    \\n    writeLogOut(log[n], \\'./outputs/part%02d.log\\'%n)\\nprint(\"==== Done ====\")\\n'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Download links for output logs from runs of partial files\n\nThis allows for results to be produced and retrived over many different runs instead of all at once.\n\n<a href=\"outputs/part00.log\">part00.log</a>,\n<a href=\"outputs/part01.log\">part01.log</a>, \n<a href=\"outputs/part02.log\">part02.log</a>, \n<a href=\"outputs/part03.log\">part03.log</a>, \n<a href=\"outputs/part04.log\">part04.log</a>,  \n<a href=\"outputs/part05.log\">part05.log</a>, \n<a href=\"outputs/part06.log\">part06.log</a>, \n<a href=\"outputs/part07.log\">part07.log</a>, \n<a href=\"outputs/part08.log\">part08.log</a>, \n<a href=\"outputs/part09.log\">part09.log</a>  "},{"metadata":{},"cell_type":"markdown","source":"## Remapping All Entities to Generic"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remapFiles(filePathIn, filePathOut):\n    remap = re.compile(r'([\\w]\\-)(.+)')\n    \n    fIn = open(filePathIn, 'r')\n    reader = csv.reader(fIn, delimiter=' ')\n    fOut = open(filePathOut, 'w')\n    writer = csv.writer(fOut, delimiter=' ')\n    for l in reader:\n        if l:\n            writer.writerow(l[:3] + [remap.sub(r'\\g<1>ENT', l[-1])])\n        else:\n            writer.writerow('')\n    fIn.close()\n    fOut.close()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir ./inputs/remapped\nremapFiles('/kaggle/input/conll003-englishversion/train.txt',\n           './inputs/remapped/train.txt')\nremapFiles('/kaggle/input/conll003-englishversion/test.txt',\n           './inputs/remapped/test.txt')\nremapFiles('/kaggle/input/conll003-englishversion/valid.txt',\n           './inputs/remapped/valid.txt')","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the remapped files have the same number of lines as originals"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wc -l /kaggle/input/conll003-englishversion/*.txt\n!echo ''\n!wc -l ./inputs/remapped/*.txt","execution_count":14,"outputs":[{"output_type":"stream","text":"  50350 /kaggle/input/conll003-englishversion/test.txt\n 219554 /kaggle/input/conll003-englishversion/train.txt\n  55044 /kaggle/input/conll003-englishversion/valid.txt\n 324948 total\n\n  50350 ./inputs/remapped/test.txt\n 219554 ./inputs/remapped/train.txt\n  55044 ./inputs/remapped/valid.txt\n 324948 total\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"inPath = './inputs/remapped'\ninfile = 'train.txt'\ncmd = ' '.join(template).format(inPath,'train.txt',30)\nprint(cmd)","execution_count":15,"outputs":[{"output_type":"stream","text":"python -W ignore train_wc.py --emb_file /kaggle/input/glove6b100dtxt/glove.6B.100d.txt --train_file ./inputs/remapped/train.txt --dev_file ./inputs/remapped/valid.txt --test_file ./inputs/remapped/test.txt --checkpoint checkpoint/ner_ --epoch 30 --caseless --fine_tune --high_way --co_train --least_iters 100\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remapped = subprocess.check_output(cmd, shell=True)\n#writeLogOut(remapped, './outputs/remapped.log')","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"outputs/remapped.log\">remapped.log</a>"},{"metadata":{},"cell_type":"markdown","source":"## Own Test File"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!python -W ignore seq_wc.py --load_arg ./checkpoint/ner_cwlm_lstm_crf.json \\\n#    --load_check_point ./checkpoint/ner_cwlm_lstm_crf.model \\\n#    --gpu 0 --input_file ./inputs/my_test.txt --output_file ./outputs/my_test.out","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Link to output: <a href=\"outputs/my_test.out\">my_test.out</a>"},{"metadata":{},"cell_type":"markdown","source":"Actual command for easy copy/paste\n````\n!python -W ignore train_wc.py \\\n    --emb_file /kaggle/input/glove6b100dtxt/glove.6B.100d.txt \\\n    --train_file ./inputs/train01.txt \\\n    --dev_file /kaggle/input/conll003-englishversion/valid.txt \\\n    --test_file /kaggle/input/conll003-englishversion/test.txt \\\n    --checkpoint checkpoint/ner_ --epoch 2 --caseless \\\n    --fine_tune --high_way --co_train --least_iters 100\n````"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}