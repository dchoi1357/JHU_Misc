{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Language Models\n",
    "\n",
    "Student: John Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import charlm as clm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Simple Character LM\n",
    "\n",
    "train language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = clm.train_char_lm('./data/subtitles.txt', order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuations for `itte`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n', 0.30644454186760195),\n",
      " ('r', 0.28233231039017975),\n",
      " ('d', 0.2770714598860149),\n",
      " ('e', 0.11047786058746165),\n",
      " (' ', 0.007452871547566856),\n",
      " ('s', 0.0070144673388864535),\n",
      " ('.', 0.003068829460762823),\n",
      " ('l', 0.0021920210434020165),\n",
      " (',', 0.0017536168347216134),\n",
      " ('\\n', 0.00043840420868040335),\n",
      " ('!', 0.00043840420868040335),\n",
      " (\"'\", 0.00043840420868040335),\n",
      " ('k', 0.00043840420868040335),\n",
      " ('t', 0.00043840420868040335)]\n"
     ]
    }
   ],
   "source": [
    "clm.print_probs(mdl, 'itte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuations for `supe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('r', 0.9992144540455616), ('s', 0.0007855459544383347)]\n"
     ]
    }
   ],
   "source": [
    "clm.print_probs(mdl, 'supe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuations for `ther`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 0.41045090602612727),\n",
      " (' ', 0.3175606525796159),\n",
      " ('.', 0.10865089398591295),\n",
      " (',', 0.038119318523869725),\n",
      " ('s', 0.03071458671964361),\n",
      " (\"'\", 0.022394798627415568),\n",
      " ('?', 0.02027572090783216),\n",
      " ('i', 0.008295707663596412),\n",
      " ('!', 0.007489013304436819),\n",
      " ('w', 0.00744085244717356),\n",
      " ('f', 0.006983324303172596),\n",
      " ('a', 0.005911745229065077),\n",
      " ('-', 0.003383300222743965),\n",
      " ('\\n', 0.0029498525073746312),\n",
      " ('n', 0.002925772078743002),\n",
      " ('m', 0.0018662332189512973),\n",
      " ('l', 0.0010354584311600746),\n",
      " ('h', 0.0009752573595810005),\n",
      " ('\"', 0.0006260911444223707),\n",
      " ('t', 0.00046956835831677806),\n",
      " (':', 0.00025284450063211124),\n",
      " ('b', 0.00018060321473722233),\n",
      " ('y', 0.0001685630004214075),\n",
      " (']', 0.00015652278610559268),\n",
      " (')', 0.0001083619288423334),\n",
      " ('o', 9.632171452651857e-05),\n",
      " ('/', 6.0201071579074104e-05),\n",
      " (';', 6.0201071579074104e-05),\n",
      " ('g', 6.0201071579074104e-05),\n",
      " ('´', 6.0201071579074104e-05),\n",
      " ('j', 4.816085726325929e-05),\n",
      " ('c', 3.6120642947444464e-05),\n",
      " ('\\xa0', 3.6120642947444464e-05),\n",
      " ('[', 2.4080428631629644e-05),\n",
      " ('*', 1.2040214315814822e-05),\n",
      " ('4', 1.2040214315814822e-05),\n",
      " ('F', 1.2040214315814822e-05),\n",
      " ('J', 1.2040214315814822e-05),\n",
      " ('X', 1.2040214315814822e-05),\n",
      " ('d', 1.2040214315814822e-05),\n",
      " ('p', 1.2040214315814822e-05),\n",
      " ('v', 1.2040214315814822e-05),\n",
      " ('}', 1.2040214315814822e-05),\n",
      " ('¡', 1.2040214315814822e-05),\n",
      " ('\\xad', 1.2040214315814822e-05)]\n"
     ]
    }
   ],
   "source": [
    "clm.print_probs(mdl, 'ther')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- And be a reposition, Tony.\n",
      "- In get think that I expective you'd have night to\n",
      "\n",
      "You real you meeting back in they and shout then I this he do.\n",
      "- Mom.\n",
      "- What I k\n",
      "\n",
      "Okay, the Cather up the on, James, isn't you.\n",
      "- Senora?\n",
      "He really.\n",
      "- Diddy hope \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clm.generate_text(mdl, 4, 80) + '\\n')\n",
    "print(clm.generate_text(mdl, 4, 80) + '\\n')\n",
    "print(clm.generate_text(mdl, 4, 80) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Calculate Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.160948621456589\n"
     ]
    }
   ],
   "source": [
    "sent = 'The car eats forks and knives'\n",
    "print(clm.perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "sent = 'The yob eats forks and knives'\n",
    "print(clm.perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.606972940490917\n"
     ]
    }
   ],
   "source": [
    "sent = 'The student loves homework'\n",
    "print(clm.perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7112360009044503\n"
     ]
    }
   ],
   "source": [
    "sent = 'It is raining in London'\n",
    "print(clm.perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "sent = 'asdfjkl; qwerty'\n",
    "print(clm.perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Naive smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.160948621456589\n"
     ]
    }
   ],
   "source": [
    "sent = 'The car eats forks and knives'\n",
    "print(clm.smoothed_perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.00672281265043\n"
     ]
    }
   ],
   "source": [
    "sent = 'The yob eats forks and knives'\n",
    "print(clm.smoothed_perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.606972940490917\n"
     ]
    }
   ],
   "source": [
    "sent = 'The student loves homework'\n",
    "print(clm.smoothed_perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7112360009044503\n"
     ]
    }
   ],
   "source": [
    "sent = 'It is raining in London'\n",
    "print(clm.smoothed_perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344635.520980603\n"
     ]
    }
   ],
   "source": [
    "sent = 'asdfjkl; qwerty'\n",
    "print(clm.smoothed_perplexity(sent, mdl, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Language identification\n",
    "\n",
    "List of languages and reading input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = ['fr', 'de', 'da', 'en', 'it', 'nl']\n",
    "langFilePat = './data/%s.train.txt'\n",
    "\n",
    "with open('./data/test.txt', 'r') as f:\n",
    "    testData = [l.split('\\t') for l in f.read().splitlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training character language models, identification of languages, and assessment of language ID results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCharLM(namePattern, choices, order=0):\n",
    "    '''Train character language models for all 6 languages.\n",
    "    Input requires number of character orders'''\n",
    "    lms = dict() # dict for storing LMs, key=language code\n",
    "    for c in choices: # loop over languages\n",
    "        lms[c] = clm.train_char_lm(namePattern%c, order) \n",
    "    return lms\n",
    "\n",
    "def choiceID(txt, lms, options, order):\n",
    "    '''Identify languages of an input text based on input language models\n",
    "    For each language model, calcualte the perplexity score on the input text.\n",
    "    The language with the lowest perplexity is the prediction.\n",
    "    '''\n",
    "    scores = dict()\n",
    "    for c in options:\n",
    "        scores[c] = clm.smoothed_perplexity(txt, lms[c], order)\n",
    "    return min(scores, key=scores.get)\n",
    "\n",
    "def assessLMs(options, taggedData, lms, order):\n",
    "    ''' For the test data set, calculate the accuracy of all languages\n",
    "    '''\n",
    "    accuracy = {c:[0,0] for c in options}\n",
    "    for tag, txt in taggedData:\n",
    "        accuracy[tag][1] += 1\n",
    "        pred = choiceID(txt, lms, options, order)\n",
    "        if pred == tag:\n",
    "            accuracy[tag][0] += 1\n",
    "    \n",
    "    for tag,(num,denom) in accuracy.items():\n",
    "        print('%s: %u correct out of %u -- %.1f%%' % \n",
    "              (tag,num,denom,num/denom*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Unigram models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr: 194 correct out of 200 -- 97.0%\n",
      "de: 178 correct out of 200 -- 89.0%\n",
      "da: 187 correct out of 200 -- 93.5%\n",
      "en: 187 correct out of 200 -- 93.5%\n",
      "it: 188 correct out of 200 -- 94.0%\n",
      "nl: 177 correct out of 200 -- 88.5%\n"
     ]
    }
   ],
   "source": [
    "u_lms = trainCharLM(langFilePat, LANGUAGES, 0)\n",
    "assessLMs(LANGUAGES, testData, u_lms, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first test sentence, the perplexity scores of each of the languages for the unigram model is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quels que soient les témoins qui viendront déposer à la barre, M. Milosevic aura le droit de les contre-interroger.\n",
      "\n",
      "Language: fr, perplexity: 21.230361\n",
      "Language: de, perplexity: 29.177491\n",
      "Language: da, perplexity: 28.990266\n",
      "Language: en, perplexity: 31.052441\n",
      "Language: it, perplexity: 23.153187\n",
      "Language: nl, perplexity: 26.319383\n"
     ]
    }
   ],
   "source": [
    "print(testData[0][1] + '\\n')\n",
    "for l in LANGUAGES:\n",
    "    tmp = clm.smoothed_perplexity(testData[0][1], u_lms[l], 0)\n",
    "    print('Language: %s, perplexity: %f'%(l,tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bi-gram models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr: 196 correct out of 200 -- 98.0%\n",
      "de: 198 correct out of 200 -- 99.0%\n",
      "da: 198 correct out of 200 -- 99.0%\n",
      "en: 200 correct out of 200 -- 100.0%\n",
      "it: 200 correct out of 200 -- 100.0%\n",
      "nl: 198 correct out of 200 -- 99.0%\n"
     ]
    }
   ],
   "source": [
    "bi_lms = trainCharLM(langFilePat, LANGUAGES, 1)\n",
    "assessLMs(LANGUAGES, testData, bi_lms, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4-gram models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr: 199 correct out of 200 -- 99.5%\n",
      "de: 199 correct out of 200 -- 99.5%\n",
      "da: 198 correct out of 200 -- 99.0%\n",
      "en: 200 correct out of 200 -- 100.0%\n",
      "it: 200 correct out of 200 -- 100.0%\n",
      "nl: 199 correct out of 200 -- 99.5%\n"
     ]
    }
   ],
   "source": [
    "four_lms = trainCharLM(langFilePat, LANGUAGES, 3)\n",
    "assessLMs(LANGUAGES, testData, four_lms, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary of Results__\n",
    "\n",
    "Language models generally get more accurate as orders increase. With 4-gram models, the accuracy are probably as good as one could hope for. With unigram, Germanic languages like German and Dutch are not as accurate as Romance languages like English, Italian, and French."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Gender Bias\n",
    "\n",
    "create input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderFilePat = './data/tennis_%s.txt'\n",
    "GENDERS = ['M', 'F']\n",
    "\n",
    "# split training files into two separate input files\n",
    "fMale = open('./data/tennis_M.txt', 'w')\n",
    "fFemale = open('./data/tennis_F.txt', 'w')\n",
    "with open('./data/tennis.train.txt', 'r') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        tks = line.split('\\t')\n",
    "        if tks[0] == 'M':\n",
    "            fMale.write(tks[1] + '\\n')\n",
    "        else:\n",
    "            fFemale.write(tks[1] + '\\n')\n",
    "    fMale.close()\n",
    "    fFemale.close()\n",
    "\n",
    "# read test file as tagged text data\n",
    "with open('./data/tennis.test.txt', 'r') as f:\n",
    "    tennisTest = [l.split('\\t') for l in f.read().splitlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we reuse functions created in section (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Unigram Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 2736 correct out of 4518 -- 60.6%\n",
      "F: 1845 correct out of 3696 -- 49.9%\n"
     ]
    }
   ],
   "source": [
    "mf_LM_u = trainCharLM(genderFilePat, GENDERS, 0)\n",
    "assessLMs(GENDERS, tennisTest, mf_LM_u, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bi-gram Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 2559 correct out of 4518 -- 56.6%\n",
      "F: 2416 correct out of 3696 -- 65.4%\n"
     ]
    }
   ],
   "source": [
    "mf_LM_bi = trainCharLM(genderFilePat, GENDERS, 1)\n",
    "assessLMs(GENDERS, tennisTest, mf_LM_bi, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Four-gram Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 2935 correct out of 4518 -- 65.0%\n",
      "F: 2470 correct out of 3696 -- 66.8%\n"
     ]
    }
   ],
   "source": [
    "mf_LM_four = trainCharLM(genderFilePat, GENDERS, 3)\n",
    "assessLMs(GENDERS, tennisTest, mf_LM_four, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Five-gram Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 2946 correct out of 4518 -- 65.2%\n",
      "F: 2296 correct out of 3696 -- 62.1%\n"
     ]
    }
   ],
   "source": [
    "mf_LM_five = trainCharLM(genderFilePat, GENDERS, 4)\n",
    "assessLMs(GENDERS, tennisTest, mf_LM_five, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary of results__\n",
    "\n",
    "A unigram model produced better than random results for male questions, but not female ones. Results improved with bi-gram and four-gram models, reaching about 65% correct for both genders. However, increasing the order to five-gram models resulted in a degradation of the result, likely due to ungeneralizability.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jwu)",
   "language": "python",
   "name": "conda_jwu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
