{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07: Information Extraction\n",
    "\n",
    "Student: John Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint, re\n",
    "from dateutil.parser import parse as dateParser\n",
    "pprint.sorted = lambda x, key=None: x # disable sorting of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, the spaCy library, especially its NER capabilities, is used extensively. The library performs NLP tasks such as tokenization, POS tagging, sentence segmentation, rule-based matching, etc. There are pre-trained models that achieve 86% accuracy in NER. Its output is combined with other techniques to perform the information extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\") # load spacy English model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for loading input SGML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagCap = re.compile(r'<P ID=(\\d+)>\\s+(.+?)\\s?</P>', re.DOTALL)\n",
    "def readFiles(filePath):\n",
    "    with open(filePath, 'r', encoding='utf-8') as fh:\n",
    "        matches = tagCap.findall(fh.read())\n",
    "        ids,txts = zip(*matches)\n",
    "        ids = [int(s) for s in ids]\n",
    "        return ids, txts\n",
    "    \n",
    "trIDs, trTxts = readFiles('data/obits.train.txt') # get training files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the NER capability on the 19th document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Robert &quot;Bobby&quot; Rittel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    101\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Cape Coral\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Florida\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " passed away on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    April 21, 2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br>He will be dearly missed by his loving family.</br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Bobby\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was a \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    World War II\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " veteran of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the United States Army\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</br>After his service he became an Oral Surgeon and ran a dental practice for the rest of his career.</br>A memorial service will be held on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sunday, April 28, 2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    3:00PM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " at \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Good Shepherd United Methodist Church 2951 Trail Dairy Circle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Fort Myers\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Florida\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(nlp(trTxts[18]), style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of Required Relations\n",
    "\n",
    "__Name of the deceased__\n",
    "\n",
    "Unfortunately, due to peculiarities with names like nicknames, the `PERSON` tagging capability of spaCy does not work well enough to simply extract the first PERSON entity. However, in obituaries, the name of the deceased is in the first sentence vast majority of the time. Therefore, we could parse the first sentence using word patterns to get the full name for vast majority of the time.\n",
    "\n",
    "All tokens of the name are written consecutively, in the shape of \"Xx\". Therefore, we simply take the first sequence of token where the following are not true:\n",
    "\n",
    "1. Frst letter is not capitalized\n",
    "1. Is a number\n",
    "1. is a punctuation, unless it's either a comma, left, or right side punctuation (like quotation marks)\n",
    "\n",
    "This way, names such as `John \"The Johnny\" C. Smith, Jr.` would get captured as the full name. There is a final check, that one of the tokens in this string of consecutive tokens has to be tagged as `PERSON` entity to eliminate spurious matches. If none of the tokens are `PERSON`, we simply take the first entity tagged as `PERSON`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractName(doc):\n",
    "    sent = next(doc.sents) # get first sentence of document\n",
    "    for n,tk in enumerate(sent): # loop over tokens of first sentence\n",
    "        # if\n",
    "        if (tk.is_digit or tk.shape_[0]=='x' or tk.is_punct and \n",
    "                not (tk.text==',' or tk.is_left_punct or tk.is_right_punct)):\n",
    "            break\n",
    "    if doc[n-1].is_punct: # if span ends with punctuation, reduce span by 1\n",
    "        n -= 1\n",
    "    nameSpan = doc[:n]\n",
    "    \n",
    "    # see if any PERSON entity was matched in span\n",
    "    if 'PERSON' not in set((tk.ent_type_ for tk in nameSpan)): # no PERSON\n",
    "        for e in doc.ents: # loop over all extracted entities\n",
    "            if e.label_ == 'PERSON': # find first PERSON entity\n",
    "                nameSpan = e # set that entity to the name\n",
    "                break\n",
    "    return nameSpan.text, nameSpan.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sex of the deceased__\n",
    "\n",
    "A simple way of doing this is to count the number of female pronouns (\"her\" and \"she\") vs. male ones (\"his\" and \"he\") and return the one with the higher number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isMan(tokens):\n",
    "    tokens = [tk.lower_ for tk in tokens]\n",
    "    female = sum((tk=='her' or tk=='she' for tk in tokens))\n",
    "    male = sum((tk=='his' or tk=='he' for tk in tokens))\n",
    "    return male >= female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Age at death__\n",
    "\n",
    "For this, we use combine regular expression with spaCy's matching capability. The regex matches for either a 3-digit number if the first digit is a 1, or a two digit number as a separate token (so \"105 year's old\" would be matched, but not \"410-105-0001\"). Since the age is most likely in the early part of the obit, we only check the first half of the document.\n",
    "\n",
    "One complication is that the regular expression will also match dates (e.g. the \"25\" in \"Jan 25, 2019\"). Therefore, we check the match against NER result, and only accept the match if it is not a date or if it is tagged as date, the number is greater than 31.\n",
    "\n",
    "The function returns the maximum of all matches (as dead people tend to be older).\n",
    "\n",
    "Note that the function only tries to match the age at death linguistically instead of constructing the age of death from other information provided in the document. In the template filling section, a construction of the age will be described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageMatch = spacy.matcher.Matcher(nlp.vocab)\n",
    "ageMatch.add(\"age\", None, [{\"TEXT\": {\"REGEX\": \"^(1?\\d\\d)$\"}}])\n",
    "def getAgeDoc(doc, nameEnd=None):\n",
    "    matches = ageMatch(doc)\n",
    "    spanEnd = nameEnd if nameEnd else next(doc.sents).end\n",
    "\n",
    "    numPos = list()\n",
    "    for n,(nx,mBeg,mEnd) in enumerate(matches):\n",
    "        if mBeg > len(doc)//2: # age unlikely to be in latter 1/2 \n",
    "            break\n",
    "\n",
    "        num = int(doc[mBeg:mEnd].text) # the int that was matched\n",
    "        if (doc[mBeg].ent_type_!='DATE' or # not date, or if date, num > 31\n",
    "                (doc[mBeg].ent_type_=='DATE' and num > 31) ): \n",
    "            numPos.append( (num,mBeg) )\n",
    "\n",
    "    return max(numPos, key=lambda x: x[0]) if numPos else (None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Location(s) of residency__\n",
    "\n",
    "This is perhaps the hardest extraction out of all due to the amount of complications. While spaCy generally does a pretty good job on tagging location-like entities (e.g. GPE and locations), one location are tagged separately, or the in-entities are tagged incorrectly. For example, \"Rockville, Maryland\" will get tagged as two separate entities. \"Rockville, MD\" might be tagged as `LOC` and `ORG`. To address this problem, the function works as follows. For every entity tagged as `GPE` or `LOC` it concatenate subsequent tokens if the tagged entity is:\n",
    "\n",
    "1. followed by another location-like entity ('GPE', 'LOC', 'FAC', 'ORG', or 'NORP').\n",
    "1. followed by a comma, but is followed by a location-like entity.\n",
    "\n",
    "This process is continued on until a subsequent token no longer fits. So things like \"New York, NY, U.S.A.\" will get counted as one location. For deduplication, the token index of all tokens determined to be a location is saved, such that any subsequent matches have to be an occurence yet to be seen.\n",
    "\n",
    "Another complication is that obituaries often contains information on survivors and the pre-deceased. The obituaries sometimes identify them by the cities they reside in. The function attempts prevent capturing these by looking for keywords for survivors and exclude the sentence they appear in from capture. The end of the document is also likely to contain locations where funeral services are being held. A rough way of dealing with this is to limit the matching to the first 4/5th of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivor = spacy.matcher.Matcher(nlp.vocab)\n",
    "survivor.add(\"surv\", None, [{\"LOWER\":{\"REGEX\": r'(surviv|pre-?deceas).*'}}])\n",
    "locLikes = {'GPE', 'LOC', 'FAC', 'ORG', 'NORP'}\n",
    "\n",
    "def findLocations(doc):\n",
    "    part = doc[:len(doc)//10*8] # exclude the end (where funeral info are)\n",
    "    locs,locIdxs = set(),set()\n",
    "    \n",
    "    for s in [doc[m[1]].sent for m in survivor(doc)]: # loop over sentences\n",
    "        locIdxs.update( range(s.start,s.end+1) )\n",
    "    \n",
    "    for loc in (e for e in part.ents if (e.label_=='GPE' or e.label_=='LOC')):\n",
    "        if loc.start in locIdxs:\n",
    "            continue\n",
    "        end = loc.end\n",
    "        while ((doc[end].text==',' and doc[end+1].ent_type_ in locLikes) or \n",
    "               doc[end].ent_type_ in locLikes):\n",
    "            end += 1\n",
    "        locs.add(doc[loc.start:end].text)\n",
    "        locIdxs.update( range(loc.start,end) )\n",
    "    return locs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Spouse(s) of the deceased__\n",
    "\n",
    "For matching the name of the spouses, we use regular expression to match for any appearance of tokens describing spouses or marriage (e.g. husband, partner, married, etc.). The first `PERSON` entity after such matched token is assumed to be the name of the spouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spouses = spacy.matcher.Matcher(nlp.vocab)\n",
    "spouseRe = r'(husband|wife|spouse|partner|married).*'\n",
    "spouses.add('sp', None, [{\"LOWER\": {\"REGEX\":spouseRe}}] )\n",
    "\n",
    "def findSpouseName(doc):\n",
    "    matches = spouses(doc) # search for word related to spouses\n",
    "    if not matches: # if no match, assumes no spouse can be found\n",
    "        return None\n",
    "    \n",
    "    for x,mtBeg,mtEnd in matches:\n",
    "        span = doc[mtBeg: doc[mtBeg].sent.end]\n",
    "        for et in span.ents: # loop over all persons in text span\n",
    "            if et.label_ == 'PERSON': \n",
    "                return et.text # return the first person found\n",
    "    return None # cannot find person, return empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of Additional Relations\n",
    "\n",
    "Three additional relations extracted from the text (if available) were: date of birth, date of death, and date of a funeral service.\n",
    "\n",
    "All three of these were extracted using the same function. We first build a spaCy matcher with either keywords or regular expression. With the spaCy matcher from the parameter, the function gets the first sentence it is matched in. Then it concatenate two more sentences after the sentence. For this span of the document, the function finds the first `DATE` entity that contains at least two digits.\n",
    "\n",
    "One peculiarity for birthday is that the selected document span starts at the start of the sentence it is matched (for expression like \"On October 1st 1945, John Smith was born\", while the other two start the span at the keyword it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdayMatch = spacy.matcher.Matcher(nlp.vocab) # for birthday matches\n",
    "bdayMatch.add(\"bday\", None, [{\"LOWER\":\"born\"}],[{\"LOWER\":\"birth\"}])\n",
    "\n",
    "deathMatch = spacy.matcher.Matcher(nlp.vocab) # for death matches\n",
    "deathSyns = r'^(die|pass|.?sleep|heaven|succumb|perish).*' # synonyms for death\n",
    "deathMatch.add(\"death\", None, [{\"LOWER\":{\"REGEX\": deathSyns}}])\n",
    "\n",
    "funeralMatch = spacy.matcher.Matcher(nlp.vocab) # for funeral service matches\n",
    "funeralMatch.add(\"celebration\", None, [{\"LOWER\":\"life\"},{\"LOWER\":\"celebration\"}])\n",
    "funeralMatch.add(\"serv\", None, [{\"LOWER\":{\"REGEX\": r'^(service|visitation)s?'}}]) \n",
    "funeralMatch.add(\"memo\", None, [{\"LOWER\":\"memorial\"}], [{\"LOWER\":\"viewing\"}], \n",
    "                 [{\"LOWER\":\"funeral\"}])\n",
    "\n",
    "def findDateAfterMatch(doc, matcher, startAtMatch=False):\n",
    "    matched = matcher(doc)\n",
    "    if not matched: # if no match, then nothing is after\n",
    "        return None\n",
    "    matchedSent = doc[matched[0][1]].sent # assume 1st match is good\n",
    "    spanBeg = matched[0][1] if startAtMatch else matchedSent.start\n",
    "    spanEnd = matchedSent.end\n",
    "    for n in range(2):\n",
    "        if spanEnd >= len(doc): # if no more sentences left in doc\n",
    "            break\n",
    "        spanEnd = doc[spanEnd].sent.end\n",
    "        \n",
    "    for et in doc[spanBeg:spanEnd].ents:\n",
    "        if et.label_ == 'DATE' and re.findall(r'\\d\\d', et.text):\n",
    "            return et.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Template and Outputting Result\n",
    "\n",
    "The following function simply runs all of the function above and save the result in a python dict. However, it also attempts to construct the age at death if the birth date of the deceased is available along with either a date of death or a date of funeral. With both the date of birth and date of death, the age at death can be calculated. The date of the funeral is used as a proxy if the date of death is not available. This constructed age at death overwrites the age gotten from earlier letter matching, unless the absolute difference is within two years (in which the explicitly stated age is likely more accurate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillTemplate(doc):\n",
    "    info = dict()\n",
    "    info['name'],nameEnd = extractName(doc)\n",
    "    info['sex'] = 'male' if isMan(doc) else 'female'\n",
    "    info['age'] = getAgeDoc(doc)[0] # get age using document parsing\n",
    "    info['locations'] = list(findLocations(doc))\n",
    "    info['spouse'] = findSpouseName(doc)\n",
    "    info['birth date'] = findDateAfterMatch(doc, bdayMatch)\n",
    "    info['death date'] = findDateAfterMatch(doc, deathMatch, startAtMatch=True)\n",
    "    info['funeral date'] = findDateAfterMatch(doc, funeralMatch, True)\n",
    "\n",
    "    # try to calculate age at death using birth and death (or funeral) dates\n",
    "    if info['birth date'] and (info['death date'] or info['funeral date']):\n",
    "        bd = dateParser(info['birth date']) # parse birth date\n",
    "        if info['death date']: # if death date is stated, parse death date\n",
    "            dd = dateParser(info['death date']) \n",
    "        else: # otherwise use funeral service date as proxy for death\n",
    "            dd = dateParser(info['funeral date'])\n",
    "        elapsedYrs = (dd.year-bd.year) - ((dd.month,dd.day)<(bd.month,bd.day))\n",
    "        if not info['age'] or abs(info['age'] - elapsedYrs)>2:\n",
    "            info['age'] = elapsedYrs            \n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the obituaries, analyze with spaCy, and attemp to fill template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseObitsOutputInfo(obitFiles, outInfoFiles):\n",
    "    docIDs,txts = readFiles(obitFiles)\n",
    "    \n",
    "    with open(outInfoFiles, 'w', encoding='utf-8') as outFH:\n",
    "        for docID,txt in zip(docIDs,txts):\n",
    "            doc = nlp(txt)\n",
    "            out = {'ID': docID}\n",
    "            out.update(fillTemplate(doc))\n",
    "            pprint.pprint(out, outFH)\n",
    "            outFH.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseObitsOutputInfo('data/obits.train.txt', 'obits.train.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "This section attempts to extract information from the test file. The evaluations are largely straight forward, except for location of residence and funeral date.\n",
    "\n",
    "For locations of residence, I consider a extracted location to be correct if it is a location explicitly stated by the obituary (i.e. no inferring a person lived in Baltimore if the person attend JHU), even if the locations is non-specific (i.e. \"he moved to **Colombia**\" or \"his time on **earth**\"). If a location was merely mentioned but not explicitly as a residence (i.e. \"she was a member of Christian Denomination Church in **Laurel, MD**\"), it is not counted as a location.\n",
    "\n",
    "For date of the funeral service, some obituaries mention multiple events, possibly on different dates like a viewing vs. a burial. I took the generous route and as long as the date is explicitly stated as any sort of memorial event, it would be considered correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseObitsOutputInfo('data/obits.test.txt', 'obits.test.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Statistics\n",
    "\n",
    "\n",
    "**Relation**|**Precision**|**Recall**|**F-score**\n",
    "-----|-----|-----|-----\n",
    "Name|10 / 10 (100.00%) |10 / 10 (100.00%) |1.000\n",
    "Sex|10 / 10 (100.00%) |10 / 10 (100.00%) |1.000\n",
    "Age|10 / 10 (100.00%) |10 / 10 (100.00%) |1.000\n",
    "Location|26 / 44 (59.09%) |26 / 27 (96.30%) |0.732\n",
    "Spouse|7 / 9 (77.78%) |7 / 8 (87.50%) |0.824\n",
    "Birth Date|10 / 10 (100.00%) |10 / 10 (100.00%) |1.000\n",
    "Death Date|10 / 10 (100.00%) |10 / 10 (100.00%) |1.000\n",
    "Funeral Date|7 / 7 (100.00%) |7 / 10 (70.00%) |0.824\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying numbers for the performance stats are as follows:\n",
    "\n",
    "**Relation**|**Performance**|**D100**|**D101**|**D102**|**D103**|**D104**|**D105**|**D106**|**D107**|**D108**|**D109**|**Row Sum**\n",
    "-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----\n",
    "Name|Extracted|1|1|1|1|1|1|1|1|1|1|10\n",
    "Name|Correct|1|1|1|1|1|1|1|1|1|1|10\n",
    "Name|Total|1|1|1|1|1|1|1|1|1|1|10\n",
    "Sex|Extracted|1|1|1|1|1|1|1|1|1|1|10\n",
    "Sex|Correct|1|1|1|1|1|1|1|1|1|1|10\n",
    "Sex|Total|1|1|1|1|1|1|1|1|1|1|10\n",
    "Age|Extracted|1|1|1|1|1|1|1|1|1|1|10\n",
    "Age|Correct|1|1|1|1|1|1|1|1|1|1|10\n",
    "Age|Total|1|1|1|1|1|1|1|1|1|1|10\n",
    "Location|Extracted|5|3|4|2|4|2|6|5|4|9|44\n",
    "Location|Correct|4|3|3|2|2|2|1|4|2|3|26\n",
    "Location|Total|5|3|3|2|2|2|1|4|2|3|27\n",
    "Spouse|Extracted|1|1|1|0|1|1|1|1|1|1|9\n",
    "Spouse|Correct|1|1|1|0|0|1|0|1|1|1|7\n",
    "Spouse|Total|1|1|1|0|1|1|0|1|1|1|8\n",
    "Birth Date|Extracted|1|1|1|1|1|1|1|1|1|1|10\n",
    "Birth Date|Correct|1|1|1|1|1|1|1|1|1|1|10\n",
    "Birth Date|Total|1|1|1|1|1|1|1|1|1|1|10\n",
    "Death Date|Extracted|1|1|1|1|1|1|1|1|1|1|10\n",
    "Death Date|Correct|1|1|1|1|1|1|1|1|1|1|10\n",
    "Death Date|Total|1|1|1|1|1|1|1|1|1|1|10\n",
    "Funeral Date|Extracted|1|1|1|1|1|1|0|1|0|0|7\n",
    "Funeral Date|Correct|1|1|1|1|1|1|0|1|0|0|7\n",
    "Funeral Date|Total|1|1|1|1|1|1|1|1|1|1|10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In general, the algorithm performed pretty well. This is due to obituaries largely following a general format. For the name, the location was easy as it is located in the first sentence or two. Once the linguistical format was worked out, extraction was easy. The sex was also very easy as obituaries are written in the third person with gendered pronouns. Age at death was also not difficult because it is either explicitly stated or could be constructed with date of birth and death.\n",
    "\n",
    "The dates were also not difficult to extract. Birth and death dates were easily captured by looking for keywords like \"passed\", \"died\", and \"born\". The date of the funeral performed less than ideal, despite the generous scoring. This is due to there being multiple ways of describing a memorial service. Even though the matcher has a long list of words describing funeral service, the test set had some ways that was not seen in the training set, such as \"Mass of Christian Burial will be held on Friday, April 5, 2019\" (did not search for burial as keyword) and \"Friends will be received on Tuesday, March 26, 2019\" (no funeral related keywords at all). It is possible that this can be addressed by taking the last date in the obituary given the scoring standard.\n",
    "\n",
    "There were two errors made with spouses. One obituary mentioned husband/wife of the survivors, but not of the deceased person. There is no easy way to correct for this error. Another one matched for a wrong name due to the sentence being: \"husband, 'Honest John', favorite son-in-law, Roscoe Keene\". However, the husband is mentioned elsewhere following the word \"marriage\" (which was not searched for). This could have been addressed by having additional keywords for matrimony.\n",
    "\n",
    "For location of residence, the recall was high but the precision was very low. This is there being many false positives. It is easier to do NER for a location, but h ard to distinguish whether such location is a location of residence. For example, it is possible for a location only be for work, but not living. A big source of errors were locations of survivors being extracted. The function does attempt to address this by excluding locations in the same sentence describing survivors. However, sometimes survivor description goes over sentence segmenter (a semi-colon). A good way to address the problem of low precision is to instead search for keywords regarding families like \"child\", \"son\", etc so that the locations of survivors are not even extracted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
